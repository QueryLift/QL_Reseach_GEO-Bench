# 業界別モデル活用・評価（法務・医療・財務）

## 概要


### 基本姿勢
OpenAIは、法務・医療・財務のような高規制・高説明責任領域で、安全性と有用性を同時に満たす活用を最優先に、Model Spec（CC0公開）、継続評価、プラットフォームのセキュリティ/コンプライアンスを一体で設計・運用します。OpenAIは人間の監督と説明責任を前提に、予測可能な拡張性とPreparednessに基づく評価を通じてモデル行動を継続改善し、現場ガードレールをコミュニティと共同でアップデートします。

### 重点的取り組み
OpenAIはRLHFにルールベース報酬（RBR）を統合し、過剰拒否を抑えつつ安全行動を強化、医療・メンタルヘルスを含むセンシティブ領域の応答を重点改善しています。OpenAIはHealthBench、GDPval、SWE‑bench Verifiedなど実務起点の業界別ベンチマークを拡充し、外部専門家の独立評価とPreparednessテスト、Safety Reasonerやgpt‑oss‑safeguardによる多層防御を運用します。OpenAIは契約書データエージェントや財務インテリジェンスの統合ハブ、ChatGPT Business/Enterpriseでデータ統合・説明可能性・人間の最終判断を軸に現場実装を加速します。

### 重要事実
OpenAIはGPT‑4が模擬司法試験で上位10%を達成し、HealthBench（60か国・262名医師、5,000対話/4万ルーブリック）で最新モデルの優位と改善余地を可視化、メンタルヘルスでは不適切応答を65〜80%削減しました。OpenAIはGDPvalでGPT‑4o（2024春）→GPT‑5（2025夏）にかけて2倍超（年率約3倍）の改善と、対象タスクで専門家比約100倍高速・100倍低コストを確認しました。OpenAIはSOC 2 Type 2、医療向けBAA、企業データの既定非学習化、ファインチューニングのデータ/モデル分離、原則30日保持などのデータガバナンスを提供し、オープンウェイトの安全性モデルgpt‑oss‑safeguard（120B/20B）を研究プレビューで公開しています。


## モデル・プラットフォーム
OpenAIは、法務・医療・財務といった高い規制要件と説明責任が求められる領域でモデルを安全かつ有用に活用いただけるよう、モデル行動の設計・評価・プラットフォームのガバナンスを一体で強化しています。私たちは、望ましいモデルのふるまいを定義するModel SpecをCC0で公開し、透明性と知的自由を尊重しながらガードレールを維持するという方針を明確にしました。たとえば医療相談のようなセンシティブな文脈では、原因の多様性を説明し、必要に応じて専門家への受診を促すなど、断定を避けた丁寧な案内を推奨します。対話では推測せずに明確化質問を行い、ユーザーの考えを無理に変えようとせず事実を提示する、といった指針も含め、コミュニティからのフィードバックと挑戦的な評価プロンプトを通じて準拠度を継続的に測定・改善しています。昨年時点の社内最良システムと比べて、Model Spec準拠が大幅に改善した予備結果も得ており、現場から生まれる新たなケースを取り込んで評価セットを拡充していきます[1][2]。

OpenAIは、モデルの安全行動を高度化するため、人間からのフィードバックによる強化学習（RLHF）にルールベース報酬（RBR）を統合しました。RBRは、拒否が望ましい状況では「短いお詫び」と「応じられない旨」を含む断固とした拒否、感情的にデリケートな領域では共感的な謝罪を含む柔らかい拒否、無害な要求には通常応答で従う、といった応答タイプのマッピングを明確化し、過剰拒否を抑えつつ安全性と有用性のバランスを高めます。InstructGPTに端を発するRLHFの取り組みと併せて、この枠組みを発展させ、汎用モデルのアライメントを継続的に改善しています。GPT‑4ではRLHFで行動を調整し、GPT‑3.5比で安全性指標の大幅な改善を報告しています[3][7][10]。

OpenAIは、医療・メンタルヘルスのように人命に関わりうるセンシティブな会話領域の応答を集中的に強化しました。最新の更新では、精神疾患や自傷・自殺、AIへの感情的依存に焦点を当て、不適切な応答を大幅に削減しました。Model Specの原則に沿って、ユーザーの現実世界の関係性を尊重し、根拠のない信念の無批判な肯定を避け、潜在的リスクの間接的シグナルにも敏感に対応するよう、ふるまいを改訂。問題の定義、測定、外部専門家との検証、リスク低減、継続改善というプロセスで、優先ドメインごとにChatGPTの応答品質を高めています[6]。

OpenAIは、業界別の能力評価も前進させています。法務分野では、GPT‑4が模擬司法試験で上位10%のスコアを達成するなど、リーガルリサーチや推論能力の評価で成果を示しました[10]。医療分野では、60か国・262名の医師の協力による5,000対話・4万超のルーブリックから成るHealthBenchを公開し、o3やGPT‑4.1などの最新モデルが従来モデルを大幅に上回る一方、文脈把握や最悪ケースでの信頼性に改善の余地があることを可視化しました。モデルによるルーブリック採点と医師判断との一致度を「メタ評価」で検証し、医師間一致と同程度の一致率も確認しています[11]。財務を含む主要産業横断の実務タスク評価では、米国GDP寄与上位9産業・44職種・1,320タスクから成るGDPvalを導入し、GPT‑4o（2024年春）からGPT‑5（2025年夏）にかけて2倍超、年間で約3倍の改善、さらに対象タスクで専門家比およそ100倍高速・100倍低コストでの完了を示しました（推論時間とAPI課金レートに基づく評価）[12]。

OpenAIは、開発者が各業務ドメインに合わせたガードレールを実装できるよう、オープンウェイトの安全性分類モデル「gpt‑oss‑safeguard（120b/20b）」を研究プレビューとして公開しました。本モデルは、ポリシーと分類対象コンテンツを同時に受け取り、推論とともに理由付きの結論を返すため、ドメイン固有のニュアンスに対する柔軟で説明可能な判断を可能にします。潜在的被害の出現に応じてポリシーを迅速に適応させたい場合や、小規模データ・微妙な判断が求められる状況で特に有効であり、コミュニティと連携しながら開発者の安全性パイプラインに統合して活用いただけます[5]。

OpenAIは、実運用に求められる説明可能性と一貫性を重視した設計も推進しています。たとえばDoppelとの協働では、モデルが自動判定の理由を自然言語で生成し、信頼度しきい値に応じて自動処置または人間によるレビューへ振り分ける枠組みを構築。強化ファインチューニング（RFT）により、専門家ラベルと説明品質の双方に報酬を与える採点機能を設計し、曖昧なエッジケースでも判断の一貫性と説明の明確さを向上させ、人間レベルの一貫性に近づける運用パターンを実証しました。こうした人間参加型・説明可能性重視の運用は、法務・医療・財務で求められる監査性や説明責任にも適用可能です[8]。

OpenAIは、業界別活用の前提として評価と監督の強化を位置づけ、Model Spec準拠度を測る挑戦的な評価プロンプト群を整備し、現実世界での準拠状況を継続的に測定しています。また、SWE‑bench Verifiedのようなコミュニティ連携のベンチマーク開発を通じ、モデル単体の能力だけでなく、外部システムやスキャフォルディングとの統合によって能力が大きく変化しうることを前提に、学習前・学習中・学習後を通じた継続評価を求めるPreparednessの考え方を実践しています。静的データセット評価の限界を踏まえ、実務リスクに即した評価を共同で発展させます[2][9]。

OpenAIは、プライバシーとコンプライアンス要件にも対応したプラットフォーム運用を提供します。APIプラットフォームはSOC 2 Type 2の認証を取得し、医療領域では保護対象保健情報（PHI）を扱うためのビジネスアソシエート契約（BAA）の締結に応じています。企業のお客様のデータ所有権と管理権を尊重し、ファインチューニングではお客様のプロンプト・コンプリーションペアで適応させたモデルは実施者のみが利用でき、他のお客様への提供や他モデルの学習に用いられることはありません。API入出力データは、サービス提供と不正利用の特定のために原則30日間安全に保持されます（特定エンドポイントを除く）。これらのプラットフォーム原則は、法務・財務といった機微情報を扱う業務でも、堅牢なデータガバナンスの下でモデルを活用する基盤を提供します[4]。

OpenAIは、モデル行動の指針（Model Spec）、評価の基盤、プラットフォームのセキュリティとコンプライアンス、そしてポリシー適応可能な安全技術を総合し、法務・医療・財務の現場で信頼できるAI活用を支えます。コミュニティや専門家との協働を継続し、安全性と有用性を両立させながら、業界別要件に適合した評価と運用のスタンダードをともに築いていきます[2][5][6][9]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/enterprise-privacy/
[5] https://openai.com/ja-JP/index/introducing-gpt-oss-safeguard/
[6] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[7] https://openai.com/ja-JP/index/instruction-following/
[8] https://openai.com/ja-JP/index/doppel/
[9] https://openai.com/ja-JP/index/introducing-swe-bench-verified/
[10] https://openai.com/ja-JP/index/gpt-4-research/
[11] https://openai.com/ja-JP/index/healthbench/
[12] https://openai.com/ja-JP/index/gdpval/


## モデル活用によるデータ統合・財務インテリジェンス
モデル活用によるデータ統合・財務インテリジェンスは、法務・医療・財務といった規制の厳しい領域で、データ統合と財務インテリジェンスを中核に据え、機械的な作業は自動化しつつ最終判断は人間に委ねる運用原則を徹底します。この原則は、契約書のような非構造データから条項を構造化し、非標準条項を理由付きで特定する「契約書データエージェント」の実運用で実証されており、レビュー時間の半減と夜間の自動処理による処理能力の拡張を両立し、チーム増員なしで生産性を高めました。モデル活用によるデータ統合・財務インテリジェンスは、この仕組みを財務領域にも展開し、データ解析を夜間に実行して専門家が分析と戦略に集中できる新しい運用モデルを社内外で確立しています[1]。

モデル活用によるデータ統合・財務インテリジェンスは、データウェアハウスやBI、ストリーミングを含むコネクターとコラボレーション機能を備えた統合ハブを提供し、データエンジニア、データサイエンティスト、ビジネスアナリスト、意思決定者が1つのワークスペースで連携できる環境を整備します。特徴量生成や前処理パイプラインの自動化から、モデル結果の解釈、展開可能なインサイトやサマリーの作成、モデルドリフト検知、成果物化まで、モデルから意思決定までの流れをエンドツーエンドで支援します。AIの応答は検証済みデータソース、ビジネスコンテキスト、ガバナンスに基づいて生成され、複数ソースの合成、出典明記のレポート生成、既存ツール連携（コネクターやMCP）による安全な統合、ダッシュボードやリポジトリへの自動整理など、研究・分析ワークフローの自動化を推進します[2][7]。

金融機関向けには、モデル活用によるデータ統合・財務インテリジェンスは市場データ、調査リポジトリ、社内システムのデータを安全に統合し、あらゆるプロンプトを強化できるデータ接続基盤を提供します。これらは金融基準に合わせたセキュリティ、信頼性、管理体制を備え、スケール検証済みのアーキテクチャ上で運用されます。フロンティアモデルは複雑でデータが豊富な環境でより良いインサイトを抽出し、モンテカルロシミュレーションや財務モデルの高速実行、リスク要因の特定と意思決定の迅速化に寄与します。さらにAPIプラットフォームとCodexにより、取引、リスク対策、コンプライアンスのシステム近代化と自動化を後押しします[3]。財務チーム向けには、計画・予測・分析を1つの共有ワークスペースで実施し、Slack、Notion、Google Workspaceと統合。deep researchやウェブ検索、Box、Dropbox、HubSpotなどからベンチマークや市場データを取得するエージェントモードのコネクターでレポート作成とインサイト収集を加速し、Codexや社内・市場データ連携のコネクターによって精度の高い予測、複雑な計算の自動化、KPI分析や決算レポートの要約まで高い生産性で実現します。実績として、投資評価の所要時間を従来の1〜2時間から5〜10分に短縮し、ユーザーの88%が週2時間以上の業務時間を削減しています。組織データは学習にデフォルトで使用せず、SSOや多要素認証（MFA）、SAML SSO、暗号化、中央コンソールによる権限・ブランドガバナンス・コンプライアンス管理により、分析資産・ダッシュボード・パイプライン・モデルまでをエンタープライズ水準で保護。GDPRやCCPAなどのプライバシー規制への準拠も支援します[4][2]。

業務のエンドツーエンド自動化では、モデル活用によるデータ統合・財務インテリジェンスはエージェントとアプリケーションの二層でワークフローを再設計します。金融データに特化したエージェントは、一般的なツールや最大数百テーブル・テラバイト級を含む構造化・非構造化データにまたがってスキーマを理解し、コードを作成し、文脈を把握して情報を取得します。アプリケーション層は金融に特化したインターフェースによりエンドツーエンドの自動化を実現し、退屈な作業を自動化することで人間は人間関係と戦略的思考に集中できます。これは契約処理のオペレーティングモデル変革の実績と整合し、専門家がインテリジェントシステムと連携してより重要な業務に時間を配分できるという設計哲学に根差しています。加えて、パートナー事例では、SharePointや一般的な金融データセット（Capital IQ、FactSet、Crunchbase等）にまたがる最大数百テーブル、20テラバイト規模のデータに対応し、文脈理解・スキーマ把握・コード生成・大規模データからの情報取得までを実現する取り組みを紹介しています[10][1][5]。

医療・金融のような高リスク領域での活用にあたって、モデル活用によるデータ統合・財務インテリジェンスは評価と安全性を最重視します。医療分野では、60か国・262名の医師の協力で作成した5,000の対話と4万以上のルーブリックからなる包括的ベンチマーク「HealthBench」を用い、健康データタスク、グローバルヘルス、コンテキスト把握、コミュニケーションの質、指示遵守、事実性、完全性など多面的にモデルを評価。最新モデルの改善点と信頼性・文脈把握に関する改善余地を明確に示し、ユーザーが十分な情報に基づく意思決定を行えるよう必要な詳細レベルで情報提供します[8]。加えて、Model Specを公開し、モデル行動の指針と評価用プロンプトを整備、準拠度の測定とアライメントの継続的改善を進めています。外部の独立評価者による第三者評価（独立評価、方法論レビュー、SMEプロービング）を通じ、フロンティアモデルの能力とリスクを測定し、慎重な情報開示・安全なアクセス、厳格なセキュリティ管理、バランスの取れたインセンティブの原則のもと、GPT‑5を含むモデルに適用しています[9][6]。

医療の実装例として、モデル活用によるデータ統合・財務インテリジェンスはAPIを活用し、「1分間で何百人もの患者を評価」するワークロードの設計・運用を通じて、データ統合と意思決定支援の基盤が医療にも適用可能であることを示しています[10]。

モデル活用によるデータ統合・財務インテリジェンスは、法務・医療・財務の現場におけるデータ統合と財務インテリジェンスの実装を、セキュアでコンプライアンスに適合した基盤、実運用での生産性向上、エージェントによるエンドツーエンド自動化、そして厳格な評価とガバナンスで一貫して支えます。専門家の判断を中心に据えながら、より迅速で正確な意思決定とスケーラブルな運用モデルへの移行を推進し、業界別のモデル活用・評価を着実に前進させています[1][2][3][4][7][8][9][10]。

【出典】
[1] https://openai.com/ja-JP/index/openai-contract-data-agent/
[2] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[3] https://openai.com/ja-JP/solutions/industries/financial-services/
[4] https://chatgpt.com/ja-JP/business/ai-for-finance/
[5] https://openai.com/ja-JP/index/model-ml-chaz-englander/
[6] https://openai.com/ja-JP/index/strengthening-safety-with-external-testing/
[7] https://openai.com/ja-JP/solutions/use-case/research/
[8] https://openai.com/ja-JP/index/healthbench/
[9] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[10] https://openai.com/ja-JP/solutions/use-case/data-analysis/


## 予測の活用・意思決定統合
予測の活用・意思決定統合は、法務・医療・財務といった高影響領域でモデルを活用する際、予測可能性に基づく評価と、安全に意思決定へ統合できる運用設計を最優先に据えます。私たちは、将来の機械学習システムの性能をできる限り正確に予測することをAIの安全性の要と位置づけ、社会に対して明確な期待値を提示できる手法の開発に継続的に取り組みます[1]。その一環として、計算量が1/10,000の小型モデルから最終損失を高精度に予測し、さらに1/1,000規模のモデルでHumanEvalの一部に対する合格率を予測するなど、スケーリングに基づく能力予測を実運用へ橋渡ししてきました。こうした能力予測は、より解釈しやすい評価指標へと拡張し、各業界のワークフローにモデルを組み込む際のリスク評価や品質保証の設計指針として機能します[1]。

予測の活用・意思決定統合は、医療など人命や生活に直結する文脈では、モデルが「なぜその判断に至ったのか」を理解できることが不可欠だと考え、スパース回路の研究を通じて、モデルの振る舞いを追跡可能なステップへ分解し、性能を維持しながら解釈可能性を高める可能性を検証しています。また、思考の連鎖（Chain of Thought）は監視・観察に即効性のある手段である一方、これのみに依存しない補完的アプローチを並行して研究しています[2]。安全性とアライメントは推論プロセスに直接組み込み、思考の連鎖に安全規則とその文脈的適用方法を埋め込むことで、分布外シナリオやジェイルブレイク、エッジケースに対する堅牢性を高めています。デプロイ前にはPreparedness Frameworkに基づく安全性テストとレッドチーミングを実施し、評価の詳細はSystem Cardで公開します[3]。

予測の活用・意思決定統合は、規制遵守やプライバシー保護などの業務要件に対して、望ましいモデル行動の指針であるModel Specを策定し、危険な情報の不提供、適用法の遵守、クリエイターの権利尊重、プライバシー保護を明確に定義しました[4]。現実世界でのパフォーマンス理解を深めるため、挑戦的なプロンプトセットで準拠度を測定し、昨年の最良システム比で準拠が大幅に改善していることを確認しています。これは現場で発見される新たなケースを取り込みながら継続的に更新しています[5]。意思決定への統合では、Responses APIとマルチエージェントのルーティングを活用し、役割を狭く分担したエージェント群が誤りを減らし、必要に応じて「回答しない」を選べるアーキテクチャを支援します。各回答には元研究・メタデータ・主要結果を構造化した研究コンテキストパックを付与し、根拠を遡及可能な形で提示します。初期評価では、長文コンテキスト推論と安定したツール呼び出しが、ツール精度やプランニング安定性の向上に寄与しています[6][9]。

予測の活用・意思決定統合は、強化学習（RL）により推論努力の拡大とツール使用の熟達を両立させ、o3/o4‑miniにおいて思考時間を長く与えるほど性能が向上すること、さらに「いつツールを使うか」を自律的に判断できる能力を高めました。加えて、画像をChain of Thoughtに直接組み込み、視覚とテキストを融合した新しい問題解決クラスを実現しています[10]。安全運用では、多層防御の中核として推論ベースの安全性推論（Safety Reasoner）を採用し、運用中の安全ポリシーを迅速に更新しつつ、必要に応じて計算資源を投下し慎重に適用できる体制を敷いています。実際に一部リリースでは安全性推論に全計算の16%を割き、画像生成やSora 2での段階的出力評価、自傷・バイオ領域では高再現率クラシファイアでドメイン判定後にSafety Reasonerへ引き渡す多層防御を運用しています。また、開発者が推論時に独自の安全ポリシーを指定できるオープンウェイト「gpt‑oss‑safeguard（120b/20b）」も研究プレビューとして提供しています[7]。

予測の活用・意思決定統合は、プロフェッショナル用途に向けて長文処理、コード生成、画像認識、ツール呼び出し、安全性や事実誤認の改善を図ったGPT‑5.2を提供し、ベンチマークで従来モデルを大きく上回る性能を確認しています[9]。さらに、GPT‑4.5では知識の広がりや意図理解、創造性とEQの向上を実現し、o1のような推論モデルと相補し合う方向性を示しました。私たちは、事前学習と推論のスケーリングを相補的に発展させ、将来のモデルの中核機能として推論を強化していきます[8]。

法務領域では、予測の活用・意思決定統合は、GPT‑4が模擬司法試験で上位10%のスコアを記録する評価を実施し[1]、「予測可能な拡張性」に基づき小型モデルから大規模モデルの性能を見通す検証を行い、継続的な性能管理を推進しています。Model Spec準拠度は挑戦的プロンプトセットでの測定により大幅に改善し[5]、人間フィードバックの非効率を補うルールベース報酬（RBR）をRLHFに統合して安全性と有用性のバランスを保ちながら過剰拒否を抑制できる運用を確立しました[13]。運用面では、ChatGPT Businessで「データはデフォルトで学習に使用しない」方針、SSO・多要素認証、専用ワークスペースによる権限・ブランドガバナンス・コンプライアンスの一元管理を提供し、法務・コンプライアンス視点からの導入を支援しています[11]。

医療領域では、予測の活用・意思決定統合は、センシティブなメンタルヘルス会話への応答を強化し、不適切応答を65〜80%削減する改善を行いました。170名超の専門家による評価に加え、実運用前の高リスク・困難シナリオに焦点を当てたオフライン評価も実施しています[12]。さらに、安全規則を推論過程に直接埋め込むことで、困難な安全評価でも安全なコンプリーション率を大幅に向上させ、Preparedness Frameworkに基づくテストとレッドチーミングの結果をSystem Cardで公開しています[3]。運用時にはSafety Reasonerを中核に、画像・動画の段階的評価や高再現率クラシファイアによるドメイン判定を組み合わせた多層防御を敷き、開発者向けのgpt‑oss‑safeguardでポリシー適用の柔軟性も提供します[7]。

財務・アナリティクス領域では、予測の活用・意思決定統合は、ChatGPT Businessのデータサイエンス＆アナリティクス機能でデータウェアハウス、BI、ストリーミング等へのコネクターを備えた「1つのハブ」を提供し、特徴量生成や前処理、モデル解釈、ドリフト検知、意思決定に直結するインサイト生成までを自動化。検証済みデータソースとビジネスコンテキスト、ガバナンスを前提に、意思決定者が自信を持って行動できる「信頼できるインサイト」を実現します。データの既定非学習化、SSO・多要素認証、専用ワークスペースの一元管理でセキュリティとコラボレーションも両立します[11]。同時に、o3/o4‑miniで検証した「思考時間の拡大に伴う性能向上」や「ツールを使うべき状況の自律判断」、視覚を含む多段ワークフローでの推論能力をワークフロー統合に活かしています[10]。

横断的には、予測の活用・意思決定統合は、モデルのスケールを跨いだ「予測可能な拡張性」により更新時の性能見通しを立てやすくし[1]、スパース回路の研究でモデル挙動の部分的説明可能性を高め[2]、GPT‑5.2がARC‑AGIやFrontierMathで高スコアを達成し、厳密な条件下で提示した証明が検証されるといった事例を通じて、人の綿密な監督のもとで定量的に厳密なアウトプットを意思決定に取り込む取り組みを支えています[9]。

予測の活用・意思決定統合は、能力予測、解釈可能性、安全性規範、ワークフロー分解、ツール連携を統合した全体設計により、法務・医療・財務を含む高影響領域での意思決定を、確かな根拠と安全性のもとで一貫して支援していきます[1][2][3][4][5][6][7][8][9][10][11][12][13]。

【出典】
[1] https://openai.com/ja-JP/index/gpt-4-research/
[2] https://openai.com/ja-JP/index/understanding-neural-networks-through-sparse-circuits/
[3] https://openai.com/ja-JP/index/learning-to-reason-with-llms/
[4] https://openai.com/ja-JP/index/introducing-the-model-spec/
[5] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[6] https://openai.com/ja-JP/index/consensus/
[7] https://openai.com/ja-JP/index/introducing-gpt-oss-safeguard/
[8] https://openai.com/ja-JP/index/introducing-gpt-4-5/
[9] https://openai.com/ja-JP/index/introducing-gpt-5-2/
[10] https://openai.com/ja-JP/index/introducing-o3-and-o4-mini/
[11] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[12] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[13] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/


## 予測システム・KPIモデル
予測システム・KPIモデルは、法務・医療・財務といった高影響領域での活用にあたり、実世界の成果に直結する予測システムとKPIに基づく評価を中核に据える公式見解を掲げ、現場の判断と経営意思決定を結びつけるエンドツーエンドのワークフロー（実務データからの特徴量生成、KPIダッシュボード、A/Bテスト、異常検知、モデル解釈、ドリフト監視、再現性あるデプロイ）を提供します。これにより、業界別の要件や安全基準を満たしながら、KPIで管理可能な予測モデル運用を推進します[1]。

予測システム・KPIモデルは、データサイエンス＆アナリティクス向けの統合ワークスペースを基盤に、経営層向けインサイトブリーフ、KPI・主要因・アラート・担当者までを含むダッシュボードのストーリーボード、モデルの信頼度・バイアス・安全な利用方法に関するトレーニング、データ品質チェックと是正計画、指標・サンプルサイズ・ランダム化・終了ルールを備えたA/Bテスト設計、トリアージとアラートを備えた異常検知パイプライン、CI/CDとロールバックによる再現性あるデプロイ、SHAP・PDP・サブグループチェックを含むモデル解釈、CRMやプロダクト利用データに基づく特徴量エンジニアリング、変化点・影響・是正計画を伴うモデルドリフト要約を一気通貫で自動化・支援します。SSOや多要素認証などの堅牢なセキュリティとコラボレーション機能により、組織横断の活用も可能にします[1]。

法務領域では、予測システム・KPIモデルは、GPT‑4が模擬司法試験で上位10%のスコアを達成した事実を踏まえ、能力評価の厳密さと安全性の両立を重視します。画像入力の研究プレビュー提供状況とともに、領域固有のKPIで実用性と評価透明性を両立させます。さらに、小規模モデルから最終損失やHumanEvalの一部合格率といった指標を高精度に予測する研究に基づき、将来のモデル性能を見通すための予測手法を整備し、KPIを事前に校正可能な運用を進めます[3]。

医療、とりわけメンタルヘルスのようなセンシティブな会話では、予測システム・KPIモデルは、展開前の高難度・高リスクシナリオによるオフライン評価に加え、実運用トラフィック・自動評価・独立した臨床専門家評価の三系統で挙動を定量化し、GPT‑5で不適切な応答を65〜80%削減しました。170名以上の専門家と設計したターゲット評価では、精度と再現率のトレードオフ、評価者間一致率が71〜77%にとどまるケースや、評価ツールの進化により時系列の直接比較が難しい点も透明に共有し、方向性と進捗を追跡する安全KPIを継続的に改善します[4]。

モデル行動のガードレールとKPI設計について、予測システム・KPIモデルはModel Specを基準として公開し、挑戦的な評価プロンプト群で準拠度を測定します。最新モデルでの準拠の大幅な改善を踏まえつつ、現実世界の新事例を取り込みながら課題セットと評価を更新し続けます[5]。また、思考の連鎖を活用した強化学習による推論モデルo1‑previewは、ジェイルブレイクやエッジケースを含む安全性ベンチマークで大幅な性能向上を示し、Preparedness Frameworkに基づく事前の安全テストとレッドチーミングで改善点を検証しています[6]。

運用文脈まで含めた評価の重要性から、予測システム・KPIモデルはSWE‑bench Verifiedの導入でテストの妥当性や問題記述の明確さを高め、GPT‑4oの性能を16%から33.2%へと較正された条件で引き上げました。SWE‑benchはPreparednessにおけるモデル自律性リスク「中」の追跡評価として活用し、外部RAGやCodeRといったスキャフォルディングの有無で性能が大きく変動する事実を前提に、学習前・学習中・学習後（外部システム統合後）まで繰り返し評価します。静的データセットの限界やベンチマーク汚染の可能性も踏まえ、コミュニティとともに壊滅的リスクを経験的かつ科学的に追跡し、防御を強化します[2]。

KPIの見直しでは、予測システム・KPIモデルは、実運用上100%の正確性は達成不可能であるという前提に立ち、推測を助長する正確性一辺倒の採点から、過度に自信を伴う誤答に大きなペナルティを課し、適切な不確実性の表明・棄権には部分点を与える評価へ移行します。これにより、ハルシネーション低減の手法がより採用され、現場での安全な意思決定につながる指標設計が可能になります[7]。

安全性KPIの強化に向けて、予測システム・KPIモデルはルールベース報酬（RBR）をRLHFに統合し、簡潔なルールでモデル行動を制御します。一般性能ベンチマークを損なうことなく安全性を人手学習モデルと同等に保ちつつ過剰拒否を低減し、ルールの追加・変更にすばやく適応できる運用性を実現します。有用性と有害性のトレードオフを追跡する評価フレームワークで安全行動のKPIを継続的にモニタリングし、推論時に独自ポリシーを指定可能なgpt‑oss‑safeguardや、運用中でも動的にポリシーを更新できるSafety Reasonerを組み合わせます。安全性推論に計算資源の最大16%を割くケースも含め、画像生成やSora 2での段階的出力評価、Moderation APIの高速クラシファイアと組み合わせた多層防御を構築します[8][9]。

産業横断の実務評価として、予測システム・KPIモデルはGDPvalを用いて、米国GDPへの寄与が大きい産業から選んだ44職種に基づく1,320の実世界タスクでモデル性能を専門家が評価します。これは学術系ベンチマークやコード競技から、SWE‑BenchやMLE‑Bench、Paper‑Benchといった応用評価、さらにはSWE‑Lancerのような市場ベース評価へと広がる流れをさらに前進させるもので、裏付けに基づく将来展望の議論と長期的な改善の追跡を可能にします。現行モデルは高速・低コストである一方、ワンショット前提などの制約も明らかになっており、業界別の実務KPIに即した改善点を可視化します[10]。

こうしたエンドツーエンドのアナリティクス基盤、安全性重視の評価フレームワーク、実世界タスクに基づくベンチマークにより、予測システム・KPIモデルは法務・医療・財務を含む高影響領域においても、実務価値と安全性の両立を測定可能な指標で管理し、エコシステムと連携して継続的な改善を進めていきます[1][4][10]。

【出典】
[1] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[2] https://openai.com/ja-JP/index/introducing-swe-bench-verified/
[3] https://openai.com/ja-JP/index/gpt-4-research/
[4] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[5] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[6] https://openai.com/ja-JP/index/learning-to-reason-with-llms/
[7] https://openai.com/ja-JP/index/why-language-models-hallucinate/
[8] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[9] https://openai.com/ja-JP/index/introducing-gpt-oss-safeguard/
[10] https://openai.com/ja-JP/index/gdpval/


## 予測モデル・基盤の構築運用
予測モデル・基盤の構築運用は、法務・医療・財務といった高い信頼性が求められる産業におけるモデル活用の要件に応えるため、「予測可能に拡張できる基盤」「継続的な評価」「運用段階での安全性とガバナンス」を中核とする公式アプローチを採用しています。基盤モデルの学習には公開データとライセンスデータを用い、事前学習で獲得された広範な能力を人間のフィードバックによる強化学習（RLHF）でユーザー意図に整合させます。一方で、試験成績の多くは事前学習で規定され、RLHFがスコアを必ずしも向上させない場合があること、実務ではモデルに「質問に答える」態度を促すためのプロンプトエンジニアリングが必要となる場合があることも明確にしています[1]。GPT‑4の開発では、小規模モデルから大規模モデルの最終損失を高精度に予測する「予測可能な拡張性」を検証し、スケールを跨いで一貫して機能する学習・最適化インフラを構築しました。これは、GPT‑4が模擬司法試験で上位10%のスコアを示すなど、高信頼領域における能力の下支えとして重要です[1]。

予測モデル・基盤の構築運用は、モデルの能力を学習前・学習中・学習後（外部システム統合も含む）の各段階で繰り返し測定する評価体制を公式に採用しています。たとえばソフトウェアエンジニアリングでは、SWE‑bench Verifiedにより問題記述の明確さとテスト妥当性を担保し、同一モデルでもRAGやCodeRなどエージェントのスキャフォールドの違いで性能が大きく変動する事実を確認しました（GPT‑4oの指標は16%から33.2%へと改善）。静的データセット評価は汚染やリスク分布の偏りといった限界があるため、コミュニティと協力して評価の補完・改善を進めます[2]。

ガバナンスの共通土台として、予測モデル・基盤の構築運用は「Model Spec」をCC0で公開し、知的自由・透明性・安全性のバランスを重視した望ましい挙動の原則を明文化しました。整合性評価用の挑戦的プロンプト群を用いて準拠度を継続的に測定・改善し、最新の測定では準拠が大幅に改善しています。今後も専門家・政策立案者・一般の皆様との対話を重ね、原則・ルール・デフォルトの継続的な更新に取り組みます[3][4]。

運用段階の安全性について、予測モデル・基盤の構築運用はルールベース報酬（RBR）をRLHFに統合し、「有用性」と「安全性」のトレードオフを可視化しながら過剰拒否を抑えて安全行動を引き出す方法を採用しています。RBRはシンプルな命題やポリシー更新を迅速に反映でき、Model Specのルールと組み合わせて運用要件を精緻に実装できます[5][3][4]。また、推論時に独自の安全ポリシーを指定できるオープンウェイトの安全性推論モデル「gpt‑oss‑safeguard」を研究プレビューとして公開し、動的なポリシー更新、段階的な出力評価、マルチレイヤー防御を可能にしました。画像生成やSora 2などでは安全でない生成のリアルタイム識別・ブロックを行い、新モデル導入時には厳格なポリシーから開始し、安全推論に相応の計算資源（最近のリリースでは最大16%）を投じながら、運用リスクの理解に応じて調整するプロセスを確立しています[6]。

配備形態では、予測モデル・基盤の構築運用はデスクトップからデータセンターまでローカルで実行できるオープンウェイトの高度な推論モデル「gpt‑oss（120B/20B）」を提供し、エージェント型タスク最適化、柔軟なカスタマイズ性、安全性基盤の強化を両立します。どこでも実行できる推論基盤として、業務要件やデータ所在の制約に応じた運用設計を支援します[7]。財務・アナリティクスの現場向けには、ChatGPT Businessによる統合ワークスペースを用意し、特徴量や前処理パイプラインの生成、モデル結果の解釈、モデルドリフト検知、意思決定者向けの展開可能なインサイト作成までを一気通貫で支援します。データがデフォルトで学習に用いられない設計、SSO・多要素認証、権限・ブランドガバナンス・コンプライアンスの一元管理により、検証済みデータソースとビジネスコンテキストに基づく信頼できる分析を実現します[11]。

医療領域では、予測モデル・基盤の構築運用は医師262名（60か国）と協働し、5,000の臨床対話と4万以上のルーブリックから成るHealthBenchを公開しました。最新モデルの大幅な改善を定量化し、医師評価との一致度を測るメタ評価設計も採用しています。一方で、不十分な情報下での文脈把握や最悪時の信頼性には改善余地があることを公式に認め、データと評価を公開してコミュニティとともに継続改善を進めます[8]。メンタルヘルスや自傷・自殺、AIへの感情的依存などセンシティブな会話に対しては、Model Specの原則に基づくモデル更新を実施し、不適切応答を65〜80%削減するなど大幅な改善を達成。問題の定義、測定の開始、外部専門家との検証、リスクの軽減という段階的プロセスで安全性を高め続けます[9][3]。

法務領域では、予測モデル・基盤の構築運用はGPT‑4の模擬司法試験における上位10%のスコアといった進展を確認しつつ、事前学習に起因する統計的限界から“もっともらしい誤り（ハルシネーション）”が生じうることを前提に、推測を奨励しない評価手法や、不確実な場合は棄権させる設計を重視します。これにより、確度と説明可能性を重視した運用を実現します[1][10]。

モデルの分析容易性に向けて、予測モデル・基盤の構築運用はスパース回路を通じた解釈可能性研究を進め、少数の可解読な回路で複雑な推論を実現する手法の可能性を実証しました。将来のシステムをより分析・デバッグ・評価しやすくするため、運用に適した効率的な訓練手法や既存モデルからのスパース回路抽出の検討を続けます[12]。データ基盤でも、DALL·E 2学習前の大規模ミティゲーションとして、暴力・性的画像の除外、バイアス抑制の再重み付け、重複画像の削除による“吐き戻し”防止、最近傍探索を用いた能動学習の多数GPUスケール化を実施し、同一ハイパーパラメータの対照実験で有効性を検証しました[13]。

応用面では、予測モデル・基盤の構築運用はサイバー防御企業と連携し、強化ファインチューニング（RFT）を活用した検知パイプラインを構築。アナリストの作業負荷を80%削減し、対応能力を3倍に拡張、脅威対応時間を数時間から数分に短縮しました。正確性だけでなく説明品質も評価するスコアリングを設計し、RFTのループで人間の判断を学習データ化することで曖昧なエッジケースへの一貫性を高めています[14]。

予測モデル・基盤の構築運用は、法務・医療・財務の各産業における予測モデルの構築・運用に必要な「拡張性の高い基盤」「ライフサイクル全体の評価」「運用で効く安全性とガバナンス」を総合的に提供し、ローカル実行性やオープンな評価資産を含むエコシステムを通じて、現実世界の価値に結び付く改善を継続していきます[2][3][7][8]。

【出典】
[1] https://openai.com/ja-JP/index/gpt-4-research/
[2] https://openai.com/ja-JP/index/introducing-swe-bench-verified/
[3] https://openai.com/ja-JP/index/introducing-the-model-spec/
[4] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[5] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[6] https://openai.com/ja-JP/index/introducing-gpt-oss-safeguard/
[7] https://openai.com/ja-JP/open-models/
[8] https://openai.com/ja-JP/index/healthbench/
[9] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[10] https://openai.com/ja-JP/index/why-language-models-hallucinate/
[11] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[12] https://openai.com/ja-JP/index/understanding-neural-networks-through-sparse-circuits/
[13] https://openai.com/ja-JP/index/dall-e-2-pre-training-mitigations/
[14] https://openai.com/ja-JP/index/doppel/


## 法務向けAIモデル: 性能・評価
法務向けAIモデル: 性能・評価は、法務分野のAI活用において実務で信頼できる性能と厳格な安全性評価を両立することを公式方針として掲げ、学術ベンチマークに加えて実世界タスクでの有用性を測る評価、独立した第三者による検証、そしてハルシネーション（誤生成）を抑制する評価設計を組み合わせ、法務ワークフローに求められる高い基準を満たすモデルづくりを推進します[1][2][3][4][5]。この方針のもと、法務向けAIモデル: 性能・評価は評価結果を透明に開示し、現場での信頼性と安全性を軸に継続的な改善を進めます[1]。

法務向けAIモデル: 性能・評価は、経済的価値のある実世界タスクに対するモデルの有用性を定量化する新たな評価手法「GDPval」を導入しました。GDPvalは、米国GDPへの寄与上位産業から抽出した44職種・1,320のタスクで専門家が成果物を評価し、速度やコストなど運用面も含めてモデルが現実の仕事にどれだけ役立つかをエビデンスに基づき可視化します。私たちはこの枠組みにより、推測ではなく裏付けのある情報にもとづいて改善を議論し、長期にわたって実務性能の進展を追跡します[2]。

法務向けAIモデル: 性能・評価は、法務に特化したパートナーシップとしてHarveyと連携し、法務業務向けにトレーニングされたカスタム判例法モデルを構築しました。文書作成、複雑な訴訟シナリオへの回答、数百の契約にまたがる重大な矛盾の特定など、単一呼び出しを超える高度な法的推論を支援し、弁護士による評価では97%が従来のGPT‑4よりもこの判例法モデルを好み、ハルシネーションの抑制が確認されています。さらに、初期検証としてRedditのr/legaladviceから抽出した100件の質問にGPT‑3で回答を生成し、弁護士がレビューしたところ、86件が編集なしでクライアントに送付可能と判断されるなど、法務応答の実用性に関する実データを伴う評価も行いました[6]。

法務向けAIモデル: 性能・評価は、モデルの安全性と性能を体系的に測定・公開するためEvaluations Hubを運用し、不許可コンテンツや敵対的プロンプト（ジェイルブレイク）への耐性、誤情報（ハルシネーション）、命令階層などの評価結果とカテゴリ内訳を提示しています。ジェイルブレイク評価では学術ベンチマーク「StrongReject」と人間のレッドチーミング由来のプロンプトの双方で耐性を測定し、ハルシネーション評価ではSimpleQAおよびPersonQAで回答精度を評価します。2025年8月15日には、GPT‑5系の結果やProduction Benchmarks、StrongRejectの詳細を含む更新を実施しました[1]。あわせて、フロンティアAIの能力とリスクを見極めるため、独立評価・方法論レビュー・専門家（SME）プロービングの三つの形態で第三者評価を活用し、展開可否などの意思決定に反映、機密性と正確性のレビュー後には詳細研究の公開を支援するなど、外部の知見を安全対策に組み込みます。これらの枠組みはGPT‑5にも適用しています[3]。

法務向けAIモデル: 性能・評価は、ハルシネーションの根本的要因の一つが評価設計にあると認識し、正確性のみを重視して推測を促す従来設計を見直します。不確かなら棄権する姿勢を評価に組み込み、推測ではなく不確実性の誠実な開示を良しとする原則をModel Specにも明示して運用します[4]。また、標準的な学術ベンチマークの有用性を認めつつ、それらが現実世界の有用性を必ずしも反映しないことを踏まえ、実務評価と併用する方針を堅持します。GPT‑4.5の研究プレビューでも、学術指標での改善に加え、実世界ユースケースでの機能把握を重視しています[5]。加えて、ベンチマーク／フレームワーク「OpenAI Evals」を整備し、将来システムの性能予測と社会への明確な指針提示に資する評価手法の開発を進めています[9]。

法務向けAIモデル: 性能・評価は、自社の法務関連業務にもAIを適用し、性能と運用効果を測定しています。社内の契約処理のボトルネックを解消するために「契約書データエージェント」を開発し、PDF・スキャン・写真から契約条項を構造化、非標準条項を理由付きでハイライトする機能によりレビュー時間を約半減しました。夜間バッチによる解析運用へ移行し、チーム増員なしで処理量を拡大しつつ、機械的抽出は自動化し最終判断は人間が行う原則で運用しています[7]。

法務向けAIモデル: 性能・評価は、クローズドモデルのみならずローカルでも実行可能なオープンウェイトモデルにも高度な安全基準を適用し、モデルごとのSystem Card公開や総合的な安全性テストを通じ、法務ワークフローでも安全基盤の徹底と透明性を確保します[8]。以上の取り組みを、法務・医療・財務などの業界別モデル活用・評価の実践とあわせて進めることで、法務向けAIモデル: 性能・評価は、実務で信頼できる品質、厳密な安全性、そして継続的な改善の透明性を提供していきます[1][2][3][4][5][6][7][8][9]。

【出典】
[1] https://openai.com/ja-JP/safety/evaluations-hub/
[2] https://openai.com/ja-JP/index/gdpval/
[3] https://openai.com/ja-JP/index/strengthening-safety-with-external-testing/
[4] https://openai.com/ja-JP/index/why-language-models-hallucinate/
[5] https://openai.com/ja-JP/index/introducing-gpt-4-5/
[6] https://openai.com/ja-JP/index/harvey/
[7] https://openai.com/ja-JP/index/openai-contract-data-agent/
[8] https://openai.com/ja-JP/open-models/
[9] https://openai.com/ja-JP/index/gpt-4-research/


## 法務向けAIモデル: 開発・連携
法務向けAIモデル: 開発・連携は、安全性・整合性・統合容易性の三本柱で、法務領域におけるAIモデルの開発と実務への連携を推進します。法務向けAIモデル: 開発・連携は、OpenAIとHarveyの提携を軸に、法務・税務・金融分野に特化した安全な生成AIの進化を実装段階まで引き上げ、文書作成、複雑な訴訟シナリオの質疑応答、数百件に及ぶ契約間の重大な矛盾の特定といった高度タスクを支援するカスタム判例法モデルを提供します。Harveyはこの1年でチーム100名超、収益10倍超、シリーズBで8,000万ドルを調達（評価額7億1,500万ドル）するなど事業基盤を大きく拡大しており、当該領域の社会実装が着実に進んでいます[1]。法務向けAIモデル: 開発・連携は、この共同開発でまずデラウェア州の判例法から着手し、米国全体へ拡張。約100億トークンのドメインデータを追加学習した結果、10の大手法律事務所とのサイドバイサイド比較では、弁護士の97%が同一質問に対しGPT‑4よりカスタム判例法モデルを選好するなど、出典付きで高い関連性・正確性とハルシネーション抑制を確認しました[1][9]。

法務向けAIモデル: 開発・連携は、業界特化モデルの品質と安全性を制度面でも担保するため、望ましいモデルの振る舞いを定めたModel Specを公開し、開発者とエンドユーザー双方の実装を支援します。Model Specは、ユーザー目的の達成支援に加え、適用法の遵守、危険情報の不提供、クリエイターの権利尊重、プライバシー保護、NSFW不提供といったルール、さらに不確実性の表明、適切なツール選択、明確化質問などのデフォルト行動を明示し、知的自由を尊重しつつ必要なガードレールを維持する指針を提供します[2][3]。

法務向けAIモデル: 開発・連携は、規制のある重要ワークフローへの統合を自ら実地で進めています。社内「契約書データエージェント」では、PDFやスキャン画像から条項を構造化し、非標準条項を理由付きでハイライトすることでレビュー時間を半減。夜間バッチでのデータ解析へ運用を移しつつ、機械的作業は自動化し、最終判断は人間に委ねる原則を徹底することで、チームの増員なくスケールを実現しました。これは、法務を含む規制対象の重大業務における、専門家とインテリジェントシステムの協働モデルの青写真です[4]。

法務向けAIモデル: 開発・連携は、導入形態の多様なニーズに応えるため、ローカル環境で実行可能なオープンウェイト推論モデル群も提供します。gpt‑ossおよびgpt‑oss‑safeguard（120B/20Bパラメーター）はエージェント型タスクに最適化され、柔軟なカスタマイズ性とカスタム安全性ポリシーの適用、総合的な安全性テストおよびModel System Cardに基づく高度な安全基準を備え、法務ユースケースの要件に即した統合を後押しします[5]。

法務向けAIモデル: 開発・連携は、モデルの能力とリスクを客観的に把握するため、第三者による外部評価を体系化。独立評価、方法論レビュー、専門家によるSMEプロービングを組み合わせ、評価の透明性、機密情報の保護、適切な報酬、セキュリティ管理のバランスを確保します。あわせて、組織的レッドチーミング、米国CAISI・英国AISIとの協力、外部諮問グループとの連携など、多面的な専門知を取り込むエコシステムを強化しています[6]。

法務向けAIモデル: 開発・連携は、機微情報の取扱いにおいて、AIとの対話が特権的コミュニケーションに匹敵する高い保護を受けるべきだと考え、その実現を政策立案者に提唱しています。同時に、お客様のデータを当社従業員からさえ守る高度なセキュリティ機能を実装し、深刻な乱用の有無は自動化されたシステムで監視、生命・安全に関わるリスクや大規模サイバーインシデントなど最重大ケースは人間のレビューにエスカレーションする原則を運用しています[7]。

法務向けAIモデル: 開発・連携は、知的財産に関しては「幅広いアクセス・協力・安全性」の原則を掲げ、特許はイノベーション支援と使命遂行に資する防御的目的に限定して用いることを誓約します。第三者からの脅迫や請求がない限り、特許を攻撃的に用いない方針を堅持します[8]。

法務向けAIモデル: 開発・連携は、現場の実装を加速する基盤として、ChatGPT、AgentKit、ChatGPT Atlasを通じたAIエージェントの構築・展開を支援します。企業データはモデル改善に用いず、暗号化、MFA、SAML SSOに対応し、GDPRやCCPAなど各種プライバシー規制への準拠をサポートするエンタープライズグレードのセキュリティで、法務ドメインの高精度なタスク実行と堅牢なガバナンスを両立します[10]。

法務向けAIモデル: 開発・連携は、パートナーとの共同開発、行動指針（Model Spec）、外部評価、オープンウェイトモデル、強固なプライバシー・安全対策、そしてエージェント基盤の整備を通じて、法務向けAIモデルの開発と現場統合を、安全性・整合性・統合容易性の三本柱でこれからも着実に前進させます[1][2][3][4][5][6][7][8][10]。

【出典】
[1] https://openai.com/ja-JP/index/harvey/
[2] https://openai.com/ja-JP/index/introducing-the-model-spec/
[3] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[4] https://openai.com/ja-JP/index/openai-contract-data-agent/
[5] https://openai.com/ja-JP/open-models/
[6] https://openai.com/ja-JP/index/strengthening-safety-with-external-testing/
[7] https://openai.com/ja-JP/index/teen-safety-freedom-and-privacy/
[8] https://openai.com/ja-JP/approach-to-patents/
[9] https://openai.com/index/harvey/
[10] https://openai.com/ja-JP/solutions/use-case/agents/


