# データガバナンス・プライバシー（モデル学習・利用）

## 概要


### 基本姿勢
OpenAIは「データ最小化・ユーザーの選択・法令遵守・透明性」を柱に、モデルの学習と利用の全工程でプライバシーを最優先します。OpenAIはBusiness/Enterprise/APIのデータを既定でモデル学習に使用せず、消費者向けでは明確なオプトアウトとアクセス・削除・移転などの権利行使手段を提供します。OpenAIはModel Specと使用ポリシーに基づき、違法行為やプライバシー侵害的用途を拒否し、ユーザーデータの販売や広告ターゲティングを行いません。

### 重点的取り組み
OpenAIはデータレジデンシーと高度なデータコントロール（地域内処理、必要に応じたサーバー非保存、ゼロデータ保持）を拡充し、AES‑256/TLS 1.2+、EKM、SSO/MFA/SCIM/RBAC、監査ログなど技術・組織的対策を強化します。OpenAIはSOC 2 Type 2、ISO 27001/27017/27018/27701、CSA STAR等の第三者評価に継続適合しつつ、透明性レポートやKodex法的窓口、システムカード/C2PA透かし、gpt‑oss‑safeguard等の安全技術で多層防御を実装します。OpenAIは自動検知＋人間レビューのモデレーションを運用し、重大リスクのみ厳格な人間審査へエスカレーションします。

### 重要事実
OpenAIは2025年に欧州を含む世界各地域でデータレジデンシー提供を拡大し、Enterprise/ APIで地域内処理とログ非保存の選択肢を提供しました。OpenAIはAPIデータを原則最大30日（不正対策等）保持し、ゼロデータ保持オプションを提供、ファインチューニングデータは顧客専用で他用途・他顧客に不使用です。OpenAIは2025年10月29日に使用ポリシーを改訂し、無断の顔認識DB、公的空間での遠隔生体認証、同意のない肖像の本物誤認利用等を明確に禁止し、Business/Enterprise/APIのデータは既定でモデル学習に不使用であることを再確認しました。


## アップロードデータの取扱い
アップロードデータの取扱いは、ユーザーが当社サービスにアップロードまたは送信するデータの最小限利用、ユーザーによる明確なコントロール、強固な技術的保護、透明性ある手続の四本柱で、モデル学習とサービス提供におけるプライバシー保護を徹底します[1][2][3]。アップロードデータの取扱いは、非APIサービス（ChatGPTやDALL·Eなど）では送信されたデータがモデルやサービスの改善に用いられる場合があることを明示し、プライバシーリクエストポータルから改善目的での利用をオプトアウトできる手段を提供します。一方、APIについてはお客様がAPIを通じて送信したデータをモデルの学習・改善に使用せず、必要な場合に限り専用フォームによる明示的なオプトインを通じて共有に同意いただく設計です。ビジネス向けプランおよびAPIでは、お客様が明示的に共有を許可しない限り学習利用は行いません。また、当社はユーザーコンテンツをマーケティング目的で第三者と共有せず、業務委託先のサブプロセッサー一覧を公開しています[1][3]。

アップロードデータの取扱いは、ビジネス顧客向けにデータレジデンシー機能を提供し、会話、アップロードファイル、カスタムGPT、画像生成の成果物などのコンテンツを選択地域内に保存します。さらに、エンタープライズで高度なデータコントロールを有効化したAPIプロジェクトでは、地域を指定してプロジェクトを作成でき、該当プロジェクト経由のリクエストは地域内で処理され、モデルのリクエストや応答は当社サーバーに保存されません[3]。APIプラットフォームはサービス提供と不正利用の特定のため、特定のエンドポイントを除き入出力データを最大30日間安全に保持します[4]。

アップロードデータの取扱いは、保存時にAES-256、送信時にTLS 1.2以上の暗号化を実施し、Enterprise Key Management（EKM）によりお客様自身の鍵を保存データ（ユーザーコンテンツ）に適用できる仕組みを提供します。GDPRやCCPAを含む各種プライバシー法への準拠を支援し、CSA STAR、SOC 2 Type 2、ISO/IEC 27001・27017・27018・27701といった認証・基準にも対応しており、APIプラットフォームはSOC 2 Type 2の審査を経て認証されています[3][4]。ファインチューニングで送信されるプロンプト・コンプリーションペアは、お客様専用のモデル改善のために用いられ、他のお客様に提供・開示されず、他のモデルの学習にも使用しません。これらのデータはお客様がファイルを削除するまで保持されます[4]。

アップロードデータの取扱いは、ユーザーによる管理権限を尊重します。ユーザーは自身のコンテンツ（プロンプト、生成画像、アップロード、APIレスポンスなど）の削除をリクエストでき、通常はリクエスト受領から最大30日で処理します。加えて、アクセス、削除、訂正、移転（データポータビリティ）、取扱い制限、同意撤回、異議申立て、監督当局への苦情申立てなどの権利を、アカウント設定のほかprivacy.openai.comまたは指定メールアドレスから行使できます。生成AIの性質上、出力が事実と異なる場合にご自身に関する不正確な情報の訂正または削除をリクエストする手段も提供しています[1][2]。

安全で責任ある利用のために、アップロードデータの取扱いはプライバシーポリシーに基づいて自動化技術と人による審査を組み合わせ、サービス上のアクティビティを監視し、規約・ポリシー違反の可能性があるコンテンツに適切に対応します[5]。政府機関からユーザーデータに関するリクエストがあった場合には、すべてのリクエストを丁寧に確認し、プライバシー・安全性の保護と適用法令の遵守の両立を図ります。法的手続はKodexポータルで受け付け、継続的に透明性レポートを公表しています[6]。さらに、裁判所命令に基づくデータ提供が必要となる場合でも、当該コンテンツは安全なシステムに隔離しリーガルホールドの下で保管し、法的義務の履行に必要な場合に限って監査済みの小規模な法務・セキュリティチームがアクセスします。閲覧は厳格な法的プロトコル下の安全な環境に限定し、個人識別情報の削除や匿名化などの追加措置を講じます[7]。

アップロードデータの取扱いは、以上の取り組みにより、ユーザーのデータに対する明確な選択肢と高度な保護、そして透明性の高い運用を継続的に強化していきます[1][2][3]。

【出典】
[1] https://openai.com/ja-JP/consumer-privacy/
[2] https://openai.com/ja-JP/policies/privacy-policy/
[3] https://openai.com/ja-JP/index/expanding-data-residency-access-to-business-customers-worldwide/
[4] https://openai.com/ja-JP/enterprise-privacy/
[5] https://openai.com/ja-JP/transparency-and-content-moderation/
[6] https://openai.com/ja-JP/trust-and-transparency/
[7] https://openai.com/ja-JP/index/fighting-nyt-user-privacy-invasion/


## オプトイン/オプトアウト案内
オプトイン/オプトアウト案内は、当社（OpenAI）のデータガバナンスとプライバシーの透明性を最重視し、規約・ポリシー上、ユーザーのコンテンツに関する権利と当社の取扱目的を明確に示します。オプトイン/オプトアウト案内は、適用法の範囲でユーザーがインプットの所有権限を保持し、アウトプットについての権利を有すること、当社が有するアウトプットに関する権限はユーザーに譲渡すること、また一般的なAIの性質上アウトプットが特有のものではない場合があることを、規約に基づきわかりやすく説明します[2][3]。

オプトイン/オプトアウト案内は、当社がユーザーのコンテンツを本サービスの提供・維持・開発・改善、適用法の遵守、ならびに規約・ポリシーの履行請求のために利用する旨を、利用規約で明示します。これにより、モデルの開発・改善やプロダクト運用を含むデータ利用の目的を、ユーザーのみなさまに明確に提示します[2][3]。

あわせて、オプトイン/オプトアウト案内は、サービス上のアクティビティの監視をプライバシーポリシーに基づいて実施し、分類器・リーズニングモデル・ハッシュマッチング・ブロックリスト等の自動化技術と人による審査を組み合わせ、規約やポリシーに違反する可能性のあるコンテンツに対応します。違反が確認された場合には、アカウントの制限、コンテンツ共有の制限、検索結果のブロック、特定GPTの公開設定の制限、フォーラム管理などの措置を講じます[4]。

さらに、オプトイン/オプトアウト案内は、使用に関するポリシーを継続的に更新し、なりすまし、政治運動・選挙干渉、機密性の高い領域での人間の確認のない重大な意思決定、重要インフラ、金融活動・与信、重要な行政サービス、製品安全コンポーネント、国家安全保障、法執行など、リスクの高い領域における禁止行為を具体化してきました。2022年11月にはアプリケーション登録要件を撤廃し、自動的な方法と手動による方法を組み合わせてポリシー違反を監視する運用へ移行したことを変更ログで公表するなど、施行と透明性も強化しています[1]。

加えて、オプトイン/オプトアウト案内は、当社が上記の目的でユーザーのコンテンツを使用しうることを明示したうえで、当社モデルの学習にお客様のコンテンツを使用してほしくない場合には、ヘルプセンターの記事の手順に従って「使用停止（オプトアウト）」を申請できる仕組みを提供します。オプトアウトを行った場合には、特定の目的にそって処理される能力が場合によっては制限されうることも、あわせてご案内します[2][3]。ビジネス向け製品については、オプトイン/オプトアウト案内は「データ非学習化」を導入し、企業ユーザーのワークスペースでの利用データがモデル学習に使われない運用を可能にする設計を提供しています（ChatGPT Business のセキュリティ重視の取り組みの一環）[5]。

オプトイン/オプトアウト案内は、これらの運用とあわせて関連ポリシーの整備・更新を継続し、データ利用に関する情報提供の透明性を今後も一貫して維持します[1][4]。

【出典】
[1] https://openai.com/ja-JP/policies/usage-policies/
[2] https://openai.com/ja-JP/policies/row-terms-of-use/
[3] https://openai.com/ja-JP/policies/terms-of-use/
[4] https://openai.com/ja-JP/transparency-and-content-moderation/
[5] https://chatgpt.com/ja-JP/business/ai-for-product-management/


## セキュリティ・法令遵守
セキュリティ・法令遵守は、OpenAIのモデルの学習と利用のあらゆる局面でセキュリティ、プライバシー、そして法令遵守を最優先するという公式見解を掲げ、お客様・ユーザーのデータ、モデル、製品を保護することで信頼を構築し、GDPRやCCPAなどのプライバシー法への対応を支援しながら、対策を継続的に強化します[3]。セキュリティ・法令遵守は、ユーザーが自身のデータ共有可否を選択できる仕組みと、消費者プライバシーに関する明確な説明を提供します[3]。

セキュリティ・法令遵守は、モデルの望ましい振る舞いを定めるModel Specを公開し、「適用法を遵守する」という基本ルールの下、違法行為の促進・助長・関与を行わない運用を徹底します。状況依存で違法性判断が複雑になり得る場合にも慎重に対処し、利用規約に反する誤用が確認された際にはアカウント措置を講じます[2]。あわせて、使用に関するポリシーは2025年10月29日に改訂し、無断の安全性テストや安全対策の回避、同意のない顔認識データベース、公的空間でのリアルタイム遠隔生体認証、同意のない肖像（画像・声を含む）の本物と誤認させる使用、社会的スコアリングや機微属性の推測、教育・職場での感情推測（医療・安全上の必要を除く）、プロファイリングのみに基づく犯罪リスク推測など、プライバシー侵害や個人の権利を損なう行為を明確に禁止しています[1]。

セキュリティ・法令遵守は、コンプライアンスと第三者評価において、OpenAIのAPI、ChatGPT Enterprise、ChatGPT Team、ChatGPT EduがSOC 2 Type 2レポートの対象であることを示し、独立監査人による評価を通じてセキュリティと機密性の業界標準への適合を確認しています。DPA（データ処理補遺契約）の締結に応じ、GDPRやCCPAなどの法令遵守を支援するとともに、ビジネス向け製品とAPIに対して定期的な第三者侵入テストを実施し、HIPAA等の規制・業界・契約要件へのお客様の対応を支援します。これらの取り組みはセキュリティポータルでご確認いただけます[3]。また、ChatGPT BusinessおよびEnterpriseはSOC 2 Type 2に加えてISO 27001、27017、27018、27701の認証を取得しており、Enterpriseプランのコンテンツはモデル学習に使用しない設計で提供し、管理機能としてSAML SSOやドメイン認証（Business/Enterprise）、SCIM・ロールベースのアクセス制御・EKM（いずれもEnterprise）を備えています[11]。

セキュリティ・法令遵守は、技術的・運用的管理として、保存時のAES‑256および転送時のTLS 1.2以上による暗号化、Enterprise Key Management（EKM）によるお客様自身の鍵管理、データ保持期間の制御機能、要件を満たす組織に対するAPIプラットフォームでのゼロデータ保持ポリシーの選択肢を提供します。さらに、ゼロトラストと多層防御を採用した設計段階からのセキュリティ組込み、サプライチェーンリスク対応、エンドポイント・インフラ・ネットワーク・アプリケーションの多層コントロール、24時間365日のオンコール体制による自動アラートと手動調査、継続的な監視とテストでお客様データを保護します[10][3]。

セキュリティ・法令遵守は、生成AIのリスクに対して多層的なモニタリングと執行を行い、ユーザーからの規約違反の可能性があるコンテンツの報告機能を提供し、自動システムと人間のレビューで利用傾向を監視します。違反コンテンツの削除とペナルティ付与、通知と意見提出の機会を備えたプロセスを運用し、児童の安全を最優先としてCSAM（児童性的虐待資料）の予防・検出・報告、責任あるデータセット調達、NCMECとの提携、法的制限に準拠したレッドチーミング、全ての入出力（ファーストパーティ、サードパーティ、API、Enterprise）での厳格なスキャンを実施します[9]。同時に、使用に関するポリシーでも未成年者の搾取や危害を助長する利用を明確に禁止し、プライバシー侵害的な用途を排除します[1]。

セキュリティ・法令遵守は、ポリシー遵守やモデレーションの実装を支援するため、開発者が定めるポリシーに基づきコンテンツを分類できるオープンウェイトのgpt‑oss‑safeguardモデルを提供し、主に分類用途に推奨されるこれらのモデルについて安全性評価の結果も公表しています[8]。このような技術的手段と運用ポリシーを組み合わせ、モデル利用時のセキュリティと法令遵守を強化します。

セキュリティ・法令遵守は、透明性と説明責任を重視し、政府からのデータ要求や児童安全、コンテンツモデレーションと施行、異議申立ての方法、企業向けのデータセキュリティ・プライバシー・コンプライアンスへの取り組みをまとめたリソースを公開しています。EUデジタルサービス法（DSA）に基づく透明性レポートや第16条通知、定性的情報も提供し、企業向けには「信頼と透明性」ページおよび信頼ポータルで関連ドキュメントにアクセスいただけます[5]。また、サイバー・レジリエンス強化、プロンプトインジェクションといった最前線の課題、責任ある開示、インシデント対応の知見など、セキュリティに関する研究・インシデント・ガイダンスを継続的に公表しており、2025年の各種発信（例：「Strengthening cyber resilience as AI capabilities advance」「Mixpanel セキュリティインシデント：OpenAI ユーザーが知っておくべきこと」「Understanding prompt injections: a frontier security challenge」「Aardvark が登場」）も含め、最新情報を随時共有しています[4][12]。

セキュリティ・法令遵守は、プライバシーポリシーに基づき、個人データを紛失・不正利用・不正アクセス・漏洩・改ざん・破壊から保護するため商業上合理的な技術的・運用的・組織的措置を講じる一方、インターネットや電子メール通信の完全性に関する一般的な限界、18歳未満の利用に保護者または後見人の許諾が必要であること、当社システムから個人データを適切と認める場合に削除し得ること、米国内の州データプライバシー法に基づく追加開示事項についても明示しています[6]。ユーザープライバシーを巡る法的対応では、ニューヨーク・タイムズによる大規模な会話データ提出要求に対し、プライバシー保護とセキュリティ慣行に反するとして強く異議を唱え、アクセス権を雇用された技術コンサルタントに限定し、厳格な法的プロトコルの下で安全な環境における限定的閲覧、データの匿名化・個人識別情報の削除などの保護措置を講じ、進捗や影響に関する重要な更新を透明性をもって公表しています[7]。

セキュリティ・法令遵守は、コミュニティからのフィードバックを取り入れながらModel Specの更新やモデル動作を形成する研究の進捗を定期的に共有し、安全性と法令遵守を中核に据えたガバナンスを継続的に改善していきます[2][7]。

【出典】
[1] https://openai.com/ja-JP/policies/usage-policies/
[2] https://openai.com/ja-JP/index/introducing-the-model-spec/
[3] https://openai.com/ja-JP/security-and-privacy/
[4] https://openai.com/ja-JP/news/security/
[5] https://openai.com/ja-JP/trust-and-transparency/
[6] https://openai.com/ja-JP/policies/privacy-policy/
[7] https://openai.com/ja-JP/index/fighting-nyt-user-privacy-invasion/
[8] https://openai.com/ja-JP/index/gpt-oss-safeguard-technical-report/
[9] https://openai.com/ja-JP/index/sora-system-card/
[10] https://openai.com/ja-JP/business-data/
[11] https://openai.com/ja-JP/business/chatgpt-pricing/
[12] https://openai.com/ja-JP/index/introducing-aardvark/


## ダッシュボード・可視化自動化
ダッシュボード・可視化自動化は、データガバナンスとプライバシーを中核に据えながら、現場の意思決定に直結するダッシュボードと可視化の自動化をエンドツーエンドで提供します。ChatGPT Businessのデータサイエンス＆アナリティクス向けソリューションを基盤に、地域別売上（通貨と会計週で正規化）、コホートやプラン階層別のリテンション、直近3か月のローリング離脱率とキャンペーン支出の重ね合わせ、LTVやNRRなど複数ソースのKPIを統合し、外れ値や大きな変動を自動で強調するストーリーボードを生成します。出力は「地域別成長」「リテンション要因」「収益安定性」といったテーマごとに整理され、サマリーチャート、トレンド注記、経営層レビュー向けの要点までを自動生成し、.pptxデッキおよびダッシュボード取り込み用JSONスキーマとしてエクスポートできます。さらに、GPTとデータウェアハウス／BI／ストリーミングの各種コネクター、コラボレーション機能を備えた統合ワークスペース上で、特徴量生成や前処理パイプライン、モデル結果の解釈から「展開可能なインサイト」までを自動化し、モデル利用から意思決定までの可視化を加速します[1]。あわせて、スプレッドシートやCSVのアップロード、ライブデータソース接続、Canvasによるインタラクティブ編集と視覚化、APIプラットフォームやChatKitを通じたアプリへのレポート／ダッシュボードの埋め込みにも対応し、分析からレポーティングまで一気通貫の運用を実現します[8]。o3およびo4‑miniモデルのツール連携により、ウェブからのデータ取得、Pythonによる予測・グラフ生成、要因説明までを連続実行し、例えば「昨年比のエネルギー使用量見込み」のような問いにも短時間で可視化付きの回答を提示します[9]。

ダッシュボード・可視化自動化は、可視化の自動化を意思決定の現場にまで拡張します。社内サポート運用では、パターンを示すダッシュボードと平易な言葉で深掘りできる会話型インターフェースを統合したリサーチアシスタントを導入し、何百万件ものチケットを製品分野・テーマに分類したチャート、未加工チケットからの要約やカスタムレポート生成を一体化。トレンドの把握と理由の理解をひとつのワークフローで結び、非技術者でも可視化に基づく迅速な意思決定を可能にしています[2]。

ダッシュボード・可視化自動化は、製品レベルでプライバシーと統制を徹底します。ChatGPT Enterpriseの方針に基づき、お客様コンテンツをモデル学習に利用しない設計を提供し、SAML SSO、ドメイン認証、管理コンソール、「GPTの分析と管理」などの管理機能、SOC 2 Type 2やISO 27001/27017/27018/27701等の認証、SCIM、エンタープライズキー管理、ロールベースのアクセス制御を備え、SSOや多要素認証と合わせて安全な可視化運用と利用状況の可視化を支えます[3]。

ダッシュボード・可視化自動化は、自動化された判断の「見える化」を重視します。Doppelの事例では、各自動削除にAI生成の正当性（理由）を付与し、顧客が「何が、なぜ」行われたのかを即座に理解できるようにしました。これにより、チームは迅速な対応に自信を持ち、社内外のステークホルダーへの説明責任を可視的に果たせます[4]。また、契約書データエージェントでは、PDFやスキャン画像から条項を構造化し、非標準条項を理由付きでハイライトしてレビュー時間を短縮。夜間の自動処理で規模を拡大しつつ、最終判断はレビュー担当者に委ねる原則を貫いています[5]。

ダッシュボード・可視化自動化は、品質管理と運用ガバナンスを可視化します。Agents SDKでステップレベルのトレースと監視、実行のリプレイやツール呼び出しの検査、即時デバッグを実装し、Responses APIでトーン・正確性・ポリシー遵守の分類を強化。Realtime APIによる音声サポートとともに、評価ダッシュボードで品質を測定・可視化し、時間経過に沿った改善を一元管理します[10]。

ダッシュボード・可視化自動化は、安全性と責任を継続的改善の柱と位置づけ、子どもの安全、個人情報、ディープフェイク、バイアス、選挙など主要課題に取り組みます。モデルと製品のライフサイクル全体でのテスト、レッドチーミング、システムカードの公開を通じ、リスクの予測・評価・防止を進めるとともに[6]、透明性とコンテンツモデレーションでは、分類器・リーズニングモデル・ハッシュマッチング・ブロックリスト等の自動検知とユーザー報告、人による審査を組み合わせ、アカウント制限・通知、共有や検索結果の制限、GPTの公開設定の制御、フォーラム管理などの措置を明確に運用します[7]。

これらの取り組みにより、ダッシュボード・可視化自動化は、組織横断の統合ワークスペースとモデルのツール連携を基盤に、データ分析から可視化・ダッシュボード化、品質評価、説明可能性の提示までを自動化し、セキュアに運用する実践を確立しています[1][2][3][4][5][6][7][8][9][10]。

【出典】
[1] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[2] https://openai.com/ja-JP/index/openai-research-assistant/
[3] https://openai.com/ja-JP/business/chatgpt-pricing/
[4] https://openai.com/ja-JP/index/doppel/
[5] https://openai.com/ja-JP/index/openai-contract-data-agent/
[6] https://openai.com/ja-JP/safety/
[7] https://openai.com/ja-JP/transparency-and-content-moderation/
[8] https://openai.com/ja-JP/solutions/use-case/data-analysis/
[9] https://openai.com/ja-JP/index/introducing-o3-and-o4-mini/
[10] https://openai.com/ja-JP/index/openai-support-model/


## デフォルトとプラン別方針
デフォルトとプラン別方針は、OpenAIがデータガバナンスとプライバシーの観点から、個人利用と組織利用を明確に設計し分けている点を重視します。個人向けのFree・Plus・Proは、あらかじめ定義された標準の既定設定で機能を提供し、法人向けのBusiness・Enterpriseは、セキュリティ、コンプライアンス、データプライバシーに配慮した機能を備え、要件に応じてカスタム設定として提供される構成です[1][2][3]。

デフォルトとプラン別方針は、個人向けプランにおいてモデル利用の可用性がデフォルトで明示されていることを評価します。たとえば、GPT‑4.5はProで「はい」、無料版とPlusでは「いいえ」、OpenAI o3はPlusで「標準」、Proで「無制限*」、o3 proは個人プランでは「いいえ」、そしてOpenAI o4‑miniはPlus・Proで「無制限*」、無料版は「いいえ」と定義されています。こうした既定の提供条件により、個人ユーザーは分かりやすい前提条件のもとでモデルを利用できます[4][5]。

一方で、デフォルトとプラン別方針は、法人向けのBusinessおよびEnterpriseにおいて、GPT‑4.1、GPT‑4.5、OpenAI o3、OpenAI o3 pro、OpenAI o4‑miniなどの提供が「カスタム設定**」として提示され、組織のポリシーや利用要件に合わせた柔軟な構成が可能であるプラン別方針を確認しています。これらの法人向けプランは、セキュリティやコンプライアンス対応とともに、データプライバシーへの配慮を強化した構成として提供されます[6][1]。加えて、デフォルトとプラン別方針は、Businessプランにおける「データをモデル学習に利用しない（データ非学習化）」、多要素認証（MFA）、シングルサインオン（SSO）の採用を重視し、業務ワークスペースでの安全な利用と共同作業を支える実装を評価しています[7][8]。

API運用に関して、デフォルトとプラン別方針は、Enterprise向けに「優先処理」を提供し、service_tierパラメータで「Default」と「priority」を用途別に使い分けられる設計、ならびに優先処理がSLA対象として運用され、目標未達時にEnterprise契約の顧客へサービスクレジットを提供するガバナンスを高く評価します[9]。

デフォルトとプラン別方針はさらに、エンタープライズ連携の実例として、Doppelとの協働で強化ファインチューニング（RFT）に人間のレビュー結果を学習データとして記録し、フィードバックループに組み込む運用、そして正確性だけでなく説明の品質も評価対象とする採点設計によって、学習プロセスの透明性と一貫性を高めた取り組みを重視します[10]。

総じて、デフォルトとプラン別方針は、個人利用には既定の標準設定を、組織利用にはカスタム設定と強化されたセキュリティ／データプライバシー機能を組み合わせるというプラン設計によって、利用規模に応じたデータガバナンスが実現されている点を支持します。また、公開の料金ページでFree／Plus／Pro／Business／Enterpriseの機能差が比較可能であり、組織のポリシーやリスク許容度に照らして最適なプランを選定できる点も重要視します[1]。

【出典】
[1] https://chatgpt.com/ja-JP/pricing
[2] https://chatgpt.com/ja-JP/pricing?openaicom-did=38045de1-ff68-4b2b-aa33-fd30f2e19659&openaicom_referred=true
[3] https://chatgpt.com/ja-JP/pricing?openaicom-did=2d6813d1-2003-4e2a-8071-accc296dfa08&openaicom_referred=true
[4] https://chatgpt.com/ja-JP/pricing?openaicom-did=64450a2d-255d-4f40-8881-e439eb4c03e8&openaicom_referred=true
[5] https://chatgpt.com/ja-JP/pricing?openaicom-did=24d803ca-e6f9-4145-9ffd-527cae3f6dc2&openaicom_referred=true
[6] https://chatgpt.com/ja-JP/pricing?openaicom-did=8988091f-e622-45d7-b21e-24172bd99250&openaicom_referred=true
[7] https://chatgpt.com/ja-JP/business/ai-for-product-management/
[8] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[9] https://openai.com/ja-JP/api-priority-processing/
[10] https://openai.com/ja-JP/index/doppel/


## データ処理方針
データ処理方針は、プライバシー・ガバナンス・セキュリティを中核に据えて設計され、ChatGPTのビジネス向けプランおよびAPIにおいては、お客様が明示的に共有を許可しない限りデータをモデル学習に使用せず、ChatGPT Business/Enterpriseを含む製品でもデフォルトで学習に用いない運用を徹底します[1][2][4]。あわせて、ビジネス向け製品におけるお客様データの所有権はお客様に帰属し、機密性と安全性を前提に取り扱います[3]。医療領域においても、ユーザーの文書や患者データを学習に使用せず、機密情報が非公開かつ保護されることを前提に導入を支援します[7]。

データ処理方針は、規制要件や主権要件への適合を支援するため、データレジデンシーを提供します。ヨーロッパでの導入に加え、米国、欧州、カナダ、日本、韓国、シンガポール、インド、オーストラリア、UAEなどで、会話やファイル、カスタムGPT、生成コンテンツ等を地域内に保存できる選択肢を用意しています[1][3]。特にAPIプラットフォームでは、高度なデータコントロールが承認されたEnterpriseのお客様がプロジェクト単位で地域を選択でき、該当プロジェクト経由のリクエストは地域内で処理され、モデルのリクエストや応答はOpenAIのサーバー上に保存されません[1]。

データ処理方針は、技術的・組織的な保護を標準装備し、データの安全性と統制を担保します。保存データにはAES-256、通信にはTLS 1.2以上の暗号化を適用し、保存対象のユーザーコンテンツにはEnterprise Key Management（EKM）でお客様自身の暗号鍵を使用できます[1]。アカウント・アクセス面ではSSOや多要素認証（MFA）を提供し、専用ワークスペースの管理コンソールで権限・ブランドガバナンス・コンプライアンスを一元管理できる運用基盤を備えています[2][8]。さらに、ChatGPT Enterpriseでは「お客様のデータや入出力内容は安全に保護」「業界基準および規制を厳格に遵守」という原則のもとで企業導入を支援します[4]。

データ処理方針は、GDPRやCCPAをはじめとするプライバシー法遵守を支援し、CSA STAR、SOC 2 Type 2、ISO/IEC 27001・27017・27018・27701などの基準・認証に準拠します。GDPR等における役割と責任を明確化する包括的なDPA（データ処理に関する補足事項）も提供し、組織のコンプライアンス達成を支援します[1][3]。また、データ主体の権利（アクセス、削除、更新・修正、ポータビリティ、処理の制限、同意の撤回、異議申立て、当局への苦情申立て等）を尊重し、OpenAIアカウントやプライバシーポータル、指定メールアドレス（dsar@openai.com、privacy@openai.com）を通じて行使できる手段を整備するとともに、モデル出力の性質上の不正確さに対する修正・削除リクエストも受け付けます[5]。

データ処理方針は、モデルの振る舞いに関するガイドライン「Model Spec」を公開し、安全性と法的遵守を重視するルールを明確化しています。とりわけ「適用法を遵守する」ことを原則とし、違法行為の助長を許容しません。違法性の判断が文脈に依存し得ることを踏まえつつ、利用規約に基づく適切な対応を行い、技術だけでなく利用プロセス全体を通じたガバナンスと透明性を担保します[6]。

データ処理方針は、検証済みのデータソース、ビジネスコンテキスト、ガバナンスの枠組みに基づく応答生成を重視し、組織が管理するコネクターを通じて社内ドキュメントやファイルと安全に統合できるよう設計しています。機密データセットや社内モデル、意思決定ロジックは常に組織の管理下で非公開として取り扱い、意思決定者が信頼できるインサイトを得られる運用を実現します[2]。

データ処理方針は、API優先処理（Enterprise向け）において処理の一貫性と公平性を確保する運用ポリシーを明確にしています。トラフィックが急増する場合には、一部の優先リクエストを標準処理に切り替えることがあり、優先処理のランプレート上限は「TPMが100万以上、かつ15分未満にTokens Per Minuteが50%以上増加」と定義します。標準サービスティアで処理されたリクエストは標準料金となり、優先処理のSLO/SLAの対象にはなりません（レスポンスにはservice_tier="Default"が含まれます）。ベストプラクティスとして、モデル切替時は段階的にトラフィックを増やすこと、大規模なデータ処理や非同期ジョブには優先処理を使わないこと、ランプレート上限に頻繁に達する場合はスケールティアの容量追加を検討することを推奨し、SLAを満たせなかった場合はEnterprise契約のお客様にサービスクレジットを提供します[9]。

データ処理方針は、設計原則として自動化と人間の判断の適切な分担を実装しています。社内の「契約書データエージェント」では、PDFやスキャン／写真から契約条項を構造化し、非標準条項を理由付きでハイライトすることでレビュー時間を半減し、夜間処理や増員なしで大量処理を実現しました[10]。また「リサーチアシスタント」では、何百万件ものチケットを分類・要約し自然言語でレポート生成を行う一方、初期段階で運用チームが手動分類を行い、データサイエンティストが比較用カスタムモデルで突合するプロセスを経て、質問・確認・信頼のサイクルで精度を検証・定着させています[11]。

データ処理方針は、これらの方針と実装が実運用の現場で機能することを重視します。大日本印刷（DNP）はChatGPT Enterpriseをセキュリティ監査やクラウドセキュリティ適用、レビュー業務に活用し、監査差分確認を30分から5分、暗号スイート選定を3時間から1時間、CIS Benchmarksの初動調査を約2人日から約10分に短縮しました[12]。Holiday Extrasは全社導入により多言語コンテンツやデータ活用、エンジニアリング効率化などで週500時間・年間50万ドル相当の生産性向上を達成し、部門横断で安全にデータを活用する基盤として機能しています[13]。データ処理方針は、これらの取り組みを礎に、企業が安全かつコンプライアンスに則ったかたちでAIを活用できるよう、継続的に強化を進めていきます[2]。

【出典】
[1] https://openai.com/ja-JP/index/expanding-data-residency-access-to-business-customers-worldwide/
[2] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[3] https://openai.com/ja-JP/index/introducing-data-residency-in-europe/
[4] https://chatgpt.com/ja-JP/business/enterprise?openaicom-did=05ea467a-07b5-4b11-92be-6342ad385e02&openaicom_referred=true
[5] https://openai.com/ja-JP/policies/privacy-policy/
[6] https://openai.com/ja-JP/index/introducing-the-model-spec/
[7] https://openai.com/ja-JP/solutions/healthcare/
[8] https://chatgpt.com/ja-JP/business/ai-for-engineering/
[9] https://openai.com/ja-JP/api-priority-processing/
[10] https://openai.com/ja-JP/index/openai-contract-data-agent/
[11] https://openai.com/ja-JP/index/openai-research-assistant/
[12] https://openai.com/ja-JP/index/dai-nippon-printing/
[13] https://openai.com/ja-JP/index/holiday-extras/


## データ出典・処理
データ出典・処理は、データガバナンスとプライバシーの要諦を「透明性」「ユーザーの選択」「法令遵守」に定め、モデルの学習と利用に関わるデータの出典・処理を厳格に管理します。AIの望ましい振る舞いを明確化するためにModel Specへのフィードバックを広く受け付け、今後1年間にわたり変更点や研究の進捗を定期的に共有するなど、運用方針の透明性を一層高めます[1]。データ出典・処理は、こうした実務を「信頼と透明性」の取り組みとして継続的に公開し、企業向けの信頼ポータル等を通じてドキュメントやFAQを提供し、ステークホルダーとの対話と説明責任を徹底します[9]。

データ出典・処理は、ビジネス向けプランやAPIで取り扱うお客様データを、明示的な共有許可がない限り当社モデルの学習に使用しません。ChatGPT Businessでも、デフォルトでお客様のデータは学習に用いられません[2][3]。一方、個人向けサービスでは、本サービスの提供・維持・開発・改善、法令・規約の遵守、サービスの安全性維持のためにお客様のコンテンツを使用する場合がありますが、モデル学習への利用はヘルプセンターからいつでもオプトアウトをリクエストできます[4][5]。プライバシーポリシーに基づき、適切な告知・選択・コントロールを提供します[7]。

データ出典・処理は、地域要件やデータ主権に対応するためデータレジデンシーを提供し、米国、欧州、カナダ、日本、韓国、シンガポール、インド、オーストラリア、UAEなど各地域で、会話、アップロードファイル、カスタムGPT、画像生成の成果物等のコンテンツを地域内に保存・処理できるようにしています。APIやChatGPTのビジネス向け製品では、お客様データの機密性・安全性を確保し、その所有権がお客様に帰属することを明確化するとともに、これらのデータはAIモデルの学習に使用しません[2][6]。APIプラットフォームでは、Enterpriseのお客様がプロジェクトごとに地域を指定してデータレジデンシーを有効化でき、当該プロジェクト経由のリクエストは地域内で処理され、モデルのリクエストや応答は当社サーバー上に保存されません。ChatGPT Enterprise・EduやAPIで保存されるコンテンツも、選択した地域内に保存されます[2]。

データ出典・処理は、保存時のAES‑256および送信時のTLS 1.2以上による暗号化、Enterprise Key Management（EKM）によるお客様管理鍵の適用など、技術的管理策を実装しています。加えて、GDPRやCCPAなどのプライバシー法遵守を支援し、CSA STAR、SOC 2 Type 2、ISO/IEC 27001・27017・27018・27701といった基準・認証に準拠する包括的なデータ保護プログラム、および役割と責任を明確化するデータ処理契約（DPA）を提供します[2][6]。

データ出典・処理は、企業のデータガバナンスに適合したワークスペースとアクセス管理を用意し、ChatGPT BusinessにおいてSSOや多要素認証によるアカウント保護、権限・ブランドガバナンス・コンプライアンスの一元管理を実現します。さらに、データウェアハウス、BI、ストリーミング等のコネクターと連携するハブにより、検証済みデータソースやビジネスコンテキスト、ガバナンスの枠組みに基づく分析・応答を生成できる環境を提供します[3]。

データ出典・処理は、ユーザーの個人データに関する権利行使（アクセス、削除、更新・修正、ポータビリティ、処理の制限、同意撤回、異議申立て、監督当局への苦情申立て）に対応し、アカウント機能または指定窓口（privacy.openai.com、dsar@openai.com、privacy@openai.com）でのリクエストを受け付けます。当社モデルのアウトプットに不正確な個人情報が含まれる場合の修正・削除リクエストにも対応します[7]。また、個人データの第三者処理に際しては、ベンダーやサービス提供事業者が当社の指示に基づき業務遂行に必要な範囲でのみアクセス・取扱い・保存できるよう制限し、関連会社への開示、事業再編等の移転、法令遵守・権利保護・不正防止・安全確保等の正当な目的で、政府当局や第三者へ情報を提供する場合があります[7]。

データ出典・処理は、例外的に法的手続に基づくデータ提出が求められる場合でもプライバシー保護を最優先します。対象データは匿名化や個人識別情報の削除（スクラブ）を施し、安全なシステムに隔離保管してリーガルホールドを適用し、法的義務を果たす目的以外ではアクセス・利用しません。アクセス権限は監査済みの小規模な法務・セキュリティチームに限定し、相手方の外部顧問弁護士等の閲覧も厳格な法的プロトコル下の安全な環境に限ります。過度でプライバシー基準に一致しない請求には異議を申し立て、重要な更新情報を随時共有します[8]。

データ出典・処理は、モデル学習前のデータ処理でも安全性と品質向上のための対策を実施しており、DALL·E 2では学習前に暴力的・性的な画像を除外し、重複画像の削除で記憶による再現（いわゆる吐き戻し）を抑制しました。さらに、能動学習（最近傍探索など）でフィルターの偽陰性率低減に取り組み、データフィルタリングに伴う偏りには再重み付けで補正しています[10]。

データ出典・処理は、出典の透明性を高める機能を製品に組み込み、ChatGPTやdeep research、ナレッジ検索等でウェブや企業データを横断的に分析し、明確なソース参照に基づく出典付きの回答やレポートを生成します[12]。社内の「契約書データエージェント」では、検索拡張プロンプトで契約の関連部分のみを抽出・解析し、推論過程の可視化、非標準条項の理由付きハイライトや参照を含む構造化データ生成を行い、専門家レビューと組み合わせて精度を担保する処理パイプラインを運用しています[11]。これらの取り組みを通じて、データ出典・処理は透明性、ユーザーの選択、法令遵守を軸とするデータガバナンスを一貫して実現していきます[1][9]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/expanding-data-residency-access-to-business-customers-worldwide/
[3] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[4] https://openai.com/ja-JP/policies/row-terms-of-use/
[5] https://openai.com/ja-JP/policies/terms-of-use/
[6] https://openai.com/ja-JP/index/introducing-data-residency-in-europe/
[7] https://openai.com/ja-JP/policies/privacy-policy/
[8] https://openai.com/ja-JP/index/fighting-nyt-user-privacy-invasion/
[9] https://openai.com/ja-JP/trust-and-transparency/
[10] https://openai.com/ja-JP/index/dall-e-2-pre-training-mitigations/
[11] https://openai.com/ja-JP/index/openai-contract-data-agent/
[12] https://openai.com/ja-JP/solutions/use-case/research/


