# 品質・信頼性方針

## 概要


### 基本姿勢
OpenAIは品質と信頼性を事業の中心に据え、安全性を最優先しながら有用性と自由度を最大化します。使用ポリシー、監視・執行、ガイダンス、研究共有、不正利用報告を備えた安全エコシステムと、透明性レポートや信頼ポータル、製品内の説明可能性を通じて設計から運用までを一貫管理します。これらの原則はGPT‑5、Sora、ChatGPT searchを含む全プロダクトと当社の自社運用に適用します。

### 重点的取り組み
OpenAIはメンタルヘルスや自傷などセンシティブな会話の品質・安全性向上を最優先課題とし、Model Specに沿う行動設計と「危害マッピング→評価→専門家検証→リスク軽減」のループを運用します。OpenAIは第三者評価を常態化し、評価者に安全な深いアクセスと結果非依存の報酬を提供しつつ、評価サマリーと独立レポートの公開を進めます。OpenAIは推論ベースの安全設計（gpt‑oss‑safeguard、熟慮的アライメント）、人間レビューを用いたRFT、モデレーションと検索表示の透明化、企業データ保護とSSO/MFA等の運用堅牢化を継続強化します。

### 重要事実
2025年10月のモデル更新で、OpenAIはGPT‑5の不適切な応答を65～80%削減しました。OpenAIはMETRやApollo Research、Irregular等による独立評価の実施・公開を支援し、gpt‑oss‑safeguardを研究プレビューとしてオープンウェイトで提供しています。OpenAIは組織データや患者データを学習に用いずオプトアウト手段を提供し、ChatGPT Enterpriseの実装ではENEOSマテリアルでの全社導入により調査効率と設計品質の向上を実証しました。


## 品質・信頼性の方針
品質・信頼性の方針は、OpenAIが品質と信頼性を事業の中心に据え、安全性・透明性・有用性のバランスをとりながら製品を設計・運用する公式見解を基盤に、常に安全性を最優先しつつ有用性と自由度を最大化するものです。品質・信頼性の方針は、使用ポリシーを包括的な安全エコシステムの一部として位置づけ、監視・執行・ガイダンス提供・研究知見の共有・不正利用の報告窓口の整備を通じて、製品の信頼性と責任ある利用を継続的に支えます[4][1]。

品質・信頼性の方針は、信頼の基盤として透明性を徹底します。ユーザー報告の受付、透明性レポートの公開、企業向け信頼ポータルの提供に加え、児童安全に関する半期レポートやEUデジタルサービス法（DSA）に基づく透明性レポートを継続的に公開し、製品内の報告機能も備えます[1]。さらに、コンテンツモデレーションのアプローチと施行、異議申立てプロセス、SoraやChatGPT searchにおける表示の仕組み、安全基準の適用を公開し、インライン引用やサイドバー情報源の提示など結果提示の透明性も高めます[9]。

品質・信頼性の方針は、センシティブな会話領域の品質・安全性向上を優先課題に掲げ、Model Specの原則に沿ってモデルのふるまいを具体化します。メンタルヘルス、自傷・自殺、AIへの感情的依存に関する応答を改善し、長年の指標に加えて感情的依存や非自傷の緊急事態も将来の安全性テストのベースラインに組み込みます。また、モデルがユーザーの現実世界の関係性を尊重し、根拠のない信念を肯定せず、潜在的な妄想や躁状態の兆候に安全かつ共感的に対応し、間接的な自傷・自殺リスクのシグナルに注意を払うという原則を明確化します。これらの取り組みにより、2025年10月のモデル更新ではGPT‑5の不適切な応答を65～80%削減しました。品質・信頼性の方針は、潜在的な危害のマッピング（問題定義）、評価や実会話データ・ユーザーリサーチによる測定、外部専門家との検証、リスク軽減というステップで、ChatGPTの回答品質を体系的に高めます[2]。

品質・信頼性の方針は、フロンティアAIの能力とリスクを第三者の評価で測定し、品質と安全性の信頼性を高めます。評価者には公開用・本番向けのアクセスに加え、必要に応じてhelpful‑onlyモデルや非公開情報へのより深いアクセスも提供しつつ、厳格なセキュリティ管理のもとで機密保護と正確性を両立します。第三者評価には結果に依存しない適切な報酬（直接支払い・APIクレジット等）を提供し、持続可能な評価エコシステムを整備します。評価サマリーを公開するとともに、METRによるGPT‑5レポート、Apollo ResearchによるOpenAI o1レポート、IrregularによるGPT‑5評価など、独立機関からのレポートの公開も支援・実施してきました。これらの枠組みはGPT‑5にも適用しています[3]。

品質・信頼性の方針は、推論ベースの安全設計を組み込みます。オープンウェイトの安全性分類モデル「gpt‑oss‑safeguard」を研究プレビューとして公開し、開発者が独自の安全ポリシーを推論時に適用できる柔軟で説明可能な手段を提供します。あわせて、主要な推論モデルでは安全性ポリシーを直接学習し、熟慮的アライメントという手法で安全性の強化と多層防御の可能性を拡げています[6]。

品質・信頼性の方針は、人間によるレビューと学習ループを活用して一貫性と信頼性を高めます。たとえば脅威検知ワークフローでは、低信頼度や矛盾がある場合に人間がレビューし、その判断を学習データ化して強化ファインチューニング（RFT）にフィードバックします。説明の品質も評価対象とし、曖昧なエッジケースでも専門家の判断を再現することで、自動検知の一貫性と信頼性を向上させます[5]。

品質・信頼性の方針は、自社運用にも同じ基準を適用し、実運用で信頼性を検証します。サポートチーム向けに導入したGPT‑5ベースのリサーチアシスタントでは、数百万件規模のチケットを製品領域・テーマで構造化する分類・可視化と、未加工チケットからの要約・カスタムレポート生成を統合し、正確さを最優先に設計しました。導入初期には手動分類やカスタムモデルとの突き合わせで整合を確認し、その後も現場知見との照合による「質問→確認→信頼」のサイクルで信頼性を高めています[8]。

品質・信頼性の方針は、企業用途におけるデータ保護と運用上の信頼性を重視します。組織データをモデル改善に使用しないことを徹底し、データの静止時・転送時暗号化、MFAやSAML SSOによる保護、GDPR・CCPAなどプライバシー規制への準拠支援を明確に示します。ChatGPTがユーザーの文書や患者データを学習に使用しないことも明示しています[7][11]。さらに、ChatGPT Businessのデータサイエンス＆アナリティクス向けソリューションでは、本番環境対応の特徴量パイプラインの自動生成・自動テスト・高信頼モニタリングを備えた統合ワークスペースに、SSOや多要素認証などのセキュリティ機能を統合し、品質と運用の両立を支援します[10]。

品質・信頼性の方針は、コンテンツの安全な表示と施行プロセスの透明性を通じて、ユーザーに信頼できる体験を提供します。ChatGPT searchでは、関連性・品質・安全基準に基づいて結果を選定し、インライン引用やサイドバー情報源で文脈を補足します。違法・有害・センシティブなコンテンツを含む特定サイトは表示から除外する場合があり、施行に対する上訴の仕組みも整備しています[9]。これらは、使用ポリシーの監視・執行、開発者向けモデレーションツールやガイダンスの提供、研究・最新情報の共有、規則の継続的アップデートとともに、品質・信頼性の維持・向上を支える実装です[4]。

品質・信頼性の方針は、利用規約において重要な前提を明確化します。サービスの正確性・信頼性・安全性を継続的に改善すること、アウトプットが常に正確とは限らないため人による確認を含む適切性評価が必要であること、ならびにお客様コンテンツの学習利用に関するオプトアウト手段を規定しています[12][13]。

品質・信頼性の方針は、顧客現場での実装と成果にも責任を持ちます。たとえばENEOSマテリアルでのChatGPT Enterprise全社導入（2025年9月）では、deep researchによる調査時間の大幅短縮に加え、社内設計基準を組み込んだカスタムGPTにより設計初期検討の迅速化と品質向上を実現しています[14]。

品質・信頼性の方針は、透明性の確保、体系的な安全性評価、第三者検証、人間とAIの協働、推論ベースの安全設計、データ保護と運用の堅牢性、そして実運用での継続的改善という柱により、品質と信頼性を実務に落とし込み、継続的に強化していきます[1][2][3][4][6][7][8][9][10][11][12][13][14]。

【出典】
[1] https://openai.com/ja-JP/trust-and-transparency/
[2] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[3] https://openai.com/ja-JP/index/strengthening-safety-with-external-testing/
[4] https://openai.com/ja-JP/policies/usage-policies/
[5] https://openai.com/ja-JP/index/doppel/
[6] https://openai.com/ja-JP/index/introducing-gpt-oss-safeguard/
[7] https://openai.com/ja-JP/solutions/use-case/content-creation/
[8] https://openai.com/ja-JP/index/openai-research-assistant/
[9] https://openai.com/ja-JP/transparency-and-content-moderation/
[10] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[11] https://openai.com/ja-JP/solutions/healthcare/
[12] https://openai.com/ja-JP/policies/row-terms-of-use/
[13] https://openai.com/ja-JP/policies/terms-of-use/
[14] https://openai.com/ja-JP/index/eneos-materials/



---


