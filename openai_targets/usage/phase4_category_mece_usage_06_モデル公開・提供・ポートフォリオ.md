# モデル公開・提供・ポートフォリオ

## 概要


### 基本姿勢
OpenAIは、モデル公開・提供を「安全性を前提にした実用性の最大化」と定義し、Model SpecのCC0公開と独立した外部評価を通じて、知的自由・透明性・ガードレールの両立を図ります。OpenAIは、Preparedness FrameworkとEvaluations Hubで展開前後を継続評価し、システムカードや使用ポリシーの更新に迅速に反映します。OpenAIは、Business/Enterprise/APIでお客様データを学習に使用せず、暗号化とSSO/SCIM等のエンタープライズ基盤でプライバシーを守ります。

### 重点的取り組み
OpenAIは、GPT‑5系の継続発展を推進し、2025年12月にGPT‑5.2を公開、適応推論・Autoルーティング・Codex強化とともに全モデルへセーフコンプリーションを適用し、メンタルヘルス等のセンシティブ領域で不適切出力を65〜80%削減しました。OpenAIは、Agents SDK・Responses・Realtime、MCPと主要コネクター、SAML SSO/Admin/Audit LogsなどAPI・運用基盤を拡充し、企業ワークフローへ安全に統合します。OpenAIは、gpt‑ossおよびgpt‑oss‑safeguardの公開と、METR・Irregular・Apollo Researchなどによる第三者テストを通じて、選択肢と検証可能性を広げます。

### 重要事実
OpenAIは、GPT‑5.2でSWE‑Bench Verified 80.0%、GPQA Diamond 92.4%、HMMT 99.4%など最先端の評価を達成し、GDPvalでは44職種の知識業務で専門家水準を上回る結果を報告しました。OpenAIは、2025年11月に企業顧客100万社を突破し、Indeed・Intercom・Lowe’s・Databricks等に加え、日本のDNPで自動化率87%・処理量10倍などの成果を確認しています。OpenAIは、評価サマリーをシステムカードとEvaluations Hubで公開し、使用ポリシーを2025年10月29日に改訂、Aardvarkなど安全ツールの提供も進めています。


## API・エコシステム連携
API・エコシステム連携は、「安全性を前提にした実用性の最大化」を公式見解として掲げ、明確な使用ポリシー、開発者向けモデレーションツール、監視・執行の仕組みを整備しながら、外部との協調を通じて信頼できる導入を推進します[1][2]。フロンティアAIについては、独立した第三者評価を計画的に活用し、公開用・本番運用向けの情報やモデルへのアクセスに加え、評価ニーズに応じてhelpful-onlyモデルや非公開情報への深いアクセスも付与するなど、厳格なセキュリティ管理のもとで安全な評価環境を確保します。報酬は直接支払いに加えてAPIクレジット等を提供しつつ、評価結果に影響しないバランスの取れたインセンティブ設計を貫徹します。評価サマリーはシステムカードで公開され、METRやIrregularによるGPT‑5の評価、Apollo ResearchによるOpenAI o1の評価など、第三者による調査結果の公表も進めています[2]。さらに、社会的な安全・信頼性を支える「AIレジリエンスエコシステム」の構築を提言しつつ、現在の能力水準にあるAIはすでに実用段階にあるとの認識のもと、開発者や多くのオープンソース導入事例に既存枠組み以上の新たな規制負担を過度に課すべきではないという立場を明確にしています[3]。あわせて、API・エコシステム連携は新しい情報やユースケースの広がりに合わせて規則を更新し、過度な制限を避けながらユーザー保護を強化します。これらの規則は法的・職業的・倫理的義務の代替ではなく、違反・回避があればアクセス権の停止等を含む対応を行い、不正利用の報告手段も提供します[1]。

API・エコシステム連携は、企業や開発者が安全かつ大規模に連携できるよう、APIプラットフォームとエンタープライズ機能を拡充しています。APIプラットフォームでは、MFA（TOTP）、SAML SSO、プロジェクトとプロジェクト制限、Admin API、Audit Logs API、使用状況ダッシュボードなどを提供し、ワークスペース内のアクセス、権限、支出、利用状況をきめ細かく管理できます。ChatGPT Enterprise/EduではSCIMやロールベースのアクセス制御、ユーザーアナリティクスを備え、ID管理・権限設計・導入可視化を一体的に支援します。加えて、ChatGPT Enterprise/Business/APIはいずれもビジネスデータを学習に使用しない設計をとり、AES‑256・TLS1.2以上による暗号化でデータを保護します[4]。なお、エコシステム連携に際しては第三者のソフトウェア・製品・サービスやそれらのアウトプットが含まれる場合があり、第三者側の独自条件が適用されること、当該第三者サービスやアウトプットに関してOpenAIが責任を負わないことを明確にし、統合利用の前提を透明化しています[5]。

API・エコシステム連携は、自らもAPIとエージェント技術を活用して実運用の中で生産性と品質を実証しています。GTM Assistant、DocuGPT、Research Assistant、Support Agent、Inbound Sales Assistantなどを構築し、AIエージェント・継続的評価・動的知識ループにもとづく運用モデルで、すべてのインタラクションを学習データへと変換して品質を継続向上しています。インバウンドセールスでは、リードごとのパーソナライズやコンプライアンス対応、要件適合リードの文脈情報付き引き渡しを通じて、機会損失を売上に変換します[6]。サポート領域では、GPT‑5ベースのResearch Assistantが数百万件のチケットを分類・要約し、自然言語インターフェースでの対話型レポーティングと可視化により、製品・営業・運用の意思決定を加速しています[7]。この新しいAIオペレーティングモデルは、Agents SDK、Responses API、Realtime APIなどを実運用で活用し、応対品質の一貫性向上と継続的学習を両立しています[9]。さらに、契約書データエージェントでは、PDFやスキャン・写真から契約条項を構造化し、非標準条項を理由付きでハイライト。「機械的な作業は自動化し、判断は人間が行う」原則を堅持し、夜間の自動解析で専門家が分析と戦略に集中できる新たな運用モデルを確立しました。これは規制のある重大な業務におけるAI活用の青写真です[8]。

API・エコシステム連携は、業務ツールやデータソースとの接続性を広げ、Slack、Notion、Google Workspaceといったコラボレーション基盤や、deep research・ウェブ検索、Box、Dropbox、HubSpotなどの外部ソースからのデータ取得を可能にするコネクター、MCP（Model Context Protocol）との連携を通じて、研究・分析・レポーティングのワークフローを自動化・拡張します[10][11][12]。プロダクトマネジメント向けには、JiraやSlackとの連携を備えた統合ワークスペースを提供し[13]、リアルタイム音声・テキスト対話やマルチモーダルなエージェントの実装までをカバーしています[9]。

API・エコシステム連携は実運用事例の拡大も牽引しています。2025年11月には企業顧客が100万社を超え、Indeedは応募数20％・採用数13％の向上、IntercomはOpenAIを中核にしたカスタマーサービスエージェント「Fin」で開発サイクルを数四半期から数日に短縮、Lowe’sは全米1,700店舗超の従業員向けアプリ「Mylow Companion」にOpenAIモデルを採用。Databricksは企業データが存在する環境に最先端インテリジェンスを統合し、高品質なエージェントの構築と運用を容易にしています[14]。日本においても大日本印刷（DNP）がChatGPT Enterpriseを10部門に導入し、外部セキュリティ監査の差分確認を30分から5分、暗号スイート選定を3時間から1時間へ短縮するなど、業務の自動化率87％、知識再利用70％、処理量10倍といった成果を上げています[15]。医療領域ではSummer HealthがGPT‑4を用いて診療記録を自動要約し、記録作成時間を1件あたり10分から2分に短縮、記録遅延を400％削減するなど、患者・保護者体験の向上につなげています[16]。

API・エコシステム連携はセキュリティ分野でも連携を強化しています。GPT‑5によるエージェント型セキュリティリサーチャー「Aardvark」は、コードリポジトリを継続的に分析し、脆弱性の検出・現実世界での悪用可能性の検証・優先度付け・パッチ提案までを支援する「セキュリティ従事者優先」の新しいモデルで、現在プライベートベータとして提供中です。商用目的ではないオープンソースリポジトリへの無償スキャン提供を予定し、外部向けの協調開示ポリシーもコラボレーションとスケーラブルな影響に重点を置く形に更新しました。API・エコシステム連携は、Aardvarkのようなツールで発見されるバグの増加を見込み、長期的レジリエンスの実現に向けた継続的協力を推進します[17]。

これらの取り組みにより、API・エコシステム連携は、API、コネクター、認証・管理基盤、開発者向けSDK、マルチモーダルAPIを核に、企業の既存ツール群・データ環境・運用プロセスと密接に連携する、安全性・信頼性・拡張性に優れたプラットフォームを継続的に発展させていきます[2][4][9][14]。

【出典】
[1] https://openai.com/ja-JP/policies/usage-policies/
[2] https://openai.com/ja-JP/index/strengthening-safety-with-external-testing/
[3] https://openai.com/ja-JP/index/ai-progress-and-recommendations/
[4] https://openai.com/ja-JP/business-data/
[5] https://openai.com/ja-JP/policies/terms-of-use/
[6] https://openai.com/ja-JP/index/building-openai-with-openai/
[7] https://openai.com/ja-JP/index/openai-research-assistant/
[8] https://openai.com/ja-JP/index/openai-contract-data-agent/
[9] https://openai.com/ja-JP/index/openai-support-model/
[10] https://openai.com/ja-JP/solutions/use-case/research/
[11] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[12] https://chatgpt.com/ja-JP/business/ai-for-finance/
[13] https://chatgpt.com/ja-JP/business/ai-for-product-management/
[14] https://openai.com/ja-JP/index/1-million-businesses-putting-ai-to-work/
[15] https://openai.com/ja-JP/index/dai-nippon-printing/
[16] https://openai.com/ja-JP/index/summer-health/
[17] https://openai.com/ja-JP/index/introducing-aardvark/


## GPT-5関連機能・提供
GPT-5関連機能・提供は、GPT-5シリーズを通じて高度な推論と即時応答を統合したモデル提供を推進し、文章作成・コーディング・ヘルスケアなど幅広い専門領域での有用性と安全性の両立を図っています。GPT‑5は、高速応答モデルと深い推論モデルをリアルタイムで自動切替するルーターを備え、ハルシネーション低減と指示遵守の改善、ならびに最新のセーフコンプリーションを全モデルに実装しました[1][2]。あわせて、Plus／Pro向けの提供や推論強化版「GPT‑5プロ」を用意し、ChatGPTの回答スタイルを切り替えられる4種類のプリセット人格を研究プレビューとして提供することで、ユーザー体験の即時性とカスタマイズ性を強化しました[1]。

GPT-5関連機能・提供は、開発者・企業・エンタープライズユーザーが即戦力として使えるよう段階的に公開・提供を進めてきました。2025年11月にはGPT‑5.1をAPI向けに提供開始し、タスクの複雑さに応じて思考時間を動的に最適化する適応的推論、「推論なし」モード、24時間保持のプロンプトキャッシュなど、開発者の生産性を高める機能を搭載しました。さらに、コード編集のためのapply_patchツールやshellツールを新たに提供し、コーディング性能と応答速度を大幅に向上。評価ではSWE‑bench Verifiedで76.3%（GPT‑5は72.8%）、GPQA Diamondで88.1%（ツールなし）など、複数のベンチマークで向上を確認しています。現時点でGPT‑5をAPIで非推奨にする予定はなく、非推奨とする場合は事前に開発者へ通知します[3]。また、GPT‑5.1のバリアントとしてInstant（より会話的で指示遵守を強化）とThinking（質問内容に応じて思考時間をきめ細かく調整）を提供し、各クエリを最適なモデルに自動振り分けるGPT‑5.1 Autoでユーザーのモデル選択の負担を軽減しました[3][4]。コーディング領域では、長時間・大規模プロジェクトに対応する推論力とトークン効率を備えたGPT‑5.1‑Codex‑Maxを公開し、より高速で知的なエージェント型コーディングを可能にしています[5]。

GPT-5関連機能・提供は、2025年12月にGPT‑5.2を公開しました。GPT‑5.2は、専門的な知識業務や長時間稼働するエージェントに最適化され、長文コンテキスト理解、コード生成、画像認識、ツール活用で性能を強化。SWE‑Bench Verified 80.0%、GPQA Diamond 92.4%、HMMT（2025年2月）99.4%、FrontierMath 40.3%、ARC‑AGI‑1（Verified）86.2%、ARC‑AGI‑2（Verified）52.9%など、幅広い領域で優位性を示しました[6]。また、GDPvalでは44の職種にまたがる明確に定義された知識業務タスクで業界専門家を上回る結果を達成し[8]、ラインアップとしてgpt‑5.2‑instantとgpt‑5.2‑thinkingを提供しています。安全性についてはGPT‑5およびGPT‑5.1のSystem Cardで説明した包括的緩和策を踏襲し、更新内容を公開しています[6][7]。

GPT-5関連機能・提供は、安全性を最優先に据え、GPT‑5 System Cardに基づき生物・化学領域での高度な能力に予防的セーフガードを適用しています。Preparedness Frameworkに沿った判断のもと、非専門家による重大な生物学的危害への実質的寄与の決定的証拠は確認されていない一方で、先手を打った対策を講じ、全モデルにセーフコンプリーションを実装しました[2]。さらに、CAISIやUK AISIと連携し、合計5,000時間に及ぶレッドチーミングを含む包括的なセーフガードを組み込み[1]、メンタルヘルスや不健全な感情的依存に関する評価を含むベースライン安全指標を拡張。2025年10月のモデル更新では、精神疾患や自殺・自傷、AI依存といったセンシティブな会話に関する不適切な出力を65〜80%削減し、検出・抑制システムの準拠率を大幅に向上させました[4][9]。

GPT-5関連機能・提供は、実利用現場での価値検証も重視しています。2025年8月にはAmgenにおけるGPT‑5の活用事例を公開し、早期導入段階での評価やAPI経由でのChatGPTビジネス製品活用の様子を紹介しました[10]。今後も、実際のエージェントタスクやコーディング作業で使える、より高性能で信頼性の高いモデルの継続提供に取り組み、開発者が作業の流れを保ったまま効率的に思考し迅速に反復できるよう、適応推論の強化、コーディング能力の高度化、分かりやすい更新、そしてapply_patchやshellといった新ツールの提供を拡充し、今後数週間から数か月でより高性能なエージェント型コーディング向けモデルの提供を進めていきます[3]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-gpt-5/
[2] https://openai.com/ja-JP/index/gpt-5-system-card/
[3] https://openai.com/ja-JP/index/gpt-5-1-for-developers/
[4] https://openai.com/ja-JP/index/gpt-5-system-card-addendum-gpt-5-1/
[5] https://openai.com/ja-JP/research/index/
[6] https://openai.com/ja-JP/index/introducing-gpt-5-2/
[7] https://openai.com/ja-JP/index/gpt-5-system-card-update-gpt-5-2/
[8] https://openai.com/ja-JP/index/gdpval/
[9] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[10] https://openai.com/ja-JP/index/gpt-5-amgen/


## データフォーマットと使い方ガイド
データフォーマットと使い方ガイドは、ユーザーが手元のドキュメントや業務データから最短経路で洞察を得られるよう、「受け取れるデータ形式」と「効果的な使い方」を当社方針として明確に提供します。中核となるのは、ChatGPTへのPDFアップロード機能です。研究論文や契約書など大容量ドキュメントの内容理解を、自然な対話での要約・分析・明確化まで一気通貫で行える体験を重視し、メールやスプレッドシート等とのシームレスな連携によって、日々のワークフローにそのまま組み込める活用を推進します[1]。

データフォーマットと使い方ガイドは、PDFをChatGPTにアップロードするだけで内容理解を開始できることを公式にサポートしています。具体的には、「マニュアル.pdf」からのクイックスタートガイド作成、「財務報告書.pdf」を使った今四半期の業績要約や過去3年間の収益傾向の抽出、「書籍.pdf」に対する主題の把握、5〜7章に関する考察を深める質問の生成、特定の「本の一節.pdf」を初心者向けにやさしく解説する、といった実務直結のプロンプトで、高度な要約・分析・説明を実現します。さらに、プレゼンテーションではデッキをアップロードして双方向の対話に変換し、より明確なメッセージ設計や適切なビジュアル選定を支援します。スプレッドシートとのチャットでは、生データの理解促進、数式の修正支援、インサイトの抽出やテンプレート化まで対応し、AIブラウジング「Atlas」ではウェブ上の要約・比較・分析・アクション実行までを一貫提供します[1]。

データフォーマットと使い方ガイドは、こうしたファイル活用を誰もが安心して始められるよう、プラン別の提供範囲も明示しています。ファイルアップロードは無料版（およびBusiness無料版）でも上限付きで利用可能で、有料のPlus、Pro、Business、Enterpriseでは継続的なドキュメント活用を支えるアップロード機能を提供します。チームや企業でのナレッジ活用に向けては、BusinessおよびEnterpriseで「社内ナレッジ」を提供し、Enterpriseでは「内部ソース向けのコネクター」により自社データソースとの接続も可能です。加えて、Plus、Pro、Business、Enterpriseでは「カスタム MCP コネクター向けの開発者モード（ベータ版）」を提供し、独自のデータ接続を柔軟に構成できます。対話内容の取り扱いと運用整備を後押しする「ChatGPT 記録モード」にも、Plus、Pro、Business、Enterpriseで対応しています[2][3][4][5]。

データフォーマットと使い方ガイドは、実務での再現性を高めるための使い方の進め方も提示します。まず、対象のPDFやプレゼンテーションデッキ、スプレッドシートをアップロードし、目的とアウトプット形式、対象箇所を明確に指示してください。たとえば「このマニュアルからクイックスタートガイドを作成して」「今四半期の会社の業績を要約して」「過去3年間の収益の傾向を教えて」「5章〜7章について考察のための質問をして」「この一節を初心者に向けて解説して」といった具体性のある指示により、要約・分析・質問生成・やさしい説明まで高精度に実行します。続けて、メールやスプレッドシートといった既存ツールとの連携や、Atlasによるウェブ情報の補完を組み合わせることで、日常の業務フローに自然に溶け込むナレッジ循環を実現できます[1]。

データフォーマットと使い方ガイドは、対応するデータ形式の範囲を明確化し、プラン別の機能提供と合わせて、個人から企業までが実務で再現性高く活用できるガイドを継続的に整備します。PDFを中心に、プレゼンテーションやスプレッドシートとの対話、ウェブブラウジングまでを横断する体験により、ドキュメントの理解・意思決定・共有を一体化して加速します[1][2][3][4][5]。

【出典】
[1] https://chatgpt.com/ja-JP/features/chat-with-pdfs/
[2] https://chatgpt.com/ja-JP/pricing?openaicom-did=b13b5acf-f74d-4ef9-9f12-a6d78d643978&openaicom_referred=true
[3] https://chatgpt.com/ja-JP/pricing?openaicom-did=e4be0c66-b079-4b4e-95b6-da1aa70072e7&openaicom_referred=true
[4] https://chatgpt.com/ja-JP/pricing?openaicom-did=4195bd3f-8ca0-43c6-8e6a-bdf9cbbbb154&openaicom_referred=true
[5] https://chatgpt.com/ja-JP/pricing?openaicom-did=1e30318c-cccc-47d9-8b74-61820bed57ae&openaicom_referred=true


## モデル
OpenAIは、モデルの公開・提供にあたり、望ましいモデル行動を明確に定義し、その評価と改良を継続するという公式見解を掲げています。OpenAIは、この目的のために、知的自由と透明性を重視しながら適切なガードレールを維持する「Model Spec」を公開し、アライメント評価用プロンプトとともにCreative Commons CC0で誰もが参照・再利用できる形で共有しています。Model Specは、爆弾の作り方のような有害な手順は決して提供せず、一方で政治的・文化的にデリケートな問いにも特定の意図を推進せず思慮深く応答するという原則を、運用上の具体的な行動規範として実装しています。公開後も透明性・カスタマイズ性・知的自由のバランスがより明確に反映されるよう改定し再公開しました。OpenAIは、コミュニティからのフィードバックを受け取りつつ、この指針と評価プロンプトを継続的に進化させます[1][2]。

OpenAIは、Model Specへの準拠度を現実世界に近い形で測定するため、一般的から複雑なシナリオまで含む挑戦的なプロンプト群を整備し、人間の専門家レビューと組み合わせて評価しています。その結果、昨年5月時点の当社最高システムと比べて最新モデルの準拠が大幅に改善したことを確認しており、差分の一部はポリシー更新に起因し得るものの、主因はアライメントの強化であると判断しています。OpenAIは、現実の利用で見つかる新たな課題を取り込み、Model Specとモデルの両面から継続的に改善を進めます[2]。

OpenAIは、モデルの安全行動を効率的に強化するため、ルールベース報酬（Rule-Based Rewards, RBR）を導入し、RLHFと統合してGPT‑4以降のモデルに適用しています。簡潔な命題とルールにより、非合法なヘイトスピーチや暴力犯罪の指示などは「断固とした拒否」、自傷行為に関する助言などは「柔らかい拒否」、無害な要求には通常どおり応答する、といった応答タイプを定義し、短い謝罪の有無など具体的な応答要件まで明示します。これにより、安全性と有用性のバランスを保ちながら過剰拒否を抑制し、ポリシー変更時の更新もしやすい運用を実現しています[3]。

OpenAIは、センシティブな会話における応答品質の強化にも注力しています。2025年10月のモデル更新では、GPT‑5の安全性を高め、精神疾患や自傷・自殺、AIへの感情的依存に関わる状況での不適切な応答を65〜80%削減しました。170名以上の精神科医や専門家と連携し、Model Specの原則に沿って、現実世界の人間関係への配慮、根拠のない信念を肯定しない姿勢、妄想や躁状態の兆候への安全かつ共感的な対応、間接的な自傷・自殺リスクシグナルへの一層の注意などを明確化しています。リリース前の新モデルも含め、メンタルヘルス文脈のターゲット評価を社内外で検証し、優先領域におけるChatGPTの応答を継続的に改善します[5]。

OpenAIは、領域特化の安全性・有用性評価として、医療分野の包括的ベンチマーク「HealthBench」を発表しました。60か国・262名の医師と協働し、5,000の対話と4万以上の評価ルーブリックで、緊急時のトリアージ、ユーザーの専門性に応じたコミュニケーション、適切な不確実性の伝達、回答の深さ、健康データタスクの安全な遂行などの観点からモデルを評価します。最新モデル（o3、GPT‑4.1等）は従来モデルより大幅に改善しましたが、信頼性や文脈把握には引き続き改善の余地があることも確認しています[4]。

OpenAIは、モデルの解釈可能性を高める研究として、スパースな回路（circuits）で複雑な挙動を実現するスパースモデルの訓練手法を検証しています。多数の重みをゼロに固定し、少数の可解読な回路で性能を維持しつつ振る舞いを説明可能にすることで、スケーラブルな監視や安全上の懸念の早期警告を支援し、レッドチーミングなど他の安全性向上の取り組みを補完します。思考の連鎖といった現在の観測手法は有益な一方で、それのみに依存する戦略は脆弱であるため、OpenAIは機械論的解釈可能性の原理に基づき、より根源的にモデル計算を理解できる道筋を探求します[6]。

OpenAIは、画像生成モデルの学習前対策として、DALL·E 2で暴力・性的な画像の除外、性別バイアスの再重み付け、データの重複排除（重複ペアの97%を特定し、データセットの約4分の1を除去）を実施し、人手評価で重複排除データで学習したモデルがやや好まれる結果を得ています。学習データのプロンプトを与えた場合でも、元画像の「吐き戻し」を起こさないことも確認しています[9]。

OpenAIは、言語モデルの品質向上に向け、ハルシネーションの根本原因と評価の課題を技術的に分析し、「不確かなら推測せずに棄権する」姿勢を評価に反映させる重要性を公表しています。次単語予測という学習設定の統計的限界が、もっともらしいが誤った出力を生みやすい構造的要因であることを示し、改善の方向性を明確にしています[7]。

OpenAIは、モデル提供時のプライバシー保護を徹底します。ChatGPT Free/Plusでは設定でモデル改善へのデータ提供を制御でき、Temporary Chatsは学習に使用しません。APIやEnterpriseの顧客データはデフォルトで学習に使用せず、インターネット上の公開情報からプロフィール作成・広告・ターゲティング・データ販売も行いません。モデルは問い合わせごとに新たな文章を生成し、後で思い出すためのデータベース保存を行わない設計を採用しています[8]。

OpenAIは、Model Specや評価プロンプトの公開、RBRとRLHFの統合、領域別ベンチマークの整備、センシティブ領域での安全性強化、解釈可能性研究の推進を通じて、モデルの安全性・有用性・透明性を継続的に高めます。OpenAIは、コミュニティと共に学習し、検証し、改良を重ねる開かれたプロセスを維持しながら、モデルの公開・提供・ポートフォリオ全体の質を前進させていきます[1][2][4]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/index/healthbench/
[5] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[6] https://openai.com/ja-JP/index/understanding-neural-networks-through-sparse-circuits/
[7] https://openai.com/ja-JP/index/why-language-models-hallucinate/
[8] https://openai.com/ja-JP/consumer-privacy/
[9] https://openai.com/ja-JP/index/dall-e-2-pre-training-mitigations/


## モデル仕様・性能（コンテキスト）
モデル仕様・性能（コンテキスト）は、ユーザーの入力（トーン、性格、長さなど）の文脈に即してモデルがどのように振る舞うべきかを定義するModel Specを公開し、その設計意図、トレードオフ、評価手法まで明確に開示しています。モデル仕様・性能（コンテキスト）は、広範なデータから学習するモデルの挙動形成がなお研究の初期段階にあることを踏まえつつ、文書をCreative Commons CC0でオープンにし、コミュニティのフィードバックとともに継続的に改訂します。また、知的自由と透明性を重視し、爆弾の作り方やプライバシー侵害の方法など危害をもたらす具体的手順は提供しない一方で、政治的・文化的にデリケートな質問にも特定の意図を押し付けず思慮深く応答する原則を掲げます[1][5]。

モデル仕様・性能（コンテキスト）は、現実世界の文脈での挙動を測るため、Model Spec各原則に対する準拠度を評価する挑戦的なプロンプト群をCC0で整備し、モデル生成と人間の専門家レビューを組み合わせて進捗を測定します。予備結果では準拠が大幅に改善しており、ポリシー更新に加えアライメント強化が寄与したと分析しています[5]。さらに、人間フィードバックの非効率を補うため、ルールベース報酬（RBR）をRLHFに統合し、安全性と有用性のバランスを保ちながら過剰拒否を抑制する仕組みを導入。これにより、有害・センシティブなリクエストに対する断固とした拒否や柔らかい拒否、無害なリクエストへの遵守といった文脈に応じた一貫した応答タイプをルールで明示し、更新容易性も高めています[3]。

モデル仕様・性能（コンテキスト）は、チャネル横断の文脈理解を基盤に据えています。たとえばGPT‑4oは、テキスト・音声・画像・動画を混在させた入力をリアルタイムで処理し、テキスト、論理的思考、コード生成ではGPT‑4 Turboと同等の性能を保ちつつ、多言語・音声・視覚情報で新たな最高水準を達成し、平均応答速度320msを実現します。こうしたマルチモーダルの文脈把握能力により、ユーザーが提供する多様なコンテキストを損なうことなく、迅速かつ一貫した応答が可能になります[4]。

モデル仕様・性能（コンテキスト）は、実務で扱える文脈スケールを選択できるよう、プラン別にコンテキストウィンドウの上限と応答特性を明示し、実際に提供しています。ChatGPTの「推論なし」のコンテキストウィンドウは、無料版とBusiness無料版が16K、PlusとBusinessが32K、ProとEnterpriseが128K、「推論あり」は無料版からPlus、Pro、Business無料版、Business、Enterpriseまで一貫して196Kです。応答時間はPlus/Pro/Businessで高速、Enterpriseで最速を提供し、モデルの進化に伴い品質と速度を定期的に更新します[6][7][2]。さらに、BusinessおよびEnterpriseの提供内容はビジネス向けの価格ページでも明確に案内しており、長文や大量ドキュメントの取り扱いに耐える設計を継続的に強化しています[2]。

モデル仕様・性能（コンテキスト）は、このように行動仕様（Model Spec）、安全性最適化（RBR+RLHF）、マルチモーダル能力（GPT‑4o）、およびプラン別のコンテキストウィンドウ仕様を統合したアプローチで、透明性と知的自由を堅持しながら、現実世界での有用性と安全性を両立する“コンテキストに強いモデル”の提供を継続的に改善していきます[1][3][4][5][6][7][2]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/business/chatgpt-pricing/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/index/hello-gpt-4o/
[5] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[6] https://chatgpt.com/ja-JP/pricing?openaicom-did=daaffb01-4c02-4974-8eac-4e7625d01580&openaicom_referred=true
[7] https://chatgpt.com/ja-JP/pricing?openaicom-did=eee7c3cf-4181-485d-8823-34feac13c804&openaicom_referred=true


## モデル仕様（マルチモーダル）
モデル仕様（マルチモーダル）は、マルチモーダル時代の基盤となるモデル行動の仕様を公開・改定し続け、カスタマイズ性・透明性・知的自由を重視しながら、危害防止のガードレールを堅持します。とりわけ「範囲内に留まる」と「共に真実を追求する」という原則に基づき、爆弾の作り方や個人のプライバシー侵害の手順などの詳細な有害行為は提供しない一方で、重大な危害がない限り、政治・文化的にデリケートな問いには特定の意図を推進せず思慮深く答え、いかなるアイデアも議論の対象となり得るという知的自由の立場を明確に掲げます[1]。

モデル仕様（マルチモーダル）は、望ましいモデル行動とトレードオフ評価の考え方を示すModel Specの初版を公開し、モデルが広範なデータから学習するという特性を踏まえた一般原則と、開発者・エンドユーザー双方を支援する枠組みを提供しました。Model Specおよび評価用プロンプトはCreative Commons CC0で公開し、コミュニティからのフィードバックを取り入れながら継続的に改善していきます[2]。さらに、現実世界での準拠度を測るために各原則への適合を試す挑戦的なプロンプト群を収集・評価し、昨年5月時点の最高システムと比べて大幅な準拠改善を確認しつつ、引き続き成長余地があることを認識しています[1]。

モデル仕様（マルチモーダル）は、視覚とテキストを統合した推論を前提に設計・提供します。o3およびo4‑miniでは、画像をChain‑of‑Thought（思考の連鎖）に直接組み込むことを初めて可能にし、「見る」だけでなく「使って考える」推論を実現しました。加えて、ツールの使い方だけでなく、どの状況でツールを使うべきかという論理的判断を強化し、視覚的な論理的思考や多段階ワークフローを伴うオープンエンドな課題で高い能力を発揮するよう学習させています[3]。ポートフォリオの中核として、モデル仕様（マルチモーダル）は研究段階から実運用まで一貫して公開・提供を行い、GPT‑4を「画像とテキストを入力できる大規模マルチモーダルモデル」として提示し、画像入力は研究プレビューとして、利用経路はAPIおよびChatGPT Plusで提供してきました[8]。

モデル仕様（マルチモーダル）は、2024年7月18日に小型かつコスト効率に優れたマルチモーダル対応モデル「GPT‑4o mini」を発表しました。GPT‑4o miniは、128Kトークンの長大なコンテキスト、マルチモーダル対応および関数呼び出し（Function Calling）機能を備え、ChatGPT Free/Plus/Teamで即日利用可能です。外部ベンチマークでも堅実な推論性能を示し、マルチモーダル推論を測るMMMUで59.4%を記録しました（比較参照値：Gemini Flash 56.1%、Claude Haiku 50.2%）。また、領収書ファイルからの構造化データ抽出や、スレッド履歴が付与された状況での高品質なメール応答生成といった実務タスクで、GPT‑3.5 Turboを大幅に上回ることを確認しており、文書・ファイル理解を伴う実タスクにおけるマルチモーダル適性を裏づけています[5]。

モデル仕様（マルチモーダル）は、マルチモーダル能力の客観評価と透明性を推進します。Evaluations Hubを運用してモデルの安全性と性能の評価結果を共有し[4]、メッセージの優先度に従う「指示階層」など、テキストベースの指示に関する安全性評価の結果を定期的に更新・公開します[7]。安全な仕様の実装に向けては、RLHFを補完するルールベース報酬（RBR）を導入し、「断固とした拒否」「柔らかい拒否」「従う」といった応答タイプや謝罪の入れ方を簡潔な命題とルールで規定して安全行動を強化。過剰拒否を抑えつつ有用性とのバランスを保ち、更新容易な手法としてGPT‑4以降に適用しています[6]。さらに、熟慮的アライメントや指示階層を用いた事後学習により、不安全なプロンプトの拒否やプロンプトインジェクションの防止を学習させる取り組みも進めています[7]。

モデル仕様（マルチモーダル）は、これらの原則と仕組みをマルチモーダルモデルにも一貫して適用し、知的自由と安全性の両立を図りながら、コミュニティと共にモデル仕様を進化させます。評価用プロンプトや公開ベンチマーク、そしてEvaluations Hubを通じて、現実世界での性能と準拠度を継続的に測定・公開し、ユーザーと開発者の目標達成を支援していきます[1][2][4][5]。

【出典】
[1] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[2] https://openai.com/ja-JP/index/introducing-the-model-spec/
[3] https://openai.com/ja-JP/index/introducing-o3-and-o4-mini/
[4] https://openai.com/ja-JP/safety/evaluations-hub/
[5] https://openai.com/ja-JP/index/gpt-4o-mini-advancing-cost-efficient-intelligence/
[6] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[7] https://openai.com/ja-JP/index/introducing-gpt-oss/
[8] https://openai.com/ja-JP/index/gpt-4-research/


## モデル公開・ライセンス方針
モデル公開・ライセンス方針は、安全性・透明性・知的自由のバランスの上に公開とライセンスの枠組みを構築し、広いアクセスを可能にしながら責任ある提供を進めます。AIが公共の議論やイノベーションを牽引する時代において、情報と視点の自由な交換を尊重しつつ、危害に結びつく詳細な手順の提供は行わないという原則を明確に掲げ、関連ポリシーとあわせて運用します[1][2]。

モデル公開・ライセンス方針は、モデルがとるべき挙動の設計図としてModel Specを策定し、アライメント評価用プロンプトとともにCreative Commons CC0（パブリックドメイン）で公開しています。知的自由と透明性を重視してコミュニティから広くフィードバックを受け付け、今後1年間にわたり、変更点やフィードバック対応、モデル動作を形成する研究の進捗を定期的に共有します。また、現実世界の利用シナリオを含む挑戦的なプロンプトセットを収集・拡充し、人間の専門家レビューと組み合わせて準拠度を評価するプロセスを整備しており、前年5月時点の最高システムと比べて準拠度が大幅に改善していることを確認しています[3][1]。

モデル公開・ライセンス方針は、オープンウェイトの提供にあたって適切なオープンライセンスを採用します。たとえば、gpt‑oss‑120bとgpt‑oss‑20bはApache 2.0ライセンスおよびgpt‑oss利用規約の下で利用可能で、Hugging FaceおよびGitHubからダウンロードでき、Responses APIと互換性を持ちながら指示追従、ツール利用、思考の連鎖や構造化出力などのユースケースを想定して公開しています。安全性のカスタム適用を支援するgpt‑oss‑safeguardも併せて提供します。同時に、オープンモデルはクローズドな提供形態とは異なるリスク特性（悪意のあるチューニングや安全措置の回避が技術的に可能、当社が一方的にアクセスを取り消したり追加の安全策を強制できない等）を持つことを明言し、状況に応じて開発者・企業側で追加の安全対策を実装する必要があるとの立場を示します。これらのモデルについては「システムカード」ではなく「モデルカード」を提供し、多様な関係者が構築・管理する広範なシステムに組み込まれる前提を透明化しています[4][5]。

モデル公開・ライセンス方針は、知的財産の運用においても広範なアクセス・協力・安全性という原則を重視し、イノベーションを支え使命の達成を後押しするために特許を活用します。同時に、第三者が当社やユーザーに対して脅迫や請求、訴訟等を行わない限り、特許は防御的にのみ使用することを誓約し、オープンなエコシステムに資する運用を徹底します[6]。

モデル公開・ライセンス方針は、外部評価とアクセスの設計を公開方針の重要な柱と位置づけます。第三者評価者に対して、原則として公開用または本番運用向けの情報・モデルへのアクセスを提供し、評価上の必要に応じてhelpful‑onlyモデルや非公開情報などのより深いアクセスも付与します。その際は厳格なセキュリティ対策を適用し、モデル能力やテストニーズの進化に応じて管理手段を更新します。評価の持続可能性のため、作業への直接支払いまたはAPIクレジット等の形で報酬を提供しますが、報酬が評価結果に左右されることはありません。過去数年にわたり、システムカード等で評価サマリーを公開し、METRやApollo Research、Irregularといった外部組織の評価レポートの公表も併せて実現しています[7]。

モデル公開・ライセンス方針は、生成コンテンツの来歴表示にも配慮します。たとえばSoraの早期アクセス運用では、出力動画にC2PAメタデータを埋め込み、アーティストからのフィードバックを踏まえて、C2PAメタデータは維持しつつ有料ユーザーが透かしなしで動画をダウンロードできる選択肢を提供しました。あわせて、プロンプトフィルタリングやブロックリスト、分類器の閾値など安全対策の調整も行っています[8]。

モデル公開・ライセンス方針は、公開・ライセンス・利用に関する運用を支える包括的な規約・ポリシー群を整備し、サービス規約、利用規定、共有と公開に関するポリシー等を通じて、技術の責任ある利用と共有を徹底します。今後もコミュニティとともにModel Specを進化させ、安全性の確保と知的自由の両立を図りながら、オープンなアクセスと責任ある公開・ライセンスの在り方を前進させます[2][1][3]。

【出典】
[1] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[2] https://openai.com/ja-JP/policies/
[3] https://openai.com/ja-JP/index/introducing-the-model-spec/
[4] https://openai.com/ja-JP/index/gpt-oss-model-card/
[5] https://openai.com/ja-JP/open-models/
[6] https://openai.com/ja-JP/approach-to-patents/
[7] https://openai.com/ja-JP/index/strengthening-safety-with-external-testing/
[8] https://openai.com/ja-JP/index/sora-system-card/


