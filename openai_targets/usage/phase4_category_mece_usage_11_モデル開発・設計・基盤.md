# モデル開発・設計・基盤

## 概要


### 基本姿勢
OpenAIは、推論力を核に据えたマルチモーダルのモデル開発・設計・基盤を「安全性・有用性・透明性」の三原則で前進させます。OpenAIはModel SpecとRLHF+RBR、運用時の推論型セーフティ（Safety Reasoner/gpt‑oss‑safeguard）を中核に、研究・訓練・評価・運用を一体で設計します。OpenAIはAzure×NVIDIAのクラウドとApache‑2.0のgpt‑oss群によるローカルを両輪に、スケールとコスト効率（適応的推論・24時間プロンプトキャッシュ・SLA基盤）を両立します。

### 重点的取り組み
OpenAIはo3/o4‑miniやGPT‑5.2で“考える”アーキテクチャを強化し、画像を使って考える推論、信頼できるツール実行、196Kコンテキストとエージェント実行を実装します。OpenAIはPreparedness/外部評価/HealthBenchと推論型セーフティによる多層防御を標準化し、メンタルヘルス等センシティブ会話での不適切応答を大幅に削減しました。OpenAIはScale Tier/Priority Processing、H100/H200/GB200‑NVL72による学習基盤、MXFP4量子化のgpt‑oss‑120b/20bの広範展開で、クラウド/オンデバイスの選択肢を拡充します。

### 重要事実
OpenAIはAIME 2025でo4‑miniがツール使用下でpass@1 99.5%、o3が98.4%を達成し、GPT‑5はMMMU 84.2を記録、GPT‑5.2はTau2‑bench(通信)で98.7%と長文推論の誤りを大幅削減しました。OpenAIはAPIで適応的推論と24時間プロンプトキャッシュを提供し、Scale Tierは99.9%稼働率とレイテンシSLA、Priority Processingは混雑時でも高速応答を提供します。OpenAIはgpt‑oss‑120b/20bをApache‑2.0で公開（80GB/16GB動作、主要スタック対応）し、安全推論に最大16%の計算を投じる運用でSora等の生成もリアルタイムに保護しています。


## CLIP埋め込み二段階生成モデル
CLIP埋め込み二段階生成モデルは、テキストから画像を生成する際に、CLIPの画像埋め込みを中間表現として明示的に生成・活用する二段階（prior + decoder）の階層的アプローチを採用し、2022年4月13日にその成果を公開しました[1][2]。CLIP埋め込み二段階生成モデルは、テキストキャプションからCLIP画像埋め込みを生成するpriorと、その埋め込みを条件として画像を合成するdecoderから構成され、意味とスタイルを捉えるCLIPのロバストな表現を直接活用することで、フォトリアリズムやキャプションとの整合性を維持しながら、生成画像の多様性を高められることを示しました[1][2]。

CLIP埋め込み二段階生成モデルは、decoderに拡散モデルを採用し、priorには自己回帰モデルと拡散モデルの両方を検討した結果、拡散型のpriorが計算効率に優れ、より高品質なサンプルを生成できることを確認しています[1][2]。さらに、画像表現を条件とするdecoderによって、埋め込みに含まれない非本質的な詳細のみを変化させつつ、元の意味とスタイルを保持した画像バリエーションを生成できることを実証しました[1][2]。加えて、CLIPの結合埋め込み空間を活用することで、言語ガイドによる画像操作をゼロショットで実現できることも示しています[1][2]。

CLIP埋め込み二段階生成モデルは、こうした設計の基盤にあるCLIPの特性を重視します。CLIPは、未フィルタで多様かつノイズを含むインターネット規模の画像と言語のペアから学習し、タスク固有の最適化を行わずに自然言語によるゼロショット実行を目指した柔軟で汎用的なモデルであり、自然言語から幅広い視覚概念を直接学習して多様なタスクに汎化できることが示されています[3][4]。学習にはテキストと画像の関連付けに対照学習目的を採用し、Vision Transformerの活用により計算効率を高め、最も高性能なモデルは256 GPUで2週間の学習を実施しました[4]。また、30以上のデータセット（精細分類、ジオローカライゼーション、動画中の行動認識、OCRなど）でゼロショット性能が評価され、その広範な汎化能力が確認されています[3][4]。これらの知見が、CLIPの埋め込みを二段階生成の条件として用いるというCLIP埋め込み二段階生成モデルの設計選択の有効性を力強く裏付けています[1][2][3][4]。

【出典】
[1] https://openai.com/ja-JP/index/hierarchical-text-conditional-image-generation-with-clip-latents/
[2] https://openai.com/index/hierarchical-text-conditional-image-generation-with-clip-latents/
[3] https://openai.com/ja-JP/index/clip/
[4] https://openai.com/index/clip/


## GPU資源拡張とコスト最適化
GPU資源拡張とコスト最適化は、モデル開発・設計・基盤における中核戦略として、インフラの強化、推論効率の最大化、展開柔軟性の拡充という三つの軸を一体で推進します。ハードウェア・ソフトウェア両面の協業と最適化を重ね、研究から実装、配布までを途切れなく結び、開発者とユーザーの体験を継続的に高めます。

GPU資源拡張とコスト最適化は、長年のパートナーであるNVIDIAおよびMicrosoftと連携し、H100、H200、GB200‑NVL72を含むNVIDIA GPUとAzureデータセンターによって大規模学習インフラを構築・運用し、計算リソースの拡張性を確実に確保します。これにより、新しいモデルをより迅速に提供できる体制を継続的に強化します[2]。また、コンピューティング規模の拡大が新しい機能を生み出すという前提に立ち、スケールがもたらす能力向上を安全かつ着実に実装していきます[3]。

GPU資源拡張とコスト最適化は、推論効率とコストの最適化でも前進しています。GPT‑5.1に導入した「適応的推論」により、タスクの難易度に応じて思考トークンを動的に調整し、応答速度の向上とトークンコストの削減を両立しました。さらに、24時間保持のプロンプトキャッシュを提供し、再利用によるコストとレイテンシの低減を実現しています。外部検証として、Balyasny Asset ManagementはGPT‑5.1がGPT‑5比で2〜3倍高速かつ同等以上の品質を維持しながら、主要競合モデルの約半分のトークン数で安定動作したと評価し、Paceもエージェントの動作が50%高速化し精度も向上したと報告しています[4]。

GPU資源拡張とコスト最適化は、展開の柔軟性と資源活用を最大化するため、オープンウェイトモデルgpt‑oss‑120bおよびgpt‑oss‑20bをApache‑2.0で公開しました。MXFP4による数値化（量子化）により、120Bモデルを80GB、20Bモデルを16GBのメモリ環境で動作可能にし、PyTorchおよびApple Metal向けの推論リファレンス実装やハーモニーレンダラーをオープンソース化して、ローカル・デバイス・サードパーティ推論プロバイダーのいずれでも容易に実行できる設計としています。Hugging Faceでの配布に加え、Azure、vLLM、Ollama、llama.cpp、AWS、Cloudflare、Databricks、Vercel、Together AI、Baseten、Fireworks、LM Studio、OpenRouterなど主要な展開プラットフォーム、並びにNVIDIA、AMD、Cerebras、Groqと広く連携し、多様なシステム全体で最適性能を確保します。また、MicrosoftはONNX Runtimeを用いたgpt‑oss‑20bのGPU最適化版をWindowsデバイスに導入し、Foundry LocalおよびVS CodeのAIツールキットから利用可能とすることで、ローカル推論の選択肢を拡充しています。GPU資源拡張とコスト最適化は、ローカル実行とクラウド基盤の双方を柱に、運用形態に応じた最適化を継続します[1][2]。

GPU資源拡張とコスト最適化は、オープンモデルとAPIの両輪で開発者の選択肢を広げます。完全にカスタマイズ可能なオープンウェイトモデルは独自環境でのファインチューニングと展開に適しており、当社APIプラットフォームのモデルはマルチモーダル機能、内蔵ツール、プラットフォーム統合の利点を提供します。将来的なgpt‑ossのAPIサポートも検討しつつ、オープンモデルを既存のAPIに追加することで研究を加速し、幅広いユースケースでより安全かつ透明性の高いAI開発を可能にしていきます[1]。

GPU資源拡張とコスト最適化は今後も、ハードウェアパートナーとの協業を一層深めるとともに、モデルと推論パスの最適化を進め、計算リソースの拡張と高効率化を両立する取り組みを継続します。コンピューティングのスケールで得られる新たな能力を安全かつ迅速に提供し、開発者とユーザーにとって持続可能な基盤を構築していきます[2][3]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-gpt-oss/
[2] https://openai.com/ja-JP/index/introducing-gpt-5-2/
[3] https://openai.com/ja-JP/index/introducing-gpt-4-5/
[4] https://openai.com/ja-JP/index/gpt-5-1-for-developers/


## コスト・レイテンシ効率化
コスト・レイテンシ効率化は、モデル開発から推論運用までの全体最適を軸に、コストとレイテンシの両立を公式方針として推進します。エンタープライズのお客様には、需要ピーク時でも安定したスループットと明確なSLAを備えるスケールティアと、柔軟な従量課金で高速応答を実現するAPI優先処理を用意し、ワークロード特性に合わせた最適な選択肢をお届けします[1][2]。

コスト・レイテンシ効率化は、スケールティアにより、1分あたりの入出力トークン数（トークン単位）を前払いで購入し、専用モデルのスナップショットにアクセスできる仕組みを提供します。購入したクォータはレート制限に自動追加され、ピーク時でも従量課金より速く、かつ一定の速度でトークンを生成することを目指した設計で、スケールに上限のない拡張性、99.9%の稼働率SLA、優先的な計算リソース、レイテンシSLAを備えます[1]。各トークン単位には30日間の購入下限を設け、たとえばGPT-4.1で「99% > 80トークン/秒」、GPT-4.1 miniで「99% > 90トークン/秒」といった具体的な指標で低遅延を担保し（入出力のトークンバンドルを提供）、予測可能な遅延と明確な性能保証を通じて、運用コストの計画性とレイテンシ効率化を同時に達成します[1]。

コスト・レイテンシ効率化は、従量課金で高い応答性能が求められるケースに向けてAPI優先処理（service_tier="priority"）を提供します。ピーク時でも安定して高速なレスポンスを目指しつつ、ランプレート（急激なトラフィック増）に対する保護を設け、TPM（Tokens Per Minute）が100万以上で15分未満にTPMが50%以上増加する状態を上限と定義しています。この条件に該当する増加が続く場合は一部の優先リクエストが標準処理へ切り替わり、当該リクエストは標準料金・標準SLOの適用となり、レスポンスにはservice_tier="Default"が含まれます。エンタープライズのお客様には、優先処理のSLAをスケールティアと同様に適用し、所定期間にSLA未達があればサービスクレジットを提供します[2]。

コスト・レイテンシ効率化は、安定運用のためのガイダンスも提供します。モデルやスナップショットの切り替え時は、機能フラグ等を用いた段階的なトラフィック移行を推奨し、大規模なデータ処理や非同期ジョブなど、トラフィックが急増しやすく優先処理の高いパフォーマンスを必須としない用途では優先処理の利用を控えるようご案内します。ランプレート上限に頻繁に達する場合は、スケールティアの容量追加または代替としての購入をご検討ください。なお、ランプレート上限はプロジェクトや組織間で共有されます[2]。

あわせてコスト・レイテンシ効率化は、学習コストそのものの効率化にも取り組み、ルールベース報酬（RBR）を導入しています。RBRは簡潔な命題やルールに基づく報酬設計により、安全な挙動の強化をコスト効率よく実現し、モデル性能やガイドラインの変化に応じて大規模な再学習を行わずに迅速な更新を可能にします。また、有用性（正しく応諾した安全なプロンプトの割合）と安全性（正しく拒否した安全でないプロンプトの割合）のトレードオフを明示的に評価し、「安全かつ有用」なモデルへの調整を目標に据え、人間のフィードバックとの組み合わせで繊細な領域にも対応します。これにより、開発の反復コストを抑えつつ、安全性要件を満たすモデル改良を加速します[3]。

これらの基盤施策は実利用でも成果を上げています。ENEOSマテリアルでは、deep researchにより従来「数ヶ月」要した調査を「数分」に短縮し、人事業務でも集計・分析時間を90%以上削減、設備設計のカスタムGPTではたたき台作成を「数十分」から「数秒」へと短縮し、設計の信頼性やコスト最適化にも寄与しました[4]。大日本印刷（DNP）では、ChatGPT Enterprise導入後わずか3ヶ月でユースケースの90%が効果を実証し、週次アクティブ率100%、作業自動化率87%、処理量10倍を達成。Python未経験者が学習コストゼロでコードを作成し、従来1年以上かかった開発作業を数日で実装するなど、スループットと品質を同時に高めています[5]。さらに、ChatGPT Businessの導入企業では、88%のユーザーが週2時間以上の業務時間を削減し、ワークスペース統合や自動化が組織全体の効率化に寄与しています[6]。

コスト・レイテンシ効率化は、スケールティアと優先処理を核とするAPI基盤と、RBRをはじめとする学習面の工夫を統合し、SLAで裏付けられた安定性能、予測可能な遅延、柔軟なスケール、そして学習コストの効率化を一体的に提供し続けます[1][2][3]。

【出典】
[1] https://openai.com/ja-JP/api-scale-tier/
[2] https://openai.com/ja-JP/api-priority-processing/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/index/eneos-materials/
[5] https://openai.com/ja-JP/index/dai-nippon-printing/
[6] https://chatgpt.com/ja-JP/business/ai-for-finance/


## マルチモーダル処理対応
マルチモーダル処理対応は、OpenAIのモデル開発・設計・運用基盤の中核能力として継続的に強化されるべき対象であり、その実現のために研究から製品提供、運用に至るまで一貫した取り組みを進めています。GPT‑4o の開発では、マルチモーダル領域に専任のリーダーシップを配置し、Prafulla Dhariwal を責任者として多数のコア貢献者が横断的に参画する体制を整え、研究的ブレイクスルーと実運用の両面で機能拡張を加速しました[1]。

マルチモーダル処理対応は、o3 および o4‑mini において「画像を使って考える」設計を採用し、画像をChain‑of‑Thought（思考の連鎖）に直接取り込みながら推論する新しい能力を実装しました。これにより、視覚情報とテキストの論理的思考を統合し、視覚的文脈を伴う高度な推論や多段階ワークフローでも一貫した思考過程で解を導きます。さらに、強化学習を通じてツールの使用そのものと、使用判断に関する推論も学習させ、学術ベンチマークと実世界タスクの双方での改善を確認しています[2]。

マルチモーダル処理対応は、軽量モデルでも実用的な価値を提供することを重視しています。GPT‑4o mini はマルチモーダル推論の評価指標である MMMU で59.4%を記録し、コスト効率と多様なタスク適用性の両立を示しました。加えて、パートナー企業との検証では領収書ファイルからの構造化データ抽出などの現実的なワークロードで GPT‑3.5 Turbo を大きく上回る性能を確認し、現場での有用性を裏づけています[3]。

フラッグシップモデルでも、マルチモーダル処理対応は基礎性能を段階的に引き上げています。GPT‑4.5 は MMMU で74.4%を達成し、GPT‑4o から有意に改善しました[7]。さらに、GPT‑5 では視覚・動画・空間・科学的推論を含む広範なマルチモーダルベンチマークで卓越した結果を示し、MMMU でも84.2%を記録。これにより ChatGPT は、チャートの解釈、プレゼンテーション写真の要約、図に関する質疑など、テキスト以外の入力に対しても高精度な推論を実現しています[6]。

運用基盤においても、マルチモーダル処理対応はエンタープライズ要件に応えるための低レイテンシ運用を標準化しています。優先処理（Priority Processing）は標準のマルチモーダル機能にそのまま対応し、画像入力も同一の低レイテンシで処理します。今後登場する新しい GPT モデルにも順次対応（対象はモデルにより異なる可能性あり）し、ピーク時でも予測可能な待ち時間での利用を支えます[4]。あわせて、スケールティア（Scale Tier）でも従量課金と同等のマルチモーダル機能をサポートし、画像入力を短い遅延で処理できることを保証します[5]。これらの選択肢により、マルチモーダルワークロードはビジネスクリティカルな場面でも安定してスケールします。

マルチモーダル処理対応は、専任の研究開発体制、思考過程への画像統合といったモデル設計上の前進、ベンチマークと実タスクでの実証、そしてエンタープライズ基盤による安定提供を通じて、今後もエンドツーエンドでの体験価値を継続的に引き上げていきます[1][2][3][4][5][6][7]。

【出典】
[1] https://openai.com/ja-JP/gpt-4o-contributions/
[2] https://openai.com/ja-JP/index/introducing-o3-and-o4-mini/
[3] https://openai.com/ja-JP/index/gpt-4o-mini-advancing-cost-efficient-intelligence/
[4] https://openai.com/ja-JP/api-priority-processing/
[5] https://openai.com/ja-JP/api-scale-tier/
[6] https://openai.com/ja-JP/index/introducing-gpt-5/
[7] https://openai.com/ja-JP/index/introducing-gpt-4-5/


## モデルR&Dとプロダクト連携
モデルR&Dとプロダクト連携は、研究開発とプロダクトを中核戦略として一体で前進させ、モデルの設計思想・評価手法・安全対策を同時に進化させます。その要となるのが、望ましいモデル行動の指針「Model Spec」です。モデルR&Dとプロダクト連携はModel Specを改定・公開し、知的自由と透明性を重視しながら、危害につながる行為の助長は断固として避けるという原則を明確化しました。具体的には、爆弾の作り方やプライバシー侵害の手順は提供せず、一方で政治・文化などデリケートな論点には特定の意図を推進しない思慮深い応答を推奨し、重大な危害を及ぼさない限りあらゆるアイデアは議論の対象になり得るという立場を採用しています。また、Model Specとアライメント評価用プロンプトをCreative Commons CC0で公開し、コミュニティからのフィードバックを受けて継続的に改善します[1][2]。

モデルR&Dとプロダクト連携は、現実世界での準拠度と有用性を同時に高めるため、評価設計と計測を運用プロセスに組み込みました。Model Specの各原則に対する準拠を測る挑戦的なプロンプト集合を整備し、人間の専門家レビューと組み合わせて評価します。予備結果では、前年5月時点の当社最高システムと比べてModel Spec準拠が大幅に向上しました。進歩を認めつつ、実利用で生まれる新しい事例を取り込みながら課題セットとモデルの両面を継続的に更新し、改善状況や研究の進捗を定期的に共有し続けます[2]。

安全性と有用性の最適な両立に向けて、モデルR&Dとプロダクト連携はルールベース報酬（RBR）を導入し、RLHFに統合してモデルの安全行動を明確な命題とルールで強化しています。有用性（安全なプロンプトへの正しい応諾）と安全性（安全でないプロンプトの正しい拒否）のトレードオフを定量的に追跡し、過剰拒否を避けつつ右上の最適領域を目指します。RBRは大規模な再学習を必要とせず迅速に更新でき、Model Specのルールに準拠するよう設計可能で、主観性の高い課題には人間フィードバックと組み合わせることで柔軟に対処します[3]。

モデルR&Dとプロダクト連携は、Model Specの原則を具体的なプロダクト挙動に落とし込んでいます。たとえば「適用法の遵守」により違法行為の助長を拒否しつつ、小売事業者の防犯ニーズには適切に応えるという、文脈に応じた応答差を明確化しています。また「指揮系統に従う」により、API利用時には開発者の指示を優先する設計を取り、ユーザーと開発者の指示が矛盾する場合の権限関係を定義します。知識の性質上、意図しない悪用が生じ得る場合には、利用規約に基づくアカウント対処も行います[1][2]。

プロダクト側でも、モデルR&Dとプロダクト連携はセンシティブ領域での安全性を重点強化しています。最近のモデル更新では、メンタルヘルス、自傷・自殺、AIへの感情的依存といった会話での応答改善に注力しました。既存原則に沿って、ユーザーの現実世界の関係性を尊重し、根拠のない信念を安易に肯定せず、潜在的な妄想や躁状態の兆候には安全かつ共感的に対応し、間接的なリスクシグナルにも注意を払うようモデル行動を明確化。問題の定義、測定の開始、専門家との検証、リスクの軽減というステップで推進し、将来のモデルリリースに向けた安全性テストの標準ベースラインを拡充していきます[4]。

さらにモデルR&Dとプロダクト連携は、レッドチーミングや多層の保護策を含む安全スタックを製品化プロセスに直結させています。Soraでは、リリース前に暗示的プロンプトや比喩など敵対的手法で継続検証し、得られたフィードバックに基づきプロンプトフィルタリングやブロックリスト、分類器の閾値を調整。入出力フィルタリングや人物を含むメディアアップロードの保護策も改善し、9か月にわたる60カ国以上・300名超のクリエイターによる早期アクセスから運用知見を収集しました[7]。

基礎研究でも、モデルR&Dとプロダクト連携は解釈可能性の前進に取り組んでいます。「スパース回路」に基づくアプローチでは、モデルの大部分の重みをゼロに固定したスパースモデルを訓練し、少数の可解読な回路で複雑な振る舞いを再現できることを実証。必要・十分な接続を同定し、接続の除去でタスクが機能しなくなることも示し、変数バインディングのような複雑な振る舞いについても予測可能性を高める部分的説明を提示しています[8]。

研究とプロダクトの連携は、パートナー企業との共創にも現れています。Doppelとは、強化ファインチューニング（RFT）を用いて検知モデルの一貫性を高め、人間のレビューを学習ループに組み込んで曖昧なエッジケースでも専門家判断を再現。正確性に加えて説明の品質を評価する採点機能を共に設計し、明確な推論に報酬を与える仕組みを構築しました。最新モデル（GPT‑5およびo4‑mini）とRFT、ハイパーパラメータチューニング、反復評価の組み合わせにより、一貫性は人間レベルに近づいています[5]。

エンタープライズ導入においても、モデルR&Dとプロダクト連携はR&D成果をプロダクトとして提供し、現場の業務要件に適合させています。ChatGPT Businessのデータサイエンス＆アナリティクス向けソリューションでは、統合ワークスペースで特徴量パイプラインから成果物化までを支援し、自動のモデルドリフト検知・レポート、再利用可能アセット化、SSOや多要素認証などのセキュリティ・コラボレーション機能を提供します[9]。ライフサイエンス向けにはHIPAAおよびSOC 2 Type 2準拠のChatGPT EnterpriseやAPIを用意し、ネイティブコネクターやMCPでエンタープライズデータをすべてのプロンプトに統合できる仕組みを提供します[10]。

こうした取り組みは実運用でも成果を上げています。ENEOSマテリアルでは、ChatGPTのdeep researchにより従来数ヶ月かかった調査を数十分に短縮し、専門性の高い計算や調査も数分で実行。社内の設計ガイドラインや標準を組み込んだカスタムGPTをプラント設計に活用し、流体条件や材質要件などを同時考慮して最適仕様を迅速に提示、設計初期の検討を数秒へ短縮して「時間削減 × 安全性向上」を同時に実現しました[6]。大日本印刷（DNP）は、ChatGPT Enterpriseを10部門に導入し、3か月でユースケースの90%が効果を実証。週次アクティブ率100%、作業自動化率87%、ナレッジ再利用70%、処理量10倍を達成し、Python未経験者でも対話を通じてコード生成・解析を実現、従来1年以上の開発作業を数日で実装しました[11]。Intercomは、GPT‑4の提供直後から数時間で実験を開始し、4か月でAIエージェントFinをリリース。GPT‑4.1をFin Tasksの主要ロジックに採用し、完全なRAGパイプラインを用いずに複雑なワークフローを処理し、非検索系の問い合わせにはChain-of-Thoughtプロンプトで性能を補完しました[12]。

モデルR&Dとプロダクト連携は、公開されたModel Spec、評価プロンプト、RBRによる安全調整、専門家との連携、そしてお客様との共創を通じて、研究とプロダクトを密接に結びつけます。コミュニティのフィードバックを取り入れながらモデル行動を継続的に改善し、現実世界で安全かつ有用に機能するAIを提供し続けます[1][2][3][4][5][6][7][8][9][10][11][12]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[5] https://openai.com/ja-JP/index/doppel/
[6] https://openai.com/ja-JP/index/eneos-materials/
[7] https://openai.com/ja-JP/index/sora-system-card/
[8] https://openai.com/ja-JP/index/understanding-neural-networks-through-sparse-circuits/
[9] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/
[10] https://openai.com/ja-JP/solutions/industries/life-sciences/
[11] https://openai.com/ja-JP/index/dai-nippon-printing/
[12] https://openai.com/ja-JP/index/intercom/


## モデルの特徴と提供形態・対象
モデルの特徴と提供形態・対象は、「知的自由とガードレールの両立」を核に設計し、実運用での安全性と有用性を同時に前進させます。私たちはModel Spec（モデル行動の指針）を改定・公開し、爆弾の製造やプライバシー侵害の詳細手順は決して示さず、一方で政治的・文化的にデリケートな問いには特定の意図を推進しない思慮深い応答を行うという原則を明確化しました。重大な危害が生じない限り、どのようなアイデアも議論対象となり得るという立場を強化し、現実世界のパフォーマンスを把握するための挑戦的な評価プロンプト集を用いて準拠度を継続的に測定しています。社内の予備的結果では、昨年5月時点の最高システムと比べてModel Specへの準拠が大幅に改善していることを確認しており、この指針はCC0で公開、価値の衝突やトレードオフに対処する判断枠組みと、開発者・エンドユーザーの目標達成を支援する一般原則を併せて提示しています[1][2]。

OpenAIは、望ましいモデル行動を実装に落とし込むため、ルールベース報酬（RBR）をRLHFと統合して適用し、有害・デリケートな話題における望ましい応答を「断固とした拒否」「柔らかい拒否」「従う」の三つに設計しました。断固とした拒否では冗長や批判的な言葉を避けつつ短い謝罪と不実行の明示、柔らかい拒否ではユーザーの感情状態を認めたうえで最終的に応じない共感的な謝罪、無害の要求には従う、という具体ルールにより、過剰拒否の抑制と一貫した振る舞いを両立します[3]。同時に、指示追従性を高める学習が危険な出力への脆弱性を高め得る点を踏まえ、モデルが特定の指示を適切に拒否できる能力を確保する研究を継続し、ラベラー嗜好の偏りや英語中心の価値観の偏在を是正し、特定コミュニティの価値に基づく制約を可能にする包括的プロセスを整備します[7]。

モデルの特徴と提供形態・対象は、センシティブな会話における回答の強化を優先領域として進めています。特に、1) 精神病や躁状態などのメンタルヘルス上の懸念、2) 自傷行為や自殺行為、3) AIへの感情的依存に重点を置きます。自殺行為や自傷行為に関する既存の安全性指標に加え、感情的依存や自殺を伴わない精神衛生上の緊急事態も標準の安全性テストに組み込むとともに、Model Specを改訂して、人間関係を尊重・支援すること、根拠のない信念を肯定しないこと、妄想や躁状態の兆候に安全かつ共感的に対応すること、そして自傷を示唆する間接的シグナルに注意を高めることを明確化しました。これらは潜在的危害のマッピング、評価や実会話データ・ユーザー調査による測定、外部専門家との検証、リスク軽減の実装という段階的プロセスで推進しています。2025年10月のモデル更新では、GPT‑5を含む改善によりメンタルヘルスや自傷・自殺、AI依存などのセンシティブな会話での不適切な応答を65～80%削減し、170名以上の精神科医等の専門家およびGlobal Physician Networkとの連携によるターゲット評価で準拠率の向上を確認しました（精度と再現率のトレードオフも考慮）[4]。

医療という高リスク領域では、対象と状況に応じた評価を重視します。OpenAIは60か国・262名の医師協力による5,000件の対話と4万以上の評価ルーブリックから成るHealthBenchを用い、緊急時のトリアージ、ユーザーが医療専門家か否かに応じた用語・口調・詳細の調整、不確実性の適切な伝達、状況に応じた回答の深さ、医療文書や臨床知識支援などの健康データタスクの安全な完了といった観点で安全性と有用性を測定しました。その結果、最新モデル（o3、GPT‑4.1等）は従来モデルより大幅に改善しつつも、信頼性やコンテキスト把握には引き続き改善の余地があることが可視化されました[5]。

クリエイティブ領域では、モデルの提供形態を対象ニーズに合わせて最適化します。Soraの早期アクセスプログラムでは60カ国以上・300人以上のユーザーから50万件超のフィードバックを収集し、振る舞いと安全プロトコルの遵守を改善しました。アーティストからの知見を踏まえ、C2PAメタデータの埋め込みを維持しつつ、有料ユーザーが透かしなしで動画をダウンロードできるオプションを導入し、ストーリーテリングや創作支援に適したツールとして、汎用ツールと異なる取扱いのもとで柔軟性を高めています。一方で、前向きなユースケースと潜在的な悪用を特定し、ヌード、選挙に関する欺瞞的コンテンツ、自傷行為、暴力などの主要領域に関する内部評価を整備するとともに、プロンプトフィルタリング、ブロックリスト、分類器の閾値調整によるモデレーション基準の策定と緩和策の強化を進めています[6]。

OpenAIは、提供形態における多層の安全対策を標準化します。APIの安全性を支えるために、潜在的な用途の公開前レビュー、危険な出力を検出するコンテンツフィルターの提供、継続的な悪用監視を実施します。指示追従性の向上がもたらし得るリスクに対しては、モデルが特定の指示を拒否できることを重視し、ラベル作成者の嗜好差や不一致の理解を進めながら、特定コミュニティの価値に基づく制約を可能にする研究と、社会的影響を伴う意思決定に対する責任ある包括的プロセスを確立します[7]。

モデルの特徴と提供形態・対象は、提供チャネルごとのデータ取り扱い方針を明確化しています。APIおよびEnterpriseの顧客データはデフォルトで学習に使用せず、ChatGPTなどの非APIサービスで送信されたデータはモデル改善に用いられる場合がありますが、プライバシーリクエストポータルから学習用途のオプトアウトが可能です。Temporary Chatsは学習に使用しません。公開情報を用いた個人のプロファイリングや広告・ターゲティング、データ販売は行わず、モデルは問い合わせのたびに新たに文章を生成し、回答のために情報をデータベース保存して「コピー＆ペースト」することはありません。学習に用いる個人情報の最小化、個人・機密情報の要求への拒否、プライベート情報を含む回答の最小化といった方針も徹底します[9]。

指示追従性というモデルの特徴については、OpenAIがInstructGPTをRLHFで学習・整合し、APIのデフォルトとしてデプロイしました。InstructGPTはGPT‑3と比べてユーザー意図への忠実性と真実性が高く有害性が低いことが示され、学習にはPlayground経由のプロンプト（個人を特定できる情報を除去済み）を用いました。APIにおける潜在的に有害な出力の測定など、各種指標で挙動評価も実施しています[7]。

さらに、モデルの対象領域としてメンタルヘルスに関する独立研究を支援するため、最大200万ドルの助成金を用意した研究提案の募集を開始しました。文化・言語の多様性や年齢に応じたトーン・スタイルの調整、偏見の検出・軽減、マルチモーダルな評価データセットの構築、悲嘆支援の対話パターンや評価ルーブリックの整備などを焦点に、研究論文、分類体系、データセット、プロトタイプの対話フロー等の成果物を対象とし、研究機関・組織に所属する、またはメンタルヘルスの豊富な経験を有する18歳以上の方を対象に、営利目的ではなく研究への資金提供を行います（2025年12月1日募集開始、12月19日締切）[8]。

モデルの特徴と提供形態・対象は、行動指針（Model Spec）、具体的な応答設計（拒否の型とルール）、領域別の評価（HealthBenchなど）、製品レベルのガードレール（SoraやAPIの安全対策）を連動させ、対象ユーザーや利用文脈に適合した設計を磨き続けます。私たちは、知的自由を守りながら実世界で信頼できる有用性を実現するため、コミュニティや専門家と共に継続的に改善していきます[1][2]。

【出典】
[1] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[2] https://openai.com/ja-JP/index/introducing-the-model-spec/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[5] https://openai.com/ja-JP/index/healthbench/
[6] https://openai.com/ja-JP/index/sora-system-card/
[7] https://openai.com/ja-JP/index/instruction-following/
[8] https://openai.com/ja-JP/index/ai-mental-health-research-grants/
[9] https://openai.com/ja-JP/consumer-privacy/


## モデルアーキテクチャ・性能
モデルアーキテクチャ・性能は、推論力を核に据えたアーキテクチャと学習手法を継続的に進化させ、実世界のタスクで示せる性能を最優先に開発を進めています。強化学習を用いたChain of Thoughtアプローチで訓練した推論特化モデル「o1‑preview」を公開し、競技プログラミングやAIME、GPQAなどでGPT‑4oを大きく上回る推論能力を確認、困難なジェイルブレイクやエッジケースを含む安全性評価においても高い適合を達成しました。思考の連鎖（Chain of Thought）の取り扱いについては、モデルの監視と理解を可能にするため原則「隠す」方針をとり、内部での忠実な思考過程モニタリングに活用する一方、ポリシー遵守やユーザー嗜好を思考の連鎖に直接埋め込まないこと、整合性のない思考の連鎖をユーザーに開示しないことを明確にしています。o1シリーズでは、生の思考連鎖は表示せず要約のみを提示する運用で、ユーザー体験と安全性の両立を図っています[1]。

モデルアーキテクチャ・性能は、モデルの望ましい振る舞いとアライメント上のトレードオフを明示する「Model Spec」を導入・公開し、知的自由と透明性を重視しながらも必要なガードレールを維持する設計原則を提示しています。有害な手順（例：爆弾の作り方）は提供せず、政治的・文化的にデリケートな問いには特定の意図を推進することなく思慮深く対応する方針を明文化しました。さらに、挑戦的プロンプトセットで準拠度を測り、昨年5月時点の当社最高システムと比べて準拠が大幅に改善していることを確認しています。これは一部ポリシー更新の影響を含みますが、主としてアライメントの強化に起因すると評価しています。なお、モデルの振る舞いは明示的にプログラムされるのではなく広範なデータから学習されるため、その形成は依然研究初期段階であり、相反する要請間の評価と設計を慎重に進めます[2][3]。

モデルアーキテクチャ・性能は、安全な振る舞いの強化に向け、人間フィードバックの非効率を補完する「ルールベース報酬（RBR）」をRLHFに統合しました。有害・デリケートなリクエストに対し、断固拒否・ソフト拒否・遵守という応答タイプを定義し、簡潔な謝罪や感情への配慮など望ましい応答要件を明示的ルールで規定することで、過剰拒否を抑えつつ有用性とのバランスを保ち、ポリシー更新にも迅速に追随できる運用性を実現しています[4]。

モデルアーキテクチャ・性能は、アーキテクチャ効率とツール使用の活用を性能の鍵と位置づけ、o3およびo4‑miniを高い「推論努力」設定で評価しました。AIME 2025では、Pythonインタープリターなどのツール使用時にo4‑miniがpass@1 99.5%（consensus@8 100%）、o3がpass@1 98.4%（consensus@8 100%）を達成し、社外専門家の評価でも、ウェブソースの取り込みによる検証可能性の向上、指示遵守の精度改善、過去の会話やメモリ参照を踏まえた自然な対話性の向上が確認されました。効率性の面では、o4‑miniはo3より高い使用制限と高スループットを実現しています。これらの結果はツール非使用モデルとの単純比較は適切でないことも併せて明記しています。SWE‑bench評価は当社インフラで検証済みタスクn=477の固定サブセットで実施しています[5]。

モデルアーキテクチャ・性能は、性能評価設計において「スキャフォルディング」が結果へ与える影響を重視します。同一モデルでもRAGベースの初期スキャフォールドとCodeRのような上位スキャフォールドでSWE‑bench Liteの成績が大きく変動することを確認し（例：2.7%から28.3%へ）、学習前・学習中・学習後（外部統合後）まで継続的に多面的評価を行う実務的フレームワークを運用しています。SWE‑bench Verifiedの公開により、検証済みサンプルに基づく厳密評価を可能にし、GPT‑4oの達成率が16%から33.2%へ向上することも示しました。静的データセット評価には汚染やカバレッジの限界があるため、Preparednessの考え方に基づき他の評価と組み合わせて偏りを補正します[6]。

モデルアーキテクチャ・性能は、開発者と研究コミュニティに向けて、オープンウェイトの推論モデル「gpt‑oss‑120b」「gpt‑oss‑20b」および安全性拡張版を提供し、デスクトップからデータセンターまでローカル実行・高度なカスタマイズ・思考連鎖の可視化を可能にしています。MMLUやGPQA Diamond、AIME 2024/2025などのベンチマーク結果や安全性のModel System Cardも公開しており、AIME 2024で96.6（120b）/91.6（20b）、AIME 2025で97.9（120b）/98.7（20b）といった性能を提示しています[7]。

モデルアーキテクチャ・性能は、ハルシネーション対策として「不確実なら推量せず棄権する」を原則に掲げ、コアバリューおよびModel Specに反映しています。正確性だけを競うスコアボードには偏重せず、エラーが棄権よりも問題であるという前提で評価設計を見直します[8][2]。この方針の下、GPT‑5.2 ThinkingはGPT‑5.1 Thinking比で匿名化ChatGPTクエリの誤りを相対38%削減し、長文推論では社内ベンチマークMRCRv2でトップレベルの性能、256kトークンの4‑needle MRCRバリアントでほぼ100%に到達しました。評価は最大のreasoning effort設定でsearchツールを有効化して実施しており、重要な用途では引き続き回答の検証を推奨します[9]。

モデルアーキテクチャ・性能は、教師なし学習のスケーリングでも前進しており、GPT‑4.5の研究プレビューでは知識の広がり、意図理解、創造性・EQ、幻覚の減少が改善。代表的ベンチマークでGPQA 71.4%（GPT‑4oは53.6%）、AIME ’24 36.7%（GPT‑4oは9.3%）、SWE‑Bench Verified 38.0%（GPT‑4oは30.7%）など、標準指標で意味のある向上を示しました[10]。

モデルアーキテクチャ・性能は、指示追従性能の基盤としてInstructGPTをRLHFで学習・整合させ、175BのGPT‑3に対して100倍以上小さい1.3Bモデルの出力が人間ラベラーにより好まれ、事実の捏造や有害出力も減少することを実証しました。既存のNLPベンチでもGPT‑3の能力を損なわずに、指示遵守・真実性・有用性を高めています[12]。

モデルアーキテクチャ・性能は、医療分野の総合評価基盤HealthBenchを公開し、60か国・262名の医師協力による5,000の対話、4万以上のルーブリックで安全性・有用性・信頼性を多面的に計測しています。最新モデル（2025年4月時点のo3、o4‑mini、GPT‑4.1など）は平均28%の改善を示し、小型モデルも急進。たとえばGPT‑4.1 nanoは2024年8月のGPT‑4oを上回りつつコストを25倍削減しました。モデルサイズとテスト時計算の二軸でコスト・性能フロンティアを更新し、o3・o4‑mini・o1における低/中/高推論レベルでのテスト時計算の改善や、「worst‑of‑n」による最悪ケースの信頼性大幅改善も報告しています[11]。

モデルアーキテクチャ・性能は、アーキテクチャ研究としてスパース回路の探索を進め、大部分の重みを0に固定したスパースモデルの学習により、内部計算を少数の読解可能な「回路」へと解きほぐす方法を検証しました。スパース度を高めると固定サイズでは一部性能低下がある一方で解釈可能性が向上し、モデルサイズ拡大により性能と解釈可能性の両立フロンティアを押し広げられること、さらにはより大きくよりスパースなモデルでより単純な回路により高性能を達成できることを示しました[13]。

モデルアーキテクチャ・性能は、現実世界の業務性能を計測するためGDPvalを提案・運用し、米国GDPへの寄与が大きい9産業・44職種に基づく1,320の実世界タスクで専門家が成果物を採点しました。フロンティアモデルは多くのタスクで産業専門家より約100倍高速・100倍安価に遂行でき、品質では人間専門家に近づいており、時間経過とともに明確な進捗が確認されています[14]。

モデルアーキテクチャ・性能は、推論アーキテクチャの刷新、安全かつ有用な振る舞いの設計、ツールやスキャフォルディングを含む実運用での性能最適化、そして評価手法の継続的改善を通じて、モデルの性能を一貫して前進させていきます[1][3][5][6][8]。

【出典】
[1] https://openai.com/ja-JP/index/learning-to-reason-with-llms/
[2] https://openai.com/ja-JP/index/introducing-the-model-spec/
[3] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[4] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[5] https://openai.com/ja-JP/index/introducing-o3-and-o4-mini/
[6] https://openai.com/ja-JP/index/introducing-swe-bench-verified/
[7] https://openai.com/ja-JP/open-models/
[8] https://openai.com/ja-JP/index/why-language-models-hallucinate/
[9] https://openai.com/ja-JP/index/introducing-gpt-5-2/
[10] https://openai.com/ja-JP/index/introducing-gpt-4-5/
[11] https://openai.com/ja-JP/index/healthbench/
[12] https://openai.com/ja-JP/index/instruction-following/
[13] https://openai.com/ja-JP/index/understanding-neural-networks-through-sparse-circuits/
[14] https://openai.com/ja-JP/index/gdpval/


