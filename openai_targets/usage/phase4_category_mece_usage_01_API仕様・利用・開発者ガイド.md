# 政策ストーリーライン

## 概要


# API仕様・利用・開発者ガイド

### 基本姿勢
OpenAIはAPI仕様・利用・開発者ガイドを「セキュアで管理可能、かつ責任ある活用」を最優先に設計し、Model Specに基づく知的自由と堅牢なガードレールの両立を軸に、最新のマルチモーダルモデルを安心して使える基盤を提供します。OpenAIはAPI経由の顧客データを学習に使用せず、保存時AES‑256／転送時TLS 1.2+の暗号化、（特定エンドポイントを除き）30日間の限定保持、SOC 2 Type 2およびISO 27001/27017/27018/27701、必要に応じたHIPAA BAA対応などエンタープライズ水準の保護を徹底します。OpenAIは継続的なポリシー更新と透明性ある運用で、不適切利用を抑止しつつ拡張性と透明性を確保します。

### 重点的取り組み
OpenAIはResponses API・Realtime API・Agents SDKを進化させ、複雑なエージェント・オーケストレーション、リアルタイム音声、長文推論を本番品質で扱える開発体験を提供します。OpenAIはスケールティアとAPI優先処理（service_tier="priority"、SLA対象）でピーク時でも予測可能なレイテンシと99.9%稼働を実現し、SAML SSO、MFA、RBAC、SCIM、Admin/Audit APIs、IP許可リストやmTLS、データレジデンシーやゼロデータ保持などの統制機能を強化します。OpenAIはModel Specとルールベース報酬（RBR）で安全性を高め、入出力の権利設計や社内/外部コネクター、カスタムMCPコネクターの開発者モードで現場の導入・拡張を加速します。

### 重要事実
OpenAIは2025年10月に使用ポリシーを改訂し、なりすまし・選挙干渉や重要領域での人間未確認の自動化などの禁止を明確化しました。OpenAIは2025年11月のMixpanelにおける限定的なAPIユーザー分析データ不正アクセスに対し即時遮断・影響調査・個別通知を実施し、当社インフラへの不正アクセスは確認されていません。OpenAIはGPT‑5系/GPT‑4.1系/GPT‑4oやSora 2、gpt‑realtimeを含むマルチモーダルAPIとスケールティア（専用スナップショット、トークン前払い、無制限スケール、99.9% SLA）を提供し、DNPなどの企業で週次アクティブ率100%、自動化率87%、処理量10倍といった実運用の成果が確認されています。


## API・利用方法
API・利用方法は、APIの利用において「セキュアで管理可能、かつ責任ある活用」を公式見解として掲げ、開発者と組織が安心してアプリケーションを構築・運用できる環境を提供します。API・利用方法は最先端のモデルを安全に活用できるAPIプラットフォームを通じて、業務アプリケーションやエージェントの構築・展開・運用を支援し、顧客データをモデル学習に使用しないことを明確にするとともに、保存時はAES‑256、転送時はTLS 1.2以上で暗号化するなど、データ保護を前提とした設計を徹底しています[1][2]。APIで入出力されたデータは、プラットフォームの説明ページで列挙された特定のエンドポイントを除き、サービス提供と不正利用の特定のために30日間安全に保持します[3]。また、API・利用方法はSOC 2 Type 2の認証を受けており、必要に応じてHIPAA準拠のビジネスアソシエート契約（BAA）にも対応します[3]。

API・利用方法は、組織管理者が安全かつ効率的に運用できるエンタープライズ機能を標準提供します。SAML SSOによるシームレスな認証とMFA（TOTP）でのアカウント保護、IP許可リストやmTLSによるネットワーク管理、プロジェクトとプロジェクト制限によるアクセス・使用状況・支出のきめ細かなコントロール、Admin APIでの権限の一元管理、Audit Logs APIによるセキュリティ／コンプライアンスの可視化、使用状況ダッシュボードでの機能・製品・チーム・プロジェクト単位のトラッキング、SCIMによるユーザーライフサイクル自動化、ロールベースのアクセス制御（RBAC）や課金・使用量アラートの設定など、運用に必要な管理・可視化・統制をワークスペース全体で実現します[1][2]。さらに、データレジデンシーのコントロールやゼロデータ保持ポリシー（リクエストに応じた適用）にも対応し、規制要件への適合を支援します[2][3]。

API・利用方法は、GPT‑4やGPT‑3.5 Turboをはじめとするモデル群へのアクセスを提供し、特定タスクに合わせたファインチューニングもサポートします。ファインチューニング済みモデルは実施したお客様だけが利用でき、他のお客様への提供・開示や他モデルの学習には使用しません。ファインチューニングのために送信されたデータは、お客様がファイルを削除するまで保持します[3]。また、テキスト・画像・動画・音声を単一のシステムで扱えるマルチモーダルな利用方法をAPIで提供し、Image Generation API（Sora 2）や実運用レベルの音声エージェントを構築できるgpt‑realtime／Realtime APIまでを網羅しています[1][7]。

API・利用方法は、大規模運用のための「スケールティア」をEnterpriseのお客様向けに提供します。専用モデルのスナップショットにアクセスし、1分あたりのAPI入出力トークンを前払いで購入することで、予測可能なレイテンシ、上限なしのスケール、99.9%稼働率のSLA、優先コンピュートを実現します（例：GPT‑5は入力25,000 TPM、出力2,500 TPMのバンドルを提供。GPT‑5 miniやGPT‑4.1系のバンドルも用意）[6]。加えて、PlaygroundやAPIドキュメント、シンプルな従量課金、専任アカウントチームや優先サポート、ソリューションアーキテクトによるベストプラクティスの提供、研究者とのカスタムモデル構築の機会を通じ、素早い検証から本番実装までを一貫して後押しします[1]。

API・利用方法は、「使用に関するポリシー」に基づく責任ある活用をお願いしています。なりすまし、選挙干渉、重要インフラや金融・与信など高リスク領域での人間の確認のない自動化といった行為は禁止です。同ポリシーは継続的に更新され、安全性と適用法順守の明確化を図っており、ポリシー体系や関連規約の一覧はポリシーページでご案内しています[4][5]。

API・利用方法は、自社の運用においてもAgents SDK、Responses API、Realtime APIを用いた新しいAIオペレーティングモデルを導入し、サポート品質の継続的な向上を実現しています[8]。実装パターンや価値創出の事例は活用事例ギャラリーとして継続的に公開・更新しており、たとえばConsensusがGPT‑5とResponses APIで研究を加速した事例（2025年10月23日掲載）をはじめ、最新の活用事例を多数ご紹介しています[9][10]。

API・利用方法は、セキュリティインシデント発生時の透明性ある対応にも取り組みます。2025年11月、Mixpanelにおける限定的なAPIユーザー分析データの不正アクセスを受け、直ちにMixpanelを本番環境から除去し、影響調査と対象者への個別通知を実施しました。本件はMixpanel側に限定され、当社インフラへの不正アクセスは確認されていません。API・利用方法は、お客様にパスワード・APIキー・確認コードをメールやテキスト、チャットで要求することはありませんので、予期しないメッセージにはご注意ください。アカウント保護のため多要素認証の有効化も推奨します[11]。

API・利用方法は、これらの方針と機能群を通じて、開発者と企業がAPIを安全・確実に導入し、運用とコンプライアンスを両立させながら価値創出を加速できるよう、今後も継続的に支援していきます[1][2][4][5]。

【出典】
[1] https://openai.com/ja-JP/api/
[2] https://openai.com/ja-JP/business-data/
[3] https://openai.com/ja-JP/enterprise-privacy/
[4] https://openai.com/ja-JP/policies/usage-policies/
[5] https://openai.com/ja-JP/policies/
[6] https://openai.com/ja-JP/api-scale-tier/
[7] https://openai.com/ja-JP/index/1-million-businesses-putting-ai-to-work/
[8] https://openai.com/ja-JP/index/openai-support-model/
[9] https://openai.com/ja-JP/stories/api/
[10] https://openai.com/ja-JP/stories/
[11] https://openai.com/ja-JP/index/mixpanel-incident/


## API活用によるシステム改善
API活用によるシステム改善は、APIを中核に据えたAIオペレーティングモデルを公式方針として推進し、機械的な作業は徹底的に自動化しつつ、重要な判断は人間が担う設計原則のもとで、Agents SDK、Responses API、Realtime API、評価ダッシュボードといったプラットフォームのプリミティブを提供します。これにより、品質を測定可能にしながらスピードと一貫性を両立させ、サポートを「チケット処理」から「継続的に学習し改善するシステム」へと転換します[7][4]。API活用によるシステム改善はあわせて、MFAやSAML SSO、プロジェクト単位の制限設定、Admin APIやAudit Logs API、使用状況ダッシュボードなどの管理・セキュリティ機能をプラットフォームに備え、アクセス、利用、支出、リスクの可視化と制御を可能にします[6]。

API活用によるシステム改善は、開発者ワークフローにおける反復作業の自動化と意思決定の高速化を出発点とし、その効果を実運用で実証しています。たとえばJetBrainsは、OpenAI APIをIDE内に統合したAI Assistantで、テスト作成、変数命名、コード説明、リファクタリング、エラー原因の明確化と修正提案、文書・コミットメッセージ生成を提供し、ブラウザ切替え不要の体験によって情報検索時間の短縮（78%）、時間の有効活用（77%）、作業の短時間化（71%）を実現しました[1]。API活用によるシステム改善は、ChatGPT Business/for Engineeringを通じて、ソースコードや設計、社内ドキュメントを組織管理の下で安全に扱い、SSOと多要素認証でアカウントを保護しながら、コード作成・レビュー・ドキュメンテーション・設計改善までをワンストップでつなぐエンジニアリングワークスペースを提供します[2]。さらに、IndeedやLowe’s、Intercom、Databricksといった企業がOpenAIのAPIを組み込むことで、応募や採用の成果向上、店舗運用の支援、開発サイクルの短縮、企業データ環境との統合による高品質エージェントの構築・運用など、業務KPIの改善を広げています[10]。

API活用によるシステム改善は、自社の運用においてもAPIを基盤に改善サイクルを高速化しています。サポートチーム向けのリサーチアシスタントは、何百万件ものチケットを分類・要約し、対話型の自然言語インターフェースでレポートを生成、リリースレポート作成を数日から数分に短縮し、分析をバッチ中心から継続的な探索へと転換しました[3]。また、Support AgentやInbound Sales Assistantなど、あらゆるインタラクションを学習データへ還元する内部システムを運用し、フィードバックへの応答を数週間から数分へ短縮、品質の継続的向上を実現しています[8]。

API活用によるシステム改善は、サポート領域を全社的なシステム改善のモデルケースに位置づけています。Agents SDKはステップレベルのトレースと監視、リプレイ、ツール呼び出しの検査と即時デバッグを可能にし、Responses APIはトーン、正確さ、ポリシー遵守のための分類機能を強化します。Realtime APIは音声サポートを、評価ダッシュボードは品質の計測と可視化を支え、担当者は日々の業務の中でテストケース化や分類機能の提案、軽量オートメーションのプロトタイピングまでを担い、対応者であると同時にシステムビルダーとしてアーキテクチャに寄与します。結果として、サポート組織はスループットではなく「進化する能力」で定義されるようになります[7]。

API活用によるシステム改善は、規制が厳しい重要業務でも有効です。社内で構築した契約書データエージェントは、PDFやスキャン、写真の契約書から条項を構造化し、非標準条項を理由とともにハイライトしてレビュー時間を半減。夜間処理で大量の案件を増員なく捌ける新しい財務の運用モデルを実現し、「機械的な作業は自動化し、判断は人間が担う」という原則で専門家が分析と戦略に集中できる体制を支援します[4]。

API活用によるシステム改善は、エンタープライズ導入でも成果を示しています。大日本印刷（DNP）はChatGPT Enterpriseを10部門に展開し、3か月でユースケースの90%が効果を実証、週次アクティブ率100%、作業自動化率87%、ナレッジ再利用70%、処理量10倍を達成。外部セキュリティ監査の差分確認は30分から5分に、暗号スイート選定は3時間から1時間に、CIS Benchmarksの初動調査は約2人日から約10分に、レビュー支援も1時間から30分へ短縮し、資料突き合わせ中心から意思決定とリスク判断に集中し、最終レビューは人間が担う運用を徹底しています[5]。

API活用によるシステム改善は、ガバナンスとセキュリティを開発者体験と同じ基盤に組み込みます。MFAやSAML SSO、プロジェクトとプロジェクト制限、Admin API、Audit Logs API、使用状況ダッシュボードの提供により、ワークスペース内のアクセス、使用状況、支出、セキュリティ・コンプライアンスリスクをきめ細かく可視化・制御。さらに、Enterprise／Business／Edu／API各サービスで、ビジネスデータは既定で学習に使用せず、AES-256およびTLS1.2以上での暗号化や第三者監査を含む包括的なセキュリティを実施します[6]。

API活用によるシステム改善は、ソフトウェア開発ライフサイクルそのものを強化するエージェント活用も前進させています。Aardvarkはコードリポジトリの継続分析から、脆弱性の検出・悪用可能性の確認・優先順位付け・パッチ提案までを多段階パイプラインで実施し、GitHub等と連携して人間のセキュリティリサーチャーのように協働します（プライベートベータ）[9]。また、画像・動画生成のためのImage Generation API（Sora 2）から、実運用レベルの音声エージェントを構築できるgpt-realtimeおよびRealtime APIまで、テキスト・画像・動画・音声を1つのシステムでシームレスに扱えるマルチモーダルなワークフローを企業が実装できるよう進化させています[10][7]。

API活用によるシステム改善は、開発・データ・プロダクト領域のワークフロー最適化も包括的に支援します。エンジニアリング向けには、コード作成・レビュー・共同作業を1つの安全なワークスペースで支援し、エラーの切り分けや言語間コード変換、外部ストレージ統合によるコンテキスト反映を提供します[2]。データサイエンス／アナリティクス向けには、ビジネス上の問いを実行可能なデータプロジェクトへ変換し、特徴量パイプラインの自動化から成果物化までを、SSOと多要素認証を備えた信頼性の高いワークスペースでスケールさせます[12]。プロダクトマネジメント向けには、フィードバックの分類やロードマップ草案の作成など、計画と運用の結節点をワークスペース上で支援し、統制の取れた意思決定を促進します[11]。

API活用によるシステム改善は、今後もAPI、SDK、評価・運用ツールとエンタープライズ機能を拡充し、開発・運用・セキュリティ・サポート・財務など全社ワークフローを横断して、組織が自らの専門性をコードと組み合わせて拡張できる「継続的に学習し改善するシステム」への移行を後押ししていきます[7][8]。

【出典】
[1] https://openai.com/ja-JP/index/jetbrains/
[2] https://chatgpt.com/ja-JP/business/ai-for-engineering/
[3] https://openai.com/ja-JP/index/openai-research-assistant/
[4] https://openai.com/ja-JP/index/openai-contract-data-agent/
[5] https://openai.com/ja-JP/index/dai-nippon-printing/
[6] https://openai.com/ja-JP/business-data/
[7] https://openai.com/ja-JP/index/openai-support-model/
[8] https://openai.com/ja-JP/index/building-openai-with-openai/
[9] https://openai.com/ja-JP/index/introducing-aardvark/
[10] https://openai.com/ja-JP/index/1-million-businesses-putting-ai-to-work/
[11] https://chatgpt.com/ja-JP/business/ai-for-product-management/
[12] https://chatgpt.com/ja-JP/business/ai-for-data-science-analytics/


## エンドポイントと入出力仕様
エンドポイントと入出力仕様は、開発者が安心して高度なアプリケーションを構築できるよう、APIの入出力の定義、権利、ガバナンス、安全要件を明確に位置づけています。エンドポイントと入出力仕様は、API利用時の「インプット（入力）」と「アウトプット（出力）」を明示的に区分し、ユーザーが提供する情報について必要な権利・許諾を保有し、当社利用規約および適用法に適合する責任がユーザーにあることを定めます。適用法の範囲でユーザーはインプットの所有権を保持し、アウトプットについての権利を有し、当社が保持しうるアウトプットに関する一切の権限はユーザーに譲渡されます。一方で、生成AIの性質上アウトプットは必ずしも特有ではなく、他のユーザーが類似の結果を得る場合があること、また第三者サービスや第三者アウトプットが関与する場合には固有の条件が適用されることを明確化しています[1]。

エンドポイントと入出力仕様は、マルチモーダルを中核に据え、単一のエンドポイントで多様なメディアを扱える体験を提供します。たとえばGPT‑4oはテキスト・音声・画像・動画の混合入力と出力に対応し、リアルタイム処理を可能にすることで、会話、視覚理解、音声対話、動的なメディア生成・解析といったワークフローを統合し、エンドユーザーに一貫した応答を提供します[2]。

エンドポイントと入出力仕様は、入出力の全行程に安全対策を組み込みます。動画生成モデルSoraでは、プロンプト変換、画像出力分類器、ブロックリストから成る多層的モデレーションを採用し、入力・出力の両段で不適切なコンテンツをブロックします。人物を含む画像アップロードなど入力種別に応じて閾値を厳格化し、年齢に適した出力を重視。実運用前の評価では、ヌード・示唆的コンテンツの入力時精度およびエンドツーエンド（出力時）精度で高い検出性能を確認しています。また、合意のない親密なイメージを含む露骨な性的コンテンツなどの生成を禁止し、違反時にはコンテンツの削除や利用禁止を含む対応を行い、一般公開ギャラリー（Explore）では一層厳格な基準でコンテンツをフィルタリングします[3]。

エンドポイントと入出力仕様は、モデル振る舞いのガイドライン「Model Spec」に基づき、受け取る指示の解釈と優先順位づけを明確化します。Model Specのルールに従う限り、API利用時の権限は開発者とエンドユーザーへ委ねられ、違法行為の助長などに該当する要求には応答しないことをモデルのデフォルト動作として規定します。知識の提示方法が悪用され得るケースも含め、利用規約に基づきアカウントに対する措置が講じられる可能性を明示し、入力意図と文脈に沿った安全な出力を促進します[4]。

エンドポイントと入出力仕様は、複雑なエージェント・オーケストレーションと拡張された入出力要件に対応するため、Responses APIを提供します。Responses APIは、マルチエージェント・ルーティングやサブエージェント呼び出しの細粒度な制御を実現し、ツール呼び出しの信頼性と長文コンテキストでの推論を前提とした設計を後押しします。Chat Completions APIからの移行事例では、信頼性とコスト効率の向上に加え、複雑なワークフローにおける入出力の制御性が高まり、「いつ回答しないか」まで含めた品質設計や、研究根拠やメタデータを付随させた再検証可能な最終出力の提供が容易になります[5]。

あわせて、エンドポイントと入出力仕様は、各プランで実運用に直結する連携エンドポイントと入出力手段を提供します。Enterprise向けには「内部ソース向けのコネクター」を用意し、組織内システムやリポジトリと安全に接続して知識・データを取り込めます。BusinessおよびEnterpriseでは「社内ナレッジ」機能を提供し、ワークスペースに組織の知見を取り込んで回答品質を高める入出力経路を実装できます[8]。さらに、ChatGPT BusinessはJiraやSlackと連携し、戦略策定・ロードマップ作成・フィードバック解析までをワークスペース内で一体的に行えるようにします[6]。エンジニアリング領域では、GitHubなどのコネクターやクラウドコーディングエージェント、Googleドライブ統合を通じて、コード作成・レビュー・コラボレーションを安全なワークスペースで実施でき、組織固有のデータやコンテキストを入出力に反映させることが可能です[7]。

開発者が自社要件に合わせて拡張できるよう、エンドポイントと入出力仕様は「カスタム MCP コネクター向けの開発者モード（ベータ版）」をPlus、Pro、Business、Enterpriseで提供し、標準コネクターに加えてカスタムエンドポイント（コネクター）を実装できる柔軟性を担保します[8]。入出力の基本機能としてファイルアップロードも提供し（無料版は上限付き、Plus/Pro/Business/Enterpriseで有効）、組織ポリシーに沿った運用を支える「ChatGPT 記録モード」も各プランで利用可能です[8]。これらの標準連携とカスタム連携の両輪により、エンドポイントと入出力仕様は、既存ツール群を活かしながら組織固有のデータフローを統合する現実的な実装手段を提供します。

総じて、エンドポイントと入出力仕様は、権利の明確化、モーダリティの拡張、入力・出力の両面での安全対策、指示の解釈ガイドライン、そしてマルチエージェント時代のオーケストレーション能力という五つの柱で体系化され[1][2][3][4][5]、これを各プランの連携エンドポイントと入出力機能で実装面から支えます[6][7][8]。エンドポイントと入出力仕様は、API仕様・利用・開発者ガイドの整備とともに、開発者が安心・安全かつ拡張性の高いアプリケーションを構築できるよう、基盤と運用ポリシーを継続的に改善します。

【出典】
[1] https://openai.com/ja-JP/policies/terms-of-use/
[2] https://openai.com/ja-JP/index/hello-gpt-4o/
[3] https://openai.com/ja-JP/index/sora-system-card/
[4] https://openai.com/ja-JP/index/introducing-the-model-spec/
[5] https://openai.com/ja-JP/index/consensus/
[6] https://chatgpt.com/ja-JP/business/ai-for-product-management/
[7] https://chatgpt.com/ja-JP/business/ai-for-engineering/
[8] https://chatgpt.com/ja-JP/pricing?openaicom-did=b4d3ce0b-42c8-4fec-b5b6-8d4927e8f0b8&openaicom_referred=true


## パラメータ設定・モデル選択
パラメータ設定・モデル選択は、OpenAIのAPIにおけるモデルの振る舞いを規定するModel Specを中核に据え、カスタマイズ性・透明性・知的自由を重視しながら、安全なガードレールを維持する方針を公式に掲げます[1][2]。パラメータ設定・モデル選択はModel SpecをCreative Commons CC0で公開し、開発者とコミュニティが参照しやすい形で提示するとともに、継続的な改善を進めます[1]。このModel Specでは、爆弾の作り方やプライバシー侵害の手順のような危害につながる詳細な指示は提供しない一方で、政治的・文化的にデリケートな質問には特定の意図を推進せず思慮深く回答するという知的自由の原則を明確にし、現実世界での重大な危害を回避しながら自由な議論を支える姿勢を強化しています[2]。

パラメータ設定・モデル選択は、Model Specの原則をモデル選択と設定の実務に具体化するため、評価プロンプトのコレクションを構築し、モデルが各原則にどの程度準拠しているかを継続的に測定します。昨年時点の最良システムと比較してModel Specへの準拠が大幅に改善された事実を確認しており、ポリシー更新の影響を含みつつも、主にアライメント強化の成果と評価しています[2]。また、公開された原則と測定フレームワークに基づき、API利用時の期待挙動を開発者が理解しやすくなるよう、Model Specと評価セットを継続的に拡充します[1][2]。

パラメータ設定・モデル選択は、開発者がユースケースに適したモデルと設定を選べるよう、BusinessおよびEnterprise各プランで複数のモデルオプションと選択肢を提供します。GPT‑5.2 pro、GPT‑5 thinking mini、GPT‑4o、GPT‑4.1、GPT‑4.5、OpenAI o3、OpenAI o3 pro、OpenAI o4‑miniなどを利用でき、多くのモデルで「カスタム設定」を提供します。応答時間はBusinessで高速、Enterpriseで最速を提供し、コンテキストウィンドウは「推論なし」でBusiness 32K／Enterprise 128K、「推論あり」で両プランとも196Kを提供します。さらに、モデルの進化に伴う品質と速度の定期的な更新を行い、性能、コンテキスト長、応答速度、カスタム設定の要件に応じた最適なモデル選択を支援します[6]。加えて、一般向けプランでも、Free/Plus/Proで「推論なし」16K/32K/128K、「推論あり」196Kのコンテキストウィンドウを提供し、Plus/ProではOpenAI o4‑miniを無制限で利用できるなど、用途に応じたモデル選択・設定の幅を用意しています[7]。

パラメータ設定・モデル選択は、モデルの安全性と有用性のバランスを設計上の前提とし、ルールベース報酬（RBR）を強化学習（RLHF）に統合することで、安全な行動を簡潔な命題とルールで促進します。RBRは、有用性（安全なプロンプトへの正しい応諾）と安全性（安全でないプロンプトの正しい拒否）のトレードオフを可視化し、過剰拒否を抑えつつ「安全かつ有用」なモデルを目指し、Model Specのルールを含むガイドライン変更にも大規模な再学習なく迅速に追随できます。主観性の高いタスクでは人間フィードバックと組み合わせて対処します[3]。運用面でも、潜在的な用途を公開前にレビューし、安全でないコンプリーションを検出するコンテンツフィルターを提供し、悪用を継続的に監視します。さらに、ユーザーの指示に従うよう学習したモデルが有害な指示を拒否できるよう、拒否能力の強化を重要課題として取り組み、これらの運用的ガードレールをモデル選択とパラメータ設定の前提となる安全基準として位置づけます[4]。

パラメータ設定・モデル選択は、センシティブな会話領域での安全性向上にも継続的に取り組みます。最近の更新では、メンタルヘルス上の懸念（精神病や躁状態など）、自傷や自殺行為、AIに対する感情的依存を優先領域として強化し、現実世界における関係性を尊重し、根拠のない信念を肯定せず、潜在的な妄想や躁状態の兆候に安全かつ共感的に対応し、自傷や自殺の間接的シグナルにも注意を払う方針を徹底します。長年の自傷・自殺に関する安全性指標ベースラインに加え、感情的依存や自殺を伴わない精神衛生上の緊急事態を、将来のモデルの安全性テストにおけるベースラインの標準セットへと拡張します[5]。また、実運用トラフィックだけに依存しない体系的なオフライン評価を展開し、対応が難しくリスクの高いシナリオを敵対的に選定したうえで、自動評価に加えて独立した臨床専門家レビューを取り入れ、稀なケースでの改善点を特定・反映します[5]。

パラメータ設定・モデル選択は、運用時の品質維持に直結する設定・監視面でも、ChatGPT Businessのデータサイエンス＆アナリティクス向けソリューションを通じて、特徴量パイプラインの自動生成と検証、モデルドリフトの自動検知等を実装します。提供スキーマと特徴量定義に基づくSQL変換ロジックと検証ルールの自動生成、null/範囲/結合整合性などの検証テスト付与、DataGuard CIによる自動アサーション統合、変換スクリプトのバージョン管理化、入力分布の変化を捉える自動ドリフト分析レポート運用を組み合わせ、後続の学習・推論に供するデータ品質と予測の信頼性を維持するための設定・モニタリングを一体化します[6]。

パラメータ設定・モデル選択は、以上の原則と運用枠組みに基づき、開発者がユースケースに合致したモデルと設定を選択できるよう支援し続けます。パラメータ設定・モデル選択はModel Specの公開、評価プロンプトによる準拠測定とRBRを含むアライメント手法、API運用上の安全対策、そして各プランにおける具体的なモデルラインアップとパラメータ選択肢を組み合わせ、自由で有用かつ安全なAIの実装を推進します[1][2][3][4][5][6][7]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[3] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[4] https://openai.com/ja-JP/index/instruction-following/
[5] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[6] https://openai.com/ja-JP/business/chatgpt-pricing/
[7] https://chatgpt.com/ja-JP/pricing?openaicom-did=b18035f2-693f-4144-8219-8588328aad3d&openaicom_referred=true


## モデル概要・技術動向
モデル概要・技術動向は、望ましいモデルの振る舞いを体系化する指針「Model Spec」を掲げ、知的自由・透明性と堅牢なガードレールの両立を公式見解とします。Model Specは2024年5月に発表され、アライメント評価用プロンプトとともにCreative Commons CC0で公開されました。改定を重ねつつ、危害防止のガードレールを維持しながら、爆弾の製造手順やプライバシー侵害の具体的方法といった有害な詳細は提供しない一方、政治・文化などデリケートな問いにも特定の意図を推進せず思慮深く応答するという原則を明確化し、「重大な危害を伴わない限り、あらゆるアイデアは議論の対象になり得る」という知的自由の立場を強化しています。これらは「範囲内に留まる」「共に真実を追求する」に加え、「悪を阻止する」「人の考えを変えようとしない」「不確実性を表現する」「仕事に適したツールを使用する」「長さ制限を尊重しつつ、徹底的かつ効率的になる」といった実践原則として、モデルの具体的な振る舞い基準に落とし込まれています[1][2]。

モデル概要・技術動向は、Model Specへの準拠を現実世界のパフォーマンスとして測るため、一般的から複雑な状況まで含む挑戦的な評価プロンプトを収集し、モデル生成と人間の専門家レビューを組み合わせて検証します。予備結果では、前年5月時点の最良システムと比べ準拠が大幅に改善しており、その多くはアライメント強化に起因すると評価しています。同時に、実運用から見つかる新たなケースを課題セットに継続的に追加し、改善の余地を着実に埋めていきます。Model SpecはRLHFに取り組む研究者やAIトレーナー向けのガイドラインとしても活用し、将来的にモデルがSpecから直接学習する可能性も探求します。さらに、政策立案者・信頼機関・専門家を含むグローバルなステークホルダー、そして一般の皆さまからのご意見を広く募り、初回2週間の意見受付を皮切りに、目的・ルール・デフォルトに関する理解と支持を広げながら、収集・反映のプロセスを整備していきます[1][2]。

モデル概要・技術動向は、RLHFに基づくInstructGPTの学習・整合によって、APIからアクセスできるデフォルトの言語モデルとしての運用を実現しました。ラベル付け担当者によるデモンストレーションと出力ランキングから得たデータでファインチューニングし、GPT‑3に比べて指示追従性を大幅に改善、事実の捏造頻度を低減し、有害出力もわずかに減少しています。人間評価では、パラメータが100倍以上少ない1.3BのInstructGPT出力が、175BのGPT‑3より好まれる結果も得ています[5]。

あわせて、モデル概要・技術動向は大規模マルチモーダルモデルGPT‑4のテキスト入力機能をChatGPTおよびAPI（当初は順番待ちリスト付き）で提供し、学習の安定性を大幅に高め、事前にパフォーマンスをより正確に予測できる初の大規模モデルとして運用しました。さらに、モデルの自動評価フレームワーク「OpenAI Evals」をオープンソース化し、コミュニティによる課題報告と改善参加の基盤を整えています[6]。

技術動向として、モデル概要・技術動向は解釈可能性の研究を推進しています。現行モデルの思考の連鎖は懸念行動の兆候把握に有用である一方、それのみに依存する戦略は脆弱になり得ると評価し、モデルの計算過程をリバースエンジニアリングする機械論的解釈可能性に注力。多くの重みをゼロに固定するスパースモデルを訓練し、少数の理解可能な「回路」で複雑な振る舞いを実現する手法を検証しました。このアプローチは、スケーラブルな監視や安全性上の問題・戦略的不一致の早期警告を支え、敵対的学習やレッドチーミングを補完し、単純な振る舞いについては小さく分離された回路で十分に説明可能であることを示しています[3]。

安全性が特に重要となるセンシティブな会話領域にも、この指針と研究は直結します。モデル概要・技術動向は、メンタルヘルス上の懸念（例：精神病や躁状態）、自傷・自殺行為、AIへの感情的依存という重点領域に対応するモデル更新を実施しました。Model Specに則り、ユーザーの現実世界の関係性を尊重して支援すること、精神的・感情的な苦痛に関連し得る根拠のない信念を肯定しないこと、妄想や躁状態の兆候に安全かつ共感的に対応すること、自傷・自殺のリスクを示唆する間接的シグナルに一層注意を払うことを明確化。問題の定義、測定の開始（評価・実会話データ・ユーザーリサーチの活用）、アプローチの検証（外部のメンタルヘルスおよび安全対策の専門家との協働）、リスクの軽減というステップに基づき、ChatGPTの回答改善を継続します[4]。

また、医療領域では、60か国の262名の医師と作成した5,000の対話と4万以上のルーブリックを備えるHealthBenchを公開し、緊急時のトリアージ、ユーザーペルソナに応じたコミュニケーション、不確実性の適切な伝達、回答の深さ、医療データタスクの完了度などの観点でモデル性能を測定しています。最新モデル（o3、GPT‑4.1など）は従来モデルに比べ大幅に改善する一方、信頼性や文脈理解に改善余地があることも明らかにしています[7]。

モデル概要・技術動向は、Model Specを中核としたガイドライン、実証に基づく測定・改善サイクル、解釈可能性の研究を一体で進め、EvalsやHealthBenchといった評価基盤と合わせて、モデルの安全性・有用性・透明性を着実に前進させます。ステークホルダーおよび一般の皆さまからのフィードバックを取り入れながら、API利用者と開発者が信頼できる最新モデルを選択・活用できる環境を継続的に整備していきます[1][2][6][7]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[3] https://openai.com/ja-JP/index/understanding-neural-networks-through-sparse-circuits/
[4] https://openai.com/ja-JP/index/strengthening-chatgpt-responses-in-sensitive-conversations/
[5] https://openai.com/ja-JP/index/instruction-following/
[6] https://openai.com/ja-JP/index/gpt-4-research/
[7] https://openai.com/ja-JP/index/healthbench/


## 入口設計（使い方・モデル情報）
入口設計（使い方・モデル情報）は、開発者とエンドユーザーが安心してモデルを使いこなせる中核として「Model Spec（望ましいAIモデルの振る舞いのガイドライン）」を位置づけ、アライメント評価用プロンプトとともにCreative Commons CC0で公開しています。入口設計（使い方・モデル情報）は、広く皆さまからのフィードバックを継続的に受け付け、今後1年間にわたり変更点や研究進捗を定期的に共有することで、モデルの前提と振る舞いを理解しやすくし、初期の使い方から運用まで一貫した体験を設計できる環境を提供します[1]。

入口設計（使い方・モデル情報）は、Model Specにおいてモデルが従うべき「指揮系統」を明確化し、プラットフォーム（OpenAI）、開発者、ユーザーの指示に優先順位を設定します。プラットフォームレベルのルールで守るべき範囲を定めつつ、多くの場面で役立つガイドラインは開発者やユーザーが上書きできる柔軟性を持たせ、厳格な範囲管理と高いカスタマイズ性の両立を実現します。また、入口設計（使い方・モデル情報）は「共に真実を追求する」姿勢を重視し、特定の意図に誘導せず客観性を基本に多角的に検討し、ユーザーの目的や前提を理解・明確化し、必要な場合には批判的フィードバックを行います。たとえば、違法行為の助長を避けるなど適用法の遵守を徹底し、ユーザー意図に応じて応答方針を選択します（例：万引きの回避方法には応じない一方、小売店主の防止策には事実に基づき助言）といった原則を示します[1][2]。

入口設計（使い方・モデル情報）は、安全性と有用性のバランスを高水準で保つため、ルールベース報酬（RBR）を導入し、人間フィードバックの強化学習（RLHF）と統合してモデル挙動の一貫性を高めています。RBRは簡潔な命題とルールで安全行動を促し、過剰拒否を抑えつつ更新容易性を確保する設計で、GPT‑4以降に適用しています。さらに、有害・デリケートなトピックに対して、断固とした拒否、柔らかい拒否、従うべき無害な要求という3つの応答タイプを定義し、とりわけ断固とした拒否では「短いお詫び」と「応じられない旨」を簡潔に伝え、冗長・批判的な表現を避ける、といった具体ルールを策定しています。これらは、開発者がプロンプト設計やポリシー設定を行う際の入口要件として機能します[5]。

入口設計（使い方・モデル情報）は、ローカル実行や柔軟な統合を支援するため、オープンウェイトの推論モデル「gpt‑oss‑120b」「gpt‑oss‑20b」を提供し、Hugging FaceやGitHubから取得可能にしています。安全性は基盤という方針のもと、総合的な安全性テストとModel System Cardを公開し、検証可能性と透明性を高めています。開発者に向けては、Transformersでの利用方法、オープンモデルのプロンプトガイド、ファインチューニング手順、gpt‑ossでのResponses API互換サーバーの動作方法、PyTorchやLM Studio/Google Colabでの利用、実装検証（Verifying gpt‑oss implementations）など、導入と拡張に必要なリソース一式を整備し、フィードバックフォームで将来の改善に向けた意見も受け付けます。これにより、初期導入から運用・評価・改善まで、入口設計に必要な技術情報を一元的に入手できます[3]。

入口設計（使い方・モデル情報）は、API利用時のデータの扱いを明確化し、安心して導入できる環境を提供します。OpenAI APIを通じて送信されたデータはモデルの学習やサービス改善には使用しません。一方、ChatGPTやDALL‑Eなどの非APIサービスに送信されたデータはモデル改善に使用される場合があり、非APIサービスでのデータ利用を望まない場合はプライバシーリクエストポータルから手続きいただけます。OpenAIは公開情報から人々のプロフィールを作成したり、広告のターゲティングに利用したり、ユーザーデータを販売することはありません。モデルは問い合わせごとに新しい文章を生成し、後で思い出すために情報をデータベース保存したり、学習情報を「コピー＆ペースト」することはありません。さらに、モデル学習で用いる個人情報を減らし、個人・機密情報の要求には応じないよう訓練し、出力にプライベート・センシティブ情報が含まれる可能性の最小化に取り組みます。加えて、プライバシーポリシーでは、APIなどの事業者向けサービスに関しては本ポリシーの適用範囲が異なり、顧客契約に基づいてアクセスや利用が管理されることを明示しています。これらにより、APIの入口設計においてデータフローとガバナンスの前提が明確になります[4][7]。

入口設計（使い方・モデル情報）は、APIプラットフォーム上でモデル情報と使い方の入口を体系化し、要件に合わせて選べるモデル比較と導線を提供します。たとえば、GPT‑5.2（入力$1.75/100万トークン、出力$14.00/100万トークン、コンテキスト長40万、最大出力トークン13万、知識の中断日2025年8月31日）、GPT‑5.2 Pro（入力$21.00/100万トークン、出力$168.00/100万トークン、同コンテキスト・出力仕様、同知識の中断日）、GPT‑5 mini（入力$0.25/100万トークン、出力$2.00/100万トークン、同コンテキスト・出力仕様、知識の中断日2024年9月30日）といった具体スペックと価格を提示し、プロンプトガイド、フロントエンドのコーディング例、移行ガイドを公開して、最高性能を引き出すための使い方から旧モデルからの移行までを支援します。さらに、事前構築コンポーネントを含む「エージェント向けのオールインワンプラットフォーム」やエージェントビルダー、ChatKitといった構築支援も提供し、ビジュアルなキャンバスでの設計から本番運用までを通貫で支えます[8]。

入口設計（使い方・モデル情報）は、実運用での文脈統合と応答方針の在り方を、自社のインバウンド営業アシスタントの構築・運用で実証しています。製品ドキュメント、ポリシーライブラリ、顧客事例、プレイブックを内部コネクターで推論コンテキストに統合し、「推測しない」正確な回答を見込み客の言語でパーソナライズして返す設計を徹底。会話はコンテキストを保持したまま担当者へシームレスに引き継ぎ、精度は数週間で約60%から98%以上へ改善、パーソナライズされた応答でリード転換率が大幅に上昇し、数か月で年間数百万ドル規模の定常収益の創出に寄与しました[6]。

入口設計（使い方・モデル情報）は、モデルのカスタマイズ性、透明性、知的自由を重視しながら、確かなガードレールを維持する枠組みを反復的に強化します。Model Specやオープンモデル、評価プロンプトの公開、継続的なフィードバック受付と定期的な更新共有を通じて、開発者とユーザーが安心して導入・運用できる入口をこれからも拡充していきます[1][2][3]。

【出典】
[1] https://openai.com/ja-JP/index/introducing-the-model-spec/
[2] https://openai.com/ja-JP/index/sharing-the-latest-model-spec/
[3] https://openai.com/ja-JP/open-models/
[4] https://openai.com/ja-JP/consumer-privacy/
[5] https://openai.com/ja-JP/index/improving-model-safety-behavior-with-rule-based-rewards/
[6] https://openai.com/ja-JP/index/openai-inbound-sales-assistant/
[7] https://openai.com/ja-JP/policies/privacy-policy/
[8] https://openai.com/ja-JP/api/


## 利用管理
利用管理は、OpenAIのChatGPTを組織で安全かつ統制して活用する前提で、中核機能を「利用管理」として設計・運用します。とくにデータの取り扱いでは、ChatGPT BusinessおよびEnterpriseにおけるお客様コンテンツをモデル学習に使用しない方針を明確にし、Free/Plus/Proでは学習に利用される一方でオプトアウト手段を用意するなど、プランに応じたコントロールを提供します[2]。この差別化により、利用管理は各組織のセキュリティポリシーやコンプライアンス要件に沿った運用を実現します[2]。

利用管理は、アイデンティティとアクセスの管理を強化するため、BusinessおよびEnterpriseでSAML SSOを活用し、組織全体で一貫したログイン・認可フローを実現します[1][2]。ユーザーおよび権限のライフサイクルでは、メンバーの一括管理、管理者ロール、ドメイン認証を備え、組織的な運用・監査を支援します[1]。さらにEnterpriseでは、SCIMによるプロビジョニングの自動化、ロールベースのアクセス制御（RBAC）、エンタープライズキー管理（EKM）を採用し、より厳密なアクセス分離と鍵管理の要件に対応します[1]。

利用管理は、組織運用の基盤として専用ワークスペース、管理コンソール、GPTの分析と管理をBusinessおよびEnterpriseで活用し、利用状況の可視化とポリシー適用を容易にします[1][2]。請求面では一元化された請求管理により、部門横断のコスト把握とガバナンスを強化します[1][2]。なお、Businessではアナリティクスダッシュボードが提供対象外である点を明確にし、プランに応じた可視化・管理の最適化を図ります[1]。

利用管理は、利用管理の土台として、SOC 2 Type 2およびISO 27001/27017/27018/27701の認証を前提に運用を行い、セキュリティとプライバシーの実装を強化します。これにより監査可能性と運用の信頼性を確保し、組織のリスク管理を後押しします[1]。

あわせて利用管理は、「使用に関するポリシー」を運用上の規範として重視し、なりすまし、政治運動・選挙干渉、重要インフラや金融・与信、国家安全保障や法執行などの領域における不適切利用を明確に禁止し、高リスク領域での人間の確認のない自動化を認めない姿勢を徹底します[3]。このポリシーは継続的に更新され、2025年10月29日にはOpenAIの製品・サービス全体に適用される一般規定を反映する改訂を実施し、また2022年11月9日にはアプリケーション登録要件を撤廃して自動・手動を組み合わせた違反監視へ移行するなど、運用面からのガバナンスを強化しています[3]。機能面のコントロールとポリシー面のガバナンスを両輪として、利用管理は組織にとって予見可能で安全な利用体験を提供します[1][2][3]。

さらに利用管理は、利用の可視化とガバナンスを実効性あるものにするため、Business/Enterpriseの「GPTの分析と管理」を活用し、活用状況の把握や標準化に結びつけます[2]。実際に大日本印刷（DNP）では、ChatGPT Enterprise導入に際し「週次で1人100回以上の利用」「作業短縮自動化率50％以上」という全社目標を設定し、可視化に基づく継続的フォローを通じて選抜10部門で週次アクティブ率100％を達成するなど、データに基づく運用が利用拡大に寄与しています[4]。

加えて利用管理は、現場実装を支えるためのAPI仕様・利用・開発者ガイドの整備も進め、現場のユースケース展開とガバナンスの両立を推進します。

【出典】
[1] https://openai.com/ja-JP/business/chatgpt-pricing/
[2] https://chatgpt.com/ja-JP/pricing
[3] https://openai.com/ja-JP/policies/usage-policies/
[4] https://openai.com/ja-JP/index/dai-nippon-printing/


